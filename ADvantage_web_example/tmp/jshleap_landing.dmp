pytorch pytorch part understanding hooks in this post we cover debugging and visualisation in pytorch we go over pytorch hooks and how to use them to debug our backpass visualise activations and modify gradients ayoosh kathuria min read tutorial pytorch part memory management and using multiple gpus this article covers pytorch advanced gpu management features including how to multiple gpu for your network whether be it data or model parallelism we conclude with best practises for debugging memory error ayoosh kathuria min read tutorial pytorch part going deep with pytorch in this tutorial we dig deep into pytorch functionality and cover advanced tasks such as using different learning rates learning rate policies and different weight initialisations etc ayoosh kathuria min read pytorch pytorch part building your first neural network in this part we will implement neural network to classify cifar images we cover implementing the neural network data loading pipeline and decaying learning rate schedule ayoosh kathuria min read deep learning pytorch part understanding graphs automatic differentiation and autograd in this article we dive into how pytorch autograd engine performs automatic differentiation ayoosh kathuria min read series data augmentation data augmentation for bounding boxes rethinking image transforms for object detection how to adapt major image augmentation techniques for object detection purposes we also cover the implementation of horizontal flip augmentation ayoosh kathuria min read series data augmentation data augmentation for bounding boxes scaling and translation we implement scale and translate augmentation techniques and what to do if portion of your bounding box is outside the image after the augmentation ayoosh kathuria min read computer vision data augmentation for bounding boxes rotation and shearing this is part of the series where we are looking at ways to adapt image augmentation techniques to object detection tasks in this part we will cover how to implement how to rotate and shear images as well as bounding boxes using opencv affine transformation features ayoosh kathuria min read series data augmentation data augmentation for bounding boxes building input pipelines for your detector previously we have covered variety of image augmentation techniques such as flipping rotation shearing scaling and translating this part is about how to bring it all together and bake it into the input pipeline for your deep network ayoosh kathuria min read series optimization intro to optimization in deep learning busting the myth about batch normalization batch normalisation does not reduce internal covariate shift this posts looks into why internal covariate shift is problem and how batch normalisation is used to address it ayoosh kathuria min read series optimization intro to optimization in deep learning vanishing gradients and choosing the right activation function an look into how various activation functions like relu prelu rrelu and elu are used to address the vanishing gradient problem and how to chose one amongst them for your network ayoosh kathuria min read series optimization intro to optimization in deep learning momentum rmsprop and adam in this post we take look at problem that plagues training of neural networks pathological curvature ayoosh kathuria min read series optimization intro to optimization in deep learning gradient descent an in depth explanation of gradient descent and how to avoid the problems of local minima and saddle points ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part tutorial on building yolo detector from scratch detailing how to create the network architecture from configuration file load the weights and designing input output pipelines ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement your own yolo object detector from scratch in pytorch ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement yolo object detector from scratch in pytorch ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement yolo object detector from scratch using pytorch ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement yolo object detector from scratch using pytorch ayoosh kathuria min read security introducing single sign on sso single sign on sso has become staple in enterprise authorization and identity management we are pleased to announce that saml based sso is now generally available across all paperspace products the benefits of sso include daniel kobran min read announcement introducing gradient low cost instances the public cloud was built first and foremost to enable companies to deliver web applications at scale fast forward decade and today the cloud is used for much more than that one daniel kobran min read announcement paperspace closes to fuel growth we are excited to announce that we have closed series from sinewave ventures battery ventures intel capital with follow on from initialized capital this latest round brings our total funding to daniel kobran min read announcement teams many of our users use paperspace as part of team at company university etc working collaboratively together on projects highly requested feature was to be able structure those teams inside daniel kobran min read paperspace cloud reliability performance improvements we ve come long way as gpu cloud supporting over users and continuing to scale rapidly at times our growth has imposed burden on our systems sometimes in ways we daniel kobran min read gradient what new in gradient we ve been hard at work developing gradient into robust and scalable deep learning platform here roundup of some of the things we ve added recently product release notes can be found here and daniel kobran min read tutorial multi machine create seamlessly launch multiple instances creating multiple machines is now few clicks away this feature is great for rolling out machines for large team scaling out render nodes or running complex daniel kobran min read gpu machine learning on paperspace we spend most of our time here at paperspace making software that runs on gpus given our familiarity with the hardware we thought it would be easy to get started with the newest daniel kobran min read case study ntopology paperspace check out the case study nyc based ntopology is building cad software for generating complex lattice structures used to design high performance printed parts blue button background color ef border border radius px color ffffff daniel kobran min read enterprise paperspace vs citrix how are they different question we often get is how are we different than citrix there are two primary differences in this article we ll use citrix as the example but the same is true for all daniel kobran min read consumer experience gigabit bandwidth one of the most powerful features of paperspace is very simple downloading huge files nearly instantaneously we re distributed team with employees in three countries and we spend lot of time working daniel kobran min read enterprise paperspace deployment guide full vdi implementation in the cloud paperspace provides complete virtual desktop solution in the cloud without any of the headaches of on premise vdi its easy to setup simple to manage daniel kobran min read features new feature drag and drop upload getting stuff onto your paperspace machine should be easy that why we created drag and drop upload files images pdfs documents spreadsheets etc and even folders can be dropped over your machine and daniel kobran min read enterprise why you can host your vdi in the public cloud it seems like everyday you read about another company closing its datacenters and moving to aws josh evans director of operations engineering at netflix recently discussed how everything that is netflix from daniel kobran min read enterprise paperspace security overview security and privacy as the core of your business paperspace is designed with security as the primary consideration we know that security is the cornerstone of all business and we are committed daniel kobran min read enterprise why you should move your company to the cloud okay so you re intrigued by virtual desktops but you re still not convinced of the benefits here are five reasons you should move to the cloud remote access mobility is not buzzword daniel kobran min read consumer st gpu accelerated hosted desktop paperspace is the first hosted desktop provider to come standard with gpu why does this matter two primary reasons fluid os experience applications today are built to leverage gpus the gpu short for daniel kobran min read enterprise paperspace active directory at paperspace we have been developing our own identity management system to enable businesses without large it departments to get up and running with virtual desktops as quickly and easily as possible but daniel kobran min read enterprise why paperspace is the future of enterprise desktops in the cloud era on premise vdi is as good as dead sure on prem vdi will stick around for little longer like all legacy technologies do but it in the life support daniel kobran min read series data augmentation data augmentation for bounding boxes rethinking image transforms for object detection how to adapt major image augmentation techniques for object detection purposes we also cover the implementation of horizontal flip augmentation ayoosh kathuria min read series data augmentation data augmentation for bounding boxes scaling and translation we implement scale and translate augmentation techniques and what to do if portion of your bounding box is outside the image after the augmentation ayoosh kathuria min read computer vision data augmentation for bounding boxes rotation and shearing this is part of the series where we are looking at ways to adapt image augmentation techniques to object detection tasks in this part we will cover how to implement how to rotate and shear images as well as bounding boxes using opencv affine transformation features ayoosh kathuria min read series data augmentation data augmentation for bounding boxes building input pipelines for your detector previously we have covered variety of image augmentation techniques such as flipping rotation shearing scaling and translating this part is about how to bring it all together and bake it into the input pipeline for your deep network ayoosh kathuria min read september series data augmentation data augmentation for bounding boxes building input pipelines for your detector hello there this is the fourth and the final part in our series on adapting image augmentation methods for object detection tasks in the last three posts we have covered variety of image augmentation techniques such as flipping rotation shearing scaling and translating this part is about how to bring it all together and bake it into the input pipeline for your deep network so let get started before you begin you should be already through the previous articles in the series this series has parts part basic design and horizontal flipping part scaling and translation part rotation and shearing part baking augmentation into input pipelinesgithub repoeverything from this article and the entire augmentation library can be found in the following github repo https github com paperspace documentation for this project can be found by opening the docs build html index html in your browser or at this link combing multiple transformations now if you want to apply multiple transformations you can probably do them by applying them sequentially one by one for example if were to apply flipping followed by scaling and rotating here is how would accomplish it img bboxes img bboxes img bboxes randomscale diff true img bboxes img bboxes randomrotate img bboxes the more the transformations need to apply the more longer my code gets at this point we will implement function that solely combines multiple data augmentations we will implement it in the same manner as other data augmentations only that it takes list of the class instances of other data augmentations as arguments let write this function class sequence object initialise sequence object apply sequence of transformations to the images boxes parameters augemnetations list list containing transformation objects in sequence they are to be applied probs int or list if int the probability with which each of the transformation will be applied if list the length must be equal to augmentations each element of this list is the probability with which each corresponding transformation is applied returns sequence sequence object def self augmentations probs self augmentations augmentations self probs probs the self augmentations attribute stores the list of augmentations we talked about there is also another attribute self probs which holds the probabilities with which the augmentations of the corresponding instances will be applied the function looks like def self images bboxes for augmentation in enumerate self augmentations if type self probs list prob self probs else prob self probs if random random prob images bboxes augmentation images bboxes return images bboxesnow if we were to apply the same set of transformations as above we will write transforms sequence randomscale diff true randomrotate img bboxes transforms img bboxes here are the results resizing to an input dimensionwhile lot of architectures these days are fully convolutional and hence are size invariant we often end up choosing constant input size for sake uniformity and to facilitate putting our images into batches which help in speed gains therefore we like to have image transform which resizes our images to constant size as well as our bounding boxes we also want to maintain our aspect ratio image is resized to in the example above the original image is of the size when we have to resize rectangular image to square dimension keeping the aspect ratio constant we resize the image isotropically keeping aspect ratio constant so that longer side is equal to the input dimension we implement resizing the same way we resized augmentations class resize object resize the image in accordance to function in darknet the aspect ratio is maintained the longer side is resized to the input size of the network while the remaining space on the shorter side is filled with black color this should be the last transform parameters inp_dim tuple int tuple containing the size to which the image will be resized returns numpy ndaaray sheared image in the numpy format of shape hxwxc numpy ndarray resized bounding box co ordinates of the format where is number of bounding boxes and represents of the box def self inp_dim self inp_dim inp_dimbefore we build the augmentation logic we will implement function called letter_box image which resizes our image so that the longer side is equal to the input dimension and the image is centered along the the shorter side def letterbox_image img inp_dim resize image with unchanged aspect ratio using padding img_w img_h img shape img shape inp_dim new_w int img_w min img_w img_h new_h int img_h min img_w img_h resized_image cv resize img new_w new_h interpolation cv inter_cubic create black canvas canvas np full inp_dim inp_dim paste the image on the canvas canvas new_h new_h new_h new_w new_w new_w resized_image return canvaswe finally implement the function def self img bboxes img shape img shape img letterbox_image img self inp_dim scale min self inp_dim self inp_dim bboxes scale new_w scale new_h scale inp_dim self inp_dim del_h inp_dim new_h del_w inp_dim new_w add_matrix np array del_w del_h del_w del_h astype int bboxes add_matrix img img astype np uint return img bboxesbuilding an input pipeline for the coco datasetnow that we have our augmentations done and also way to combine these augmentations we can actually think about designing an input pipeline that serves us images and annotations from the coco dataset with augmentations applied on the fly offline augmentation vs online augmentationin deep networks augmentation may be done using two ways offline augmentation and online augmentation in offline augmentation we augment our dataset create new augmented data and store it on the disk this can help us multiply our train example by as many times as we want since we have variety of augmentations applying them stochastically can help us increase our training data many folds before we start to be repetitive however there is one drawback to this method that it isn as suitable when the size of our data is too big consider training dataset that occupies gb of memory augmenting it once alone would make the size go up to gb this might not be problem if you have sample disk space and preferably ssd or high rpm hard disk in online augmentations augmentations are applied just before the images are fed to the neural network this has couple of benifits over our previous approach no space requirements since the augmentations are done on the fly and we don need to save augmented training examples we are getting the noisier versions of the same image every time the image is fed to the neural network it well known that minor noise can help neural networks generalise better every time neural network sees the same image it bit different due to the augmentation applied on it this difference can be thought of as noise which helps our network generalise better we get different augmented dataset each epoch without having to store any extra images cpu or gpu on side note from computationally point of view one might wonder whether the cpu or the gpu should be doing the online augmentations during the training loop the answer is most likely the cpu cuda calls are asynchronous in nature in simple words it means that the control of execution returns to the cpu right after the gpu commands cuda are invoked let break it down how it happens the cpu keeps reading the code where it finally reaches point where it has to invoke the gpu for example in pytorch the command net net cuda signals to the gpu that variable net needs to be put on the gpu any computation made using net now is carried out by the gpu the cpu makes cuda call this call is asynchronous this means that the cpu doesn wait for task specified by the call to be completed by the gpu the control of execution is immediately returned to cpu and the cpu can start executing the lines of code that follow while the gpu can do it thing in the background this means that the gpu can carry out the computations in background parallel now modern deep learning libraries make sure that the calls are properly scheduled to ensure our code works properly however this feature is often exploited by deep learning libraries to speed up training while the gpu is busy executing the forward and the backward passes for the current epoch the data for the next epoch can be read from the disk and loaded into the ram in the meantime by the cpu so coming back to our question should the online augmentations be done by the cpu or the gpu the reason they should be done by the cpu is because then the augmentations for the next epoch can happen in parallel on the cpu while gpu is busy executing the forward and the backward pass of the current epoch if we put the augmentations on the gpu then the gpu will have to wait for the cpu to read the images from the disk and send them over this waiting state can decrease speed of training another thing to notice is that the cpu may be sitting idle given that it has already read the data from the disk while the gpu is doing the crunching augmentation forward backward passes setting up the coco datasetin order to show you how you should use the augmentations we just implemented we take the example of coco dataset we are going to use the pytorch and torchvision package for demonstration purposes try to keep it as general as possible so you can also make it work with other libraries or your own custom code now in pytorch data pipelines are built using the torch utils dataset class this class basically contains two important functions function described the details of dataset this includes the directories where the images and the annotations are stored etc returns the number of training examples returns an individual training example and perhaps it label out of these three the functions is our interest here we will do the image augmentations here generally you should look at the place in your code base where you are reading the images and annotations off the disk this should be the point where you should insert you augmentation code this makes sure augmentation is different for every image even the ones in single batch the following piece of code is normally serves examples from the coco training dataset let assume train is the folder containing the images and annots json is the file containing the annotations json file the reason not going into depth about how to download the coco dataset is because this is just demonstration of how you can modify an existing input pipeline to incorporate augmentations and not an exhaustive guide to set up coco input pipeline in fact the dataset in about gb in size so you might not want to download it from torchvision datasets import cocodetection coco_dataset cocodetection root train annfile annots json for image annotation in coco_dataset forward backward passnow in order to add image augmentations we need to locate the code responsible for reading the images and annotations off the disk that work is done by the function of the cocodetection class in our case we can go to torchvision source code and modify cocodetection but tinkering with inbuilt functionality is not good idea so we define new class which is derived from the cocodetection class class cocoaugment cocodetection def self root annfile transforms det_transforms super cocoaugment self root annfile transforms self det_transforms det_transforms def self idx img bboxes super cocoaugment self idx bboxes bboxes img bboxes self det_transforms img bboxes return bboxeslet us go over what exactly is happening here in our new class we introduce the attribute det_transforms which will be used to hold the augmentation being applied to the image and the bounding box note we also have attributes transforms and which are used to apply torchvision inbuilt data augmentations however those augmentations are only built for classification tasks and don have support to augment bounding boxes too then in the method we first obtain the image and the annotation bboxes returned by the of the parent class as we had mentioned in the part of the series the annotations must be in specified format for the augmentations to work we define the function to do that the bounding box annotations for objects in an image returned by the cocodetection method is in form list which contains dictionary for each bounding box the bounding box attributes are defined by the elements of the dictionary each bounding box is defined by it top left corner height and width we must change it to our format where each bounding box is defined by the top left and the bottom right corner def convert the pil image to numpy array image np array get the bounding boxes and convert them into corners format boxes bbox for in boxes np array boxes boxes boxes reshape boxes boxes boxes boxes grab the classes category_ids np array category_id for in reshape ground_truth np concatenate boxes category_ids reshape return image simply apply the augmentations and now we are served augmented images summing up the entire code from torchvision datasets import cocodetection import numpy as np import matplotlib pyplot as plt def convert the pil image to numpy array image np array get the bounding boxes and convert them into corners format boxes bbox for in boxes np array boxes boxes boxes reshape boxes boxes boxes boxes grab the classes category_ids np array category_id for in reshape ground_truth np concatenate boxes category_ids reshape return image ground_truth class cocoaugment cocodetection def self root annfile transforms det_transforms super cocoaugment self root annfile transforms self det_transforms det_transforms def self idx img bboxes super cocoaugment self idx bboxes bboxes img bboxes self det_transforms img bboxes return bboxes det_tran sequence randomscale diff true randomrotate coco_dataset cocodetection root train annfile annots json det_transforms det_tran for image annotation in coco_dataset forward backward pass conclusion this concludes our series on image augmentation for object detection tasks image augmentation is one of the most powerful yet conceptually simple technique to battle overfitting in deep neural networks as our networks get more complex we need more data to get good convergence rates and augmentation is certainly way to go ahead if data availability is bottleneck imagine in the next few years we would see more complex forms of data augmentation such as augmentations being done by generative networks and smart augmentations where the augmentations are done so as to produce more examples of the sort on which network struggles in the meantime our little library defines more augmentations as well detailed summary of them can be found by opening the index html file in the docs folder we haven covered all the augmentations in our series for example augmentations pertaining the hsv hue saturation and brightness aren covered as they don require augmenting bounding boxes you can now go ahead and even define some of your own augmentations for example we didn implement vertical flip because it doesn make sense to train the classifier on inverted images however if our dataset consists of satellite imagery vertical flip simply swaps directional orientation of objects and might make sense happy hacking the documentation for this project has been generated using sphynx in case you implement new augmentations and want to generate docstrings use the numpy convention to docstrings the sphynx files for the project are located in the docs source folder further reading data preprocessing in pytorch sphynx numpy documentation conventions ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more september series data augmentation data augmentation for bounding boxes scaling and translation this is the second part in series of articles we are doing covering on implementing adapting the image augmentation techniques for object detection tasks in this part we will cover how to implement the scale and translate augmentation techniques and what to do if portion of your bounding box is outside the image after the augmentation in the last part we covered uniform way to implement augmentation as well as the horizontalflip augmentation github repoeverything from this article and the entire augmentation library can be found in the following github repo https github com paperspace documentation for this project can be found by opening the docs build html index html in your browser or at this link part of the series is pre requisite to this article and it highly recommended you go through it this series has parts part basic design and horizontal flipping part scaling and translation part rotation and shearing part baking augmentation into input pipelinesin this post we will implement couple of augmentations called scale and translate which obviously do what they mean scale the result of scale translation would look like left original image right scale augmentation applied design decisionsthe very first thing we need to think about is the parameters of the scale augmentation the obvious choice is to ask by what factor of the original image dimension we want it to scale the our image therefore it must be value greater than you can cannot scaling less than it own dimensions one can chose to maintain the aspect ratio by constraining the scaling factor to be the same for both height and width however we can allow the scale factors to differ which not only produces scaling augmentation but also changes the aspect ratio of the images we introduce boolean variable diff that can turn on off this functionality while implementing stochastic version of this augmentation we need sample scale factor randomly from interval the way we deal with it is that if the user can provide the range from which the scaling factor scale will be sampled if user provides only one float scale it must be positive and the scaling factor is sampled from scale scale let us now define the method class randomscale object randomly scales an image bounding boxes which have an area of less than in the remaining in the transformed image is dropped the resolution is maintained and the remaining area if any is filled by black color parameters scale float or tuple float if float the image is scaled by factor drawn randomly from range scale scale if tuple the scale is drawn randomly from values specified by the tuple returns numpy ndaaray scaled image in the numpy format of shape hxwxc numpy ndarray tranformed bounding box co ordinates of the format where is number of bounding boxes and represents of the box def self scale diff false self scale scale if type self scale tuple assert len self scale invalid range assert self scale scale factor can be less than assert self scale scale factor can be less than else assert self scale please input positive float self scale max self scale self scale self diff diffone of the takeaway lessons here is that shouldn sample the final parameter in function if you do sample the parameter in the function the same value of the parameter would be used every time you call function this takes away the stochastic element of augmentation moving it to the function will result in the parameter having different value from the range every time the augmentation is applied augmentation logicthe logic of the scale transformation is fairly simple we use the opencv function cv resize to scale our image and scale our bounding boxes by the scale factor img_shape img shape if self diff scale_x random uniform self scale scale_y random uniform self scale else scale_x random uniform self scale scale_y scale_x resize_scale_x scale_x resize_scale_y scale_y img cv resize img none fx resize_scale_x fy resize_scale_y bboxes resize_scale_x resize_scale_y resize_scale_x resize_scale_y however we will keep the size constant if we are going to scale down there would be remaining area we will color it black the output would look like the augmented image shown above first we start by creating black image of the size of our original image canvas np zeros img_shape dtype np uint then we determine the the size of our scaled image if it exceeds the dimensions of the original image we are scaling up then it needs to be cut off at the original dimensions we then paste the resized image on the canvas y_lim int min resize_scale_y img_shape x_lim int min resize_scale_x img_shape canvas y_lim x_lim img y_lim x_lim img canvasbounding box clippingthe only last thing which remains is the case an object is expelled from the image as result of the scaling for example consider scaling up by factor of which means the final image dimensions are the original image this expels the football from our image the football is expelled as result of scaling up think about it and one realises such scenario arises not only while scaling up but other augmentations like translation too therefore we define function clip_box in our helper file bbox_utils py which clips bounding boxes based on the percentage of their total area lying inside the boundaries of the image this percentage is controllable parameter in the file bbox_utils py define def clip_box bbox clip_box alpha clip the bounding boxes to the borders of an image parameters bbox numpy ndarray numpy array containing bounding boxes of shape where is the number of bounding boxes and the bounding boxes are represented in the format clip_box numpy ndarray an array of shape specifying the diagonal co ordinates of the image the coordinates are represented in the format alpha float if the fraction of bounding box left in the image after being clipped is less than alpha the bounding box is dropped returns numpy ndarray numpy array containing clipped bounding boxes of shape where is the number of bounding boxes left are being clipped and the bounding boxes are represented in the format ar_ bbox_area bbox x_min np maximum bbox clip_box reshape y_min np maximum bbox clip_box reshape x_max np minimum bbox clip_box reshape y_max np minimum bbox clip_box reshape bbox np hstack x_min y_min x_max y_max bbox delta_area ar_ bbox_area bbox ar_ mask delta_area alpha astype int bbox bbox mask return bboxthe function above modifies bboxes array and removes the bounding boxes which lose too much area as result of the augmentation we then simply use this function in the method of our randomscale to make sure all the boxes are clipped here we drop all those bounding boxes which have less than of their areas in confines of the image bboxes clip_box bboxes img_shape img_shape in order to compute the area of bounding box we also define function bbox_area finally our completed method looks like def self img bboxes chose random digit to scale by img_shape img shape if self diff scale_x random uniform self scale scale_y random uniform self scale else scale_x random uniform self scale scale_y scale_x resize_scale_x scale_x resize_scale_y scale_y img cv resize img none fx resize_scale_x fy resize_scale_y bboxes resize_scale_x resize_scale_y resize_scale_x resize_scale_y canvas np zeros img_shape dtype np uint y_lim int min resize_scale_y img_shape x_lim int min resize_scale_x img_shape print y_lim x_lim canvas y_lim x_lim img y_lim x_lim img canvas bboxes clip_box bboxes img_shape img_shape return img bboxestranslate the next augmentation we are going to cover is the translate which produces an effect like this again like the scale augmentation the parameter of the augmentation is the factor of the dimensions of the image by which the image should be translated the same design decisions apply in addition to making sure that the translate factor is not less than you should also make sure it isn greater than or else you re just gonna get black image since whole of the image will be shifted class randomtranslate object randomly translates the image bounding boxes which have an area of less than in the remaining in the transformed image is dropped the resolution is maintained and the remaining area if any is filled by black color parameters translate float or tuple float if float the image is translated by factor drawn randomly from range translate translate if tuple translate is drawn randomly from values specified by the tuple returns numpy ndaaray translated image in the numpy format of shape hxwxc numpy ndarray tranformed bounding box co ordinates of the format where is number of bounding boxes and represents of the box def self translate diff false self translate translate if type self translate tuple assert len self translate invalid range assert self translate self translate assert self translate self translate else assert self translate self translate self translate self translate self translate self diff of logicthe logic of this augmentation is whole lot trickier than scale so it deserves some explaination we first start by setting up our variables def self img bboxes chose random digit to scale by img_shape img shape translate the image percentage of the dimension of the image to translate random uniform self translate random uniform self translate if not self diff when we translate the image it leaves some trailing space we will color it black if you look at the image above demonstrating translation you can easily make out the black space we proceed as before we first initialise black image about the size of our original image canvas np zeros img_shape then we have two tasks first as shown in image one to determine which part of the black canvas the image will be pasted on second which part of the image will be pasted left the part of image which will be pasted right the area of canvas on which the image will be pasted so we first figure out the area of the image on which we will paste on the canvas image purple patch on the image left in the above image get the top left corner co ordinates of the shifted image corner_x int img shape corner_y int img shape mask img max corner_y min img shape corner_y img_shape max corner_x min img shape corner_x img_shape now let us get the portion of the canvas on which we paste max corner_y max corner_x min img_shape corner_y img shape min img_shape corner_x img shape canvas orig_box_cords orig_box_cords orig_box_cords orig_box_cords mask img canvas shifting boxes is relatively simple you simply need to offset the corners of the bounding boxes we also clip the bounding boxes that have less than of area inside the image as result of the augmentation bboxes corner_x corner_y corner_x corner_y bboxes clip_box bboxes img_shape img_shape to sum up our call function looks like this def self img bboxes chose random digit to scale by img_shape img shape translate the image percentage of the dimension of the image to translate random uniform self translate random uniform self translate if not self diff canvas np zeros img_shape astype np uint corner_x int img shape corner_y int img shape change the origin to the top left corner of the translated box orig_box_cords max corner_y max corner_x min img_shape corner_y img shape min img_shape corner_x img shape mask img max corner_y min img shape corner_y img_shape max corner_x min img shape corner_x img_shape canvas orig_box_cords orig_box_cords orig_box_cords orig_box_cords mask img canvas bboxes corner_x corner_y corner_x corner_y bboxes clip_box bboxes img_shape img_shape return img bboxestesting as detailed in the last example you can test these augmentations on the sample image or your own image provided you have stored the augmentation in the correct format from data_aug bbox_utils import import matplotlib pyplot as plt scale randomscale diff true translate randomtranslate diff true img bboxes translate img bboxes img bboxes scale img bboxes plt imshow draw_rect img bboxes the end result might look like this you can try doing scaling first and then translating you might find that the results for the same values of parameters are different can you explain it this is left as an exercise of the reader another exercise can be trying to implement the deterministic versions of the augmentations we ve implemented this is it for this part in the next part the augmentation will get bit more advance and bit more messier with rotation and shearing where we will be using the affine transformation features of opencv stay tuned ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more volta mixed precision training with nvidia volta quick overview of what is and what are the capabilities of mixed precision training with the nvidia gpu card volta is one of the latest gpu architectures developed by nvidia volta cristbal valenzuela min read tutorial generating an interactive pix pix model with gradient and ml js this post will go through the process of training generative image model using gradient and then porting the model to ml js so you can interact with it in the browser for cristbal valenzuela min read gradient introducing gradientci our new friendly ci cd bot for machine learning and ai pipelines update this post is out of date we recommend viewing the docs page which includes more info and step by step guide for getting started with gradientci we re excited to introduce gradientci our new dillon cristbal valenzuela min read machine learning creating your own style transfer mirror with gradient and ml js in this post we will learn how to train style transfer network with paperspace gradient and use the model in ml js to create an interactive style transfer mirror this post is cristbal valenzuela min read training an lstm network and sampling the resulting model in ml js in this post we will learn how to train language model using lstm neural network with your own custom dataset and use the resulting model inside ml js so you will cristbal valenzuela min read  january announcement introducing gradient low cost instances the public cloud was built first and foremost to enable companies to deliver web applications at scale fast forward decade and today the cloud is used for much more than that one of the most exciting use cases that has emerged is leveraging the vast computational power of the cloud to run high end workloads such as conducting scientific experiments or training deep neural networks these applications have much different usage pattern than traditional web services they are short lived and tend to run in batches to respond to this new behavior the concept of low priority instances commonly referred to as spot instances was created low priority instances are essentially spare capacity in the cloud that is offered at significant discount compared to the regular on demand price but with the caveat that if the capacity is needed for other tasks they may be interrupted we are happy to announce that gradient now supports this class of instance type which we are calling low cost instances low cost instances are discounted by as much as depending on the instance type to run notebook or job in low cost mode just add preemptible when using the cli or toggle the option in the interface low cost instances function like normal instances but differ in the following ways they can interrupted at any time even within the first few minutes they are always shut down after hours so they are not suitable for long running jobs they cannot be migrated to regular vm instance if your workloads are fault tolerant and can withstand possible interruptions then gradient low cost instances are great fit and can significantly reduce compute costs for example using checkpoints with tensorflow and pytorch will enable you to train deep learning models on gradient low cost instances without the risk of losing progress made before the instance was interrupted create an account or sign in try paperspace sign in for more details on gradient low cost instances please check out the help center for more pricing information take look at our gradient pricing page the ps engineering team discourseembed discourseurl https community paperspace com https blog paperspace com introducing gradient low cost instances function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild daniel kobran coo co founder paperspace read more september computer vision data augmentation for bounding boxes rotation and shearing mathjax hub config tex jax inlinemath processescapes true this is part of the series where we are looking at ways to adapt image augmentation techniques to object detection tasks in this part we will cover how to implement how to rotate and shear images as well as bounding boxes using opencv affine transformation features before you start it is highly recommended that you should have gone through the last two parts of the series because they form the basis of what we are going to do here github repoeverything from this article and the entire augmentation library can be found in the following github repo https github com paperspace documentation for this project can be found by opening the docs build html index html in your browser or at this link this series has parts part basic design and horizontal flipping part scaling and translation part rotation and shearing part baking augmentation into input pipelinesthis part assumes that you have read the above articles since we are going to use the functionality that has been introduced in the earlier articles let get going rotationthe results of rotation transformation look typically like thisrotation is one of the nastiest data augmentations to deal with soon you will know why before we get our hands dirty with the code like to define some terms here affine transformation transformation of an image such that parallel lines in an image remain parallel after the transformation scaling translation rotation are all examples of affine transformations in computer graphics we also use something called transformation matrix which is very handy tool to carry out affine transformations detailed discussion of the transformation matrix is not possible as it would take us away from our task so ve provided link at the end of the article where you can read more about it in the meantime think of the transformation matrix as matrix with which you multiply point co ordinates to produce the transformed point t_p the transformation matrix is matrix which is multiplied by where are co ordinates of the point the idea of having is to facilitate shearing and you can read more about it in the link below multipling matrix with matrix leaves us with matrix containing the new point co ordinates the transformation matrix can be also used to get the coordinates of point after rotation about the center of the image the transformation matrix for rotating point by theta looks like image source https cristianpb github io blog image rotation opencv scale is thankfully we won have to code it opencv already provides inbuilt functionality to do it using it cv warpaffine function so with the requisite theoretical knowledge behind us let get started we start by defining our function def self angle self angle angle if type self angle tuple assert len self angle invalid range else self angle self angle self angle rotating the imagenow the first thing we have to do is rotate our image by an angle theta about the centre for this we need our transformation matrix we use the opencv function for this image shape cx cy cv cx cy angle now we can get the rotate image simply by using the warpaffine function image cv warpaffine image the third argument to the function is which is so due to the fact that we want to maintain the original resolution but if you imagine bit rotated image will have different dimensions and if they exceed the original dimensions opencv will simply cut them here is an example opencv rotation side effect we lose some information here so how do we get past that thankfully opencv provides us with argument to the function that helps us determine the dimensions of the final image if we can change it from to dimension that will just accomodate our rotated image we are done the inspiration for this comes from post by adrian rosebrock over at his blog pyimagesearch now the question is how do we find this new dimensions little bit trigonometry can do the job for us precisely if you look at the following diagram image source https cristianpb github io blog image rotation opencvwhere n_w sin theta cos theta n_h cos theta sin theta so now we compute the new width and height note that we can get the values of sin theta and cos theta from the transformation matrix cos np abs sin np abs compute the new bounding dimensions of the image nw int sin cos nh int cos sin there something still missing one thing is sure that the center of the image does not move since it is the axis of rotation itself however since the width and height of image is now nw nh the center must lie at nw nh to make sure this happens we must translate the image by nw cx nh ch where cx ch are the previous centers adjust the rotation matrix to take into account translation nw cx nh cyto sum this up we put the code responsible for rotating an image in function rotate_im and place it in the bbox_util pydef rotate_im image angle rotate the image rotate the image such that the rotated image is enclosed inside the tightest rectangle the area not occupied by the pixels of the original image is colored black parameters image numpy ndarray numpy image angle float angle by which the image is to be rotated returns numpy ndarray rotated image grab the dimensions of the image and then determine the centre image shape cx cy grab the rotation matrix applying the negative of the angle to rotate clockwise then grab the sine and cosine the rotation components of the matrix cv cx cy angle cos np abs sin np abs compute the new bounding dimensions of the image nw int sin cos nh int cos sin adjust the rotation matrix to take into account translation nw cx nh cy perform the actual rotation and return the image image cv warpaffine image nw nh image cv resize image return imagerotating the bounding boxthis is the most challenging part of this augmentation here we first need to rotate the bounding box which gives us tilted rectangular box then we have to find the tightest rectangle parallel to the sides of the image containing the tilted rectangular box here is what mean final bounding box shown only for one image now in order to get the rotated bounding box as seen in the middle image we need to have all the coordinates for all the corners of box we could actually get the final bounding box using corners only but that would take more trigonometry to figure out the dimensions of the the final bounding box on the right in the image above in black using only corners with corners of the intermediate box in the middle it much easier to make that computation it only matter of making the code more complicated so first we write the function get_corners in the file bbox_utils py to get all the corners def get_corners bboxes get corners of bounding boxes parameters bboxes numpy ndarray numpy array containing bounding boxes of shape where is the number of bounding boxes and the bounding boxes are represented in the format returns numpy ndarray numpy array of shape containing bounding boxes each described by their corner co ordinates width bboxes bboxes reshape height bboxes bboxes reshape bboxes reshape bboxes reshape width height bboxes reshape bboxes reshape corners np hstack return corners after this is done now we have each bounding box being described by coordinates we now define the function rotate_box in the file bbox_util py which rotates the bounding boxes for us by giving us the transformed points we use the transformation matrix for this def rotate_box corners angle cx cy rotate the bounding box parameters corners numpy ndarray numpy array of shape containing bounding boxes each described by their corner co ordinates angle float angle by which the image is to be rotated cx int coordinate of the center of image about which the box will be rotated cy int coordinate of the center of image about which the box will be rotated int height of the image int width of the image returns numpy ndarray numpy array of shape containing rotated bounding boxes each described by their corner co ordinates corners corners reshape corners np hstack corners np ones corners shape dtype type corners cv cx cy angle cos np abs sin np abs nw int sin cos nh int cos sin adjust the rotation matrix to take into account translation nw cx nh cy prepare the vector to be transformed calculated np dot corners calculated calculated reshape return calculatednow the final thing is to define function which gets us the tightest box talked about def corners get an enclosing box for ratated corners of bounding box parameters corners numpy ndarray numpy array of shape containing bounding boxes each described by their corner co ordinates returns numpy ndarray numpy array containing enclosing bounding boxes of shape where is the number of bounding boxes and the bounding boxes are represented in the format x_ corners y_ corners xmin np min x_ reshape ymin np min y_ reshape xmax np max x_ reshape ymax np max y_ reshape final np hstack xmin ymin xmax ymax corners return finalthis once again gives us notation where each bounding box is determined by co ordinates or two corners using all these helper functions we finally put together our function def self img bboxes angle random uniform self angle img shape img shape cx cy img rotate_im img angle corners get_corners bboxes corners np hstack corners bboxes corners rotate_box corners angle cx cy new_bbox corners scale_factor_x img shape scale_factor_y img shape img cv resize img new_bbox scale_factor_x scale_factor_y scale_factor_x scale_factor_y bboxes new_bbox bboxes clip_box bboxes return img bboxesnotice at the end of function we rescale our image and the bounding boxes so that our final dimensions are and not nw nh this is just in line to preserve the dimensions of the image we also clip boxes in case any box may be out of the image after transformation shearing shearing is another bounding box transformation that can be done with the help of the transformation matrix the effect that shearing produces looks like in shearing we turn the rectangular image into umm sort of image the transformation matrix used in shearing is the above is an example of horizontal shear in this the pixel with coordinates is moved to alpha alpha is the shearing factor we therefore define our function as class randomshear object randomly shears an image in horizontal direction bounding boxes which have an area of less than in the remaining in the transformed image is dropped the resolution is maintained and the remaining area if any is filled by black color parameters shear_factor float or tuple float if float the image is sheared horizontally by factor drawn randomly from range shear_factor shear_factor if tuple the shear_factor is drawn randomly from values specified by the tuple returns numpy ndaaray sheared image in the numpy format of shape hxwxc numpy ndarray tranformed bounding box co ordinates of the format where is number of bounding boxes and represents of the box def self shear_factor self shear_factor shear_factor if type self shear_factor tuple assert len self shear_factor invalid range for scaling factor else self shear_factor self shear_factor self shear_factor shear_factor random uniform self shear_factor augmentation logic since we are only covering horizontal shear we only need to change the coordinates of the corners of the boxes according to the equation alpha our call function looks like def self img bboxes shear_factor random uniform self shear_factor img shape img shape if shear_factor img bboxes horizontalflip img bboxes np array abs shear_factor nw img shape abs shear_factor img shape bboxes bboxes abs shear_factor astype int img cv warpaffine img int nw img shape if shear_factor img bboxes horizontalflip img bboxes img cv resize img scale_factor_x nw bboxes scale_factor_x scale_factor_x return img bboxesan intriguing case is that of negative shear negative shear requires bit more hacking to work if we just shear using the case we do with positive shear our resultant boxes must be smaller this is because for equation to work the coordinates of the boxes must be in the format where is the corner which is further in the direction we are shearing this works in the case of positive shear because in our default setting is the bottom right corner coordinate while is the top left the direction of shear is positive or left to right when we use negative shear the direction of shear is right to left while is not further in the negative direction than one way to solve this could be to get the other set of corners that would satisfy the constraint can you prove it apply the shear transformation and then change to the other set of corners because of the notation we follow well we could do that but there better method here how how perform negative shear with shearing factor alpha flip the image and boxes horizontally apply the positive shear transformation with shearing factor alphaflip the image and boxes horizontally again prefer you to take piece of paper and pen to validate why the above methodology works for this reason you will see the two occurences of code lines in the above function which deal with negative shears if shear_factor img bboxes horizontalflip img bboxes testing it out now that we re done with rotate and shear augmentations it time to test them out from data_aug bbox_utils import import matplotlib pyplot as plt rotate randomrotate shear randomshear img bboxes rotate img bboxes img bboxes shear img bboxes plt imshow draw_rect img bboxes this is it for this part and we re almost done with our augmentations there only one little augmentation left resizing which more an input preprocessing step than augmentation in the next and the final part we will show you how you can quickly incorporate these augmentations in your deep learning input pipelines how to combine them multiple augmentations seamlessly and how to generate documentation exerciseshere are some of the things you can try on your own implement the deterministic versions of the above augmentations scaling and translation can also be implemented using the transformation matrix with much smaller code try to implement them using this way implement vertical shear further readingrotation in matrixrotate images correctly with opencv and python ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more may tutorial vectorization and broadcasting with pytorch the performance gains derived from running your machine learning code on gpu can be huge but gpus are optimized for code that needs to perform the same operation thousands of times in parallel therefore it important that we write our code that way too earlier this week was training some word embeddings recall that word embeddings are dense vectors that are supposed to capture word meaning and the distance cosine distance or euclidean distance between two word embeddings should be smaller if the words are similar in meaning wanted to evaluate the quality of my trained word embeddings by evaluating them against word similarity dataset like the stanford rare word similarity dataset word similarity datasets collect human judgments about the distance between words word similarity dataset for vocabulary can be represented as matrix where represents the similarity between words and needed to write some pytorch code that would compute the cosine similarity between every pair of embeddings thereby producing word embedding similarity matrix that could compare against here is my first attempt source we loop through the embeddings matrix and we compute the cosine similarity for every pair of embeddings and this gives us list of lists of floats we then use torch cat to convert each sublist into tensor and then we torch stack the entire list into single tensor okay so let see how this loopy code performs we ll generate random matrix of oo dimentional word embeddings and compute the cosine similarity matrix we re running this benchmark on one of paperspace powerful machines but quick glance at the output of nvidia smi shows gpu utilization at and top shows that the cpu is hard at work it is hours before the program terminates now we rewrite the function in vectorized form source quick performance test on the shows that this function takes only seconds to compute similarity matrix from dimensional embeddings let walk through the code the key idea is that we are breaking down the function into its component operations so that we can parallelize the computations instead of doing them sequentially the of two vectors is just the cosine of the angle between them first we matrix multiply with its transpose this results in num_embeddings num_embeddings matrix dot if you think about how matrix multiplication works multiply and then sum you ll realize that each dot now stores the dot product of and then we compute the magnitude of each embedding vector the denotes that we are computing the euclidean norm of each vector the tells pytorch that our embeddings matrix is laid out as num_embeddings and not num_embeddings norm is now row vector where norm we divide each dot by here we re exploiting something called broadcasting notice that we re dividing matrix num_embeddings num_embeddings by row vector num_embeddings without allocating more memory pytorch will broadcast the row vector down so that we can imagine we are dividing by matrix made up of num_embeddings rows each containing the original row vector the result is that each cell in our original matrix has now been divided by the magnitude of the embedding corresponding to its column number finally we divide by again we re using broadcasting but this time we re converting norm into column vector first so that broadcasting will copy columns instead of rows the result is that each cell is divided by the magnitude of the th embedding that it we ve computed matrix containing the pair wise cosine similarity between every pair of embeddings and derived massive performance gains from vectorization and broadcasting conclusion next time you re wondering why your machine learning code is running slowly even on gpu consider vectorizing any loopy code if you like to read more about the things we touched on in this blog post check out some of these links pytorch broadcasting semantics learning word embeddings with word vec problems with evaluation of word embeddings using word similarity tasks amin manna read more posts by this author read more tutorial build an ai to play dino run tutorial to build reinforcement learning model ravi munde min read april series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part image credits karol majek check out his yolo real time detection video here this is part of the tutorial on implementing yolo detector from scratch in the last part we implemented the layers used in yolo architecture and in this part we are going to implement the network architecture of yolo in pytorch so that we can produce an output given an image our objective will be to design the forward pass of the network the code for this tutorial is designed to run on python and pytorch it can be found in it entirety at this github repo this tutorial is broken into parts part understanding how yolo works part creating the layers of the network architecture part this one implementing the the forward pass of the network part objectness confidence thresholding and non maximum suppression part designing the input and the output pipelines prerequisites part and part of the tutorial basic working knowledge of pytorch including how to create custom architectures with nn module nn sequential and torch nn parameter classes working with images in pytorch defining the network as ve pointed out earlier we use nn module class to build custom architectures in pytorch let us define network for our detector in the darknet py file we add the following class class darknet nn module def self cfgfile super darknet self self blocks parse_cfg cfgfile self net_info self module_list create_modules self blocks here we have subclassed the nn module class and named our class darknet we initialize the network with members blocks net_info and module_list implementing the forward pass of the network the forward pass of the network is implemented by overriding the forward method of the nn module class forward serves two purposes first to calculate the output and second to transform the output detection feature maps in way that it can be processed easier such as transforming them such that detection maps across multiple scales can be concatenated which otherwise isn possible as they are of different dimensions def forward self cuda modules self blocks outputs we cache the outputs for the route layer forward takes three arguments self the input and cuda which if true would use gpu to accelerate the forward pass here we iterate over self blocks instead of self blocks since the first element of self blocks is net block which isn part of the forward pass since route and shortcut layers need output maps from previous layers we cache the output feature maps of every layer in dict outputs the keys are the the indices of the layers and the values are the feature maps as was the case with create_modules function we now iterate over module_list which contains the modules of the network the thing to notice here is that the modules have been appended in the same order as they are present in the configuration file this means we can simply run our input through each module to get our output write this is explained bit later for module in enumerate modules module_type module type convolutional and upsample layers if the module is convolutional or upsample module this is how the forward pass should work if module_type convolutional or module_type upsample self module_list route layer shortcut layer if you look the code for route layer we have to account for two cases as described in part for the case in which we have to concatenate two feature maps we use the torch cat function with the second argument as this is because we want to concatenate the feature maps along the depth in pytorch input and output of convolutional layer has the format the depth corresponding the the channel dimension elif module_type route layers module layers layers int for in layers if layers layers layers if len layers outputs layers else if layers layers layers map outputs layers map outputs layers torch cat map map elif module_type shortcut from_ int module from outputs outputs from_ yolo detection layer the output of yolo is convolutional feature map that contains the bounding box attributes along the depth of the feature map the attributes bounding boxes predicted by cell are stacked one by one along each other so if you have to access the second bounding of cell at then you will have to index it by map this form is very inconvenient for output processing such as thresholding by object confidence adding grid offsets to centers applying anchors etc another problem is that since detections happen at three scales the dimensions of the prediction maps will be different although the dimensions of the three feature maps are different the output processing operations to be done on them are similar it would be nice to have to do these operations on single tensor rather than three separate tensors to remedy these problems we introduce the function transforming the output the function lives in the file util py and we will import the function when we use it in forward of darknet class add the imports to the top of util py from import division import torch import torch nn as nn import torch nn functional as from torch autograd import variable import numpy as np import cv takes in parameters prediction our output inp_dim input image dimension anchors num_classes and an optional cuda flag def prediction inp_dim anchors num_classes cuda true function takes an detection feature map and turns it into tensor where each row of the tensor corresponds to attributes of bounding box in the following order here the code to do the above transformation batch_size prediction size stride inp_dim prediction size grid_size inp_dim stride bbox_attrs num_classes num_anchors len anchors prediction prediction view batch_size bbox_attrs num_anchors grid_size grid_size prediction prediction transpose contiguous prediction prediction view batch_size grid_size grid_size num_anchors bbox_attrs the dimensions of the anchors are in accordance to the height and width attributes of the net block these attributes describe the dimensions of the input image which is larger by factor of stride than the detection map therefore we must divide the anchors by the stride of the detection feature map anchors stride stride for in anchors now we need to transform our output according to the equations we discussed in part sigmoid the coordinates and the objectness score sigmoid the centre_x centre_y and object confidencce prediction torch sigmoid prediction prediction torch sigmoid prediction prediction torch sigmoid prediction add the grid offsets to the center cordinates prediction add the center offsets grid np arange grid_size np meshgrid grid grid x_offset torch floattensor view y_offset torch floattensor view if cuda x_offset x_offset cuda y_offset y_offset cuda x_y_offset torch cat x_offset y_offset repeat num_anchors view unsqueeze prediction x_y_offset apply the anchors to the dimensions of the bounding box log space transform height and the width anchors torch floattensor anchors if cuda anchors anchors cuda anchors anchors repeat grid_size grid_size unsqueeze prediction torch exp prediction anchors apply sigmoid activation to the the class scores prediction num_classes torch sigmoid prediction num_classes the last thing we want to do here is to resize the detections map to the size of the input image the bounding box attributes here are sized according to the feature map say if the input image was we multiply the attributes by or the stride variable prediction stride that concludes the loop body return the predictions at the end of the function return prediction detection layer revisited now that we have transformed our output tensors we can now concatenate the detection maps at three different scales into one big tensor notice this was not possible prior to our transformation as one cannot concatenate feature maps having different spatial dimensions but since now our output tensor acts merely as table with bounding boxes as it rows concatenation is very much possible an obstacle in our way is that we cannot initialize an empty tensor and then concatenate non empty of different shape tensor to it so we delay the initialization of the collector tensor that holds the detections until we get our first detection map and then concatenate to maps to it when we get subsequent detections notice the write line just before the loop in the function forward the write flag is used to indicate whether we have encountered the first detection or not if write is it means the collector hasn been initialized if it is it means that the collector has been initialized and we can just concatenate our detection maps to it now that we have armed ourselves with the function we write the code for handling detection feature maps in the forward function at the top of your darknet py file add the following import from util import then in the forward function elif module_type yolo anchors self module_list anchors get the input dimensions inp_dim int self net_info height get the number of classes num_classes int module classes transform data inp_dim anchors num_classes cuda if not write if no collector has been intialised detections write else detections torch cat detections outputs now simply return the detections return detections testing the forward pass here function that creates dummy input we will pass this input to our network before we write this function save this image into your working directory if you re on linux then type wget https github com ayooshkathuria pytorch yolo raw master dog cycle car png now define the function at the top of your darknet py file as follows def get_test_input img cv imread dog cycle car png img cv resize img resize to the input dimension img_ img transpose bgr rgb img_ img_ np newaxis add channel at for batch normalise img_ torch from_numpy img_ float convert to float img_ variable img_ convert to variable return img_ then we type the following code model darknet cfg yolov cfg inp get_test_input pred model inp torch cuda is_available print pred you will see an output like torch floattensor of size the shape of this tensor is the first dimension is the batch size which is simply because we have used single image for each image in batch we have table the row of each of this table represents bounding box bbox attributes objectness score and class scores at this point our network has random weights and will not produce the correct output we need to load weight file in our network we ll be making use of the official weight file for this purpose downloading the pre trained weights download the weights file into your detector directory grab the weights file from here or if you re on linux wget https pjreddie com media files yolov weights understanding the weights file the official weights file is binary file that contains weights stored in serial fashion extreme care must be taken to read the weights the weights are just stored as floats with nothing to guide us as to which layer do they belong to if you screw up there nothing stopping you to say load the weights of batch norm layer into those of convolutional layer since you re reading only floats there no way to discriminate between which weight belongs to which layer hence we must understand how the weights are stored first the weights belong to only two types of layers either batch norm layer or convolutional layer the weights for these layers are stored exactly in the same order as they appear in the configuration file so if convolutional is followed by shortcut block and then the shortcut block by another convolutional block you will expect file to contain the weights of the previous convolutional block followed by those of the latter when the batch norm layer appears in convolutional block there are no biases however when there no batch norm layer bias weights have to read from the file the following diagram sums up how the weight stores the weights loading weights let us write function load weights it will be member function of the darknet class it ll take one argument other than self the path of the weightsfile def load_weights self weightfile the first bytes of the weights file store int values which constitute the header of the file open the weights file fp open weightfile rb the first values are header information major version number minor version number subversion number images seen by the network during training header np fromfile fp dtype np int count self header torch from_numpy header self seen self header the rest of bits now represent the weights in the order described above the weights are stored as float or bit floats let load rest of the weights in np ndarray weights np fromfile fp dtype np float now we iterate over the weights file and load the weights into the modules of our network ptr for in range len self module_list module_type self blocks type if module_type is convolutional load weights otherwise ignore into the loop we first check whether the convolutional block has batch_normalise true or not based on that we load the weights if module_type convolutional model self module_list try batch_normalize int self blocks batch_normalize except batch_normalize conv model we keep variable called ptr to keep track of where we are in the weights array now if batch_normalize is true we load the weights as follows if batch_normalize bn model get the number of weights of batch norm layer num_bn_biases bn bias numel load the weights bn_biases torch from_numpy weights ptr ptr num_bn_biases ptr num_bn_biases bn_weights torch from_numpy weights ptr ptr num_bn_biases ptr num_bn_biases bn_running_mean torch from_numpy weights ptr ptr num_bn_biases ptr num_bn_biases bn_running_var torch from_numpy weights ptr ptr num_bn_biases ptr num_bn_biases cast the loaded weights into dims of model weights bn_biases bn_biases view_as bn bias data bn_weights bn_weights view_as bn weight data bn_running_mean bn_running_mean view_as bn running_mean bn_running_var bn_running_var view_as bn running_var copy the data to model bn bias data copy_ bn_biases bn weight data copy_ bn_weights bn running_mean copy_ bn_running_mean bn running_var copy_ bn_running_var if batch_norm is not true simply load the biases of the convolutional layer else number of biases num_biases conv bias numel load the weights conv_biases torch from_numpy weights ptr ptr num_biases ptr ptr num_biases reshape the loaded weights according to the dims of the model weights conv_biases conv_biases view_as conv bias data finally copy the data conv bias data copy_ conv_biases finally we load the convolutional layer weights at last let us load the weights for the convolutional layers num_weights conv weight numel do the same as above for weights conv_weights torch from_numpy weights ptr ptr num_weights ptr ptr num_weights conv_weights conv_weights view_as conv weight data conv weight data copy_ conv_weights we re done with this function and you can now load weights in your darknet object by calling the load_weights function on the darknet object model darknet cfg yolov cfg model load_weights yolov weights that is all for this part with our model built and weights loaded we can finally start detecting objects in the next part we will cover the use of objectness confidence thresholding and non maximum suppression to produce our final set of detections further reading pytorch tutorial reading binary files with numpy nn module nn parameter classes ayoosh kathuria is currently an intern at the defense research and development organization india where he is working on improving object detection in grainy videos when he not working he either sleeping or playing pink floyd on his guitar you can connect with him on linkedin or look at more of what he does at github ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more october gradient introducing gradientci our new friendly ci cd bot for machine learning and ai pipelines update this post is out of date we recommend viewing the docs page which includes more info and step by step guide for getting started with gradientci we re excited to introduce gradientci our new github integration that makes running your ml jobs easier than ever install on your private github repos here https github com apps gradientci how it works note this is an early release and is not ready for production yet gradientci is really new so it not fully featured yet if you are eager to test the bleeding edge here how you can try it today just like continuous integration build for webapps where you can test and deploy your code you can now run gradient job for very change in your github repo with gradientci for github you no longer need to manually run job for every git commit it all streamlined and automatic without adding any additional configuration install the gradientci app on your private repo go to https github com apps gradientci and configure access to private repo github will first allow you to select where you want to install gradientci if member of github organization it will prompt you to select either your personal account or the organization account the next step is to select the repositories you like the gradientci app to install on you don need to give us access to all of the organizations and repositories associated with your account and you can choose which individual repos you want gradientci to run on in your repo add paperspace config file if you have initialized your repo from the paperspace cli with paperspace project init your directory will already have ps_project folder in this folder is file called config json which includes the parameters for your job your repo should look something like this project directory ps_project config json main py run sh your config json should look something like this project paperspace nvidia smi container tensorflow tensorflow gpu command nvidia smi machinetype add an api key to your config json this is temporary step to try out gradientci today we normally don recommend putting your private api keys in to repo and this requirement will be removed soon important make sure your repo is private you don want your paperspace api key floating around the internet project dte nvidia smi container tensorflow tensorflow gpu command nvidia smi machinetype apikey abc add your api key here push some code with the gradientci bot configured every new push to your repo will run job in the future we will make this configurable so it only happens on pull requests or when you manually specify it once you git commit git push your job will start running your commits will be tagged with success message if the job is submitted or an error if there is any problem with your configuration conclusion we have some really exciting new tools coming soon to help build out production ml pipelines make sure to subscribe to our newsletter to be notified this post was collaboration between dillon cristbal valenzuela dillon ceo co founder paperspace more posts by dillon cristbal valenzuela read more posts by this author tutorial neural machine translation with tensorflow if you are fan of google translate or some other translation service do you ever wonder how these programs are able to make spot on translations from one language to another on par henry ansah fordjour min read series gradient descent with python part generic python implementation of gradient descent for nn optimization hello again in the series of tutorials for implementing generic gradient descent gd algorithm in python for optimizing parameters of artificial neural network ann in the backpropagation phase the gd implementation will ahmed fawzy gad min read tutorial unpaired image to image translation with cyclegan yann lecun director of ai research at facebook and professor at nyu described generative adversarial networks gans as the most interesting idea in machine learning in the last years since the invention henry ansah fordjour min read series gradient descent with python part generic python implementation of gradient descent for nn optimization hello again in the series of tutorials for implementing generic gradient descent gd algorithm in python for optimizing parameters of artificial neural network ann in the backpropagation phase the gd implementation will ahmed fawzy gad min read tutorial tensorflow in action tensorflow is one of the most popular frameworks used for deep learning projects and is approaching major new release tensorflow luckily we don have to wait for the official release alvin koontz min read series gradient descent with python part generic python implementation of gradient descent for nn optimization through series of tutorials the gradient descent gd algorithm will be implemented from scratch in python for optimizing parameters of artificial neural network ann in the backpropagation phase the gd implementation will ahmed fawzy gad min read deep learning building state of the art bacterial classifier with paperspace gradient and fast ai one of the great promises of deep learning is its applicability in wide variety of complex tasks recent years have seen an explosion in the number of fields deep learning has seen harsh sikka min read pytorch pytorch part understanding hooks in this post we cover debugging and visualisation in pytorch we go over pytorch hooks and how to use them to debug our backpass visualise activations and modify gradients ayoosh kathuria min read tutorial pytorch part memory management and using multiple gpus this article covers pytorch advanced gpu management features including how to multiple gpu for your network whether be it data or model parallelism we conclude with best practises for debugging memory error ayoosh kathuria min read tutorial pytorch part going deep with pytorch in this tutorial we dig deep into pytorch functionality and cover advanced tasks such as using different learning rates learning rate policies and different weight initialisations etc ayoosh kathuria min read pytorch pytorch part building your first neural network in this part we will implement neural network to classify cifar images we cover implementing the neural network data loading pipeline and decaying learning rate schedule ayoosh kathuria min read deep learning pytorch part understanding graphs automatic differentiation and autograd in this article we dive into how pytorch autograd engine performs automatic differentiation ayoosh kathuria min read tutorial convert full imagenet pre trained model from mxnet to pytorch currently there are many available deep learning frameworks for researchers and engineers to implement their desired deep models each deep learning framework has its own advantages and disadvantages for example tensorflow has amir hossein karami min read tutorial detecting and localizing pneumonia from chest ray scans with pytorch over the years we have seen very powerful models being built to distinguish between objects these models keep getting better in terms of performance and latency day by day but have we ever henry ansah fordjour min read deep learning going beyond torchvision models resnets densenets and inception networks are undoubtedly some of the most powerful models out there for performing image classification and object recognition these models have shown some promising results in the imagenet large henry ansah fordjour min read tutorial physics control tasks with deep reinforcement learning in this tutorial we will implement the paper continuous control with deep reinforcement learning published by google deepmind and presented as conference paper at icrl the networks will be implemented in antonio cappiello min read getting started practical guide to deep learning in months this post will give you detailed roadmap to learn deep learning and will help you get deep learning internships and full time jobs within months sudharshan chandra babu min read tutorial generating an interactive pix pix model with gradient and ml js this post will go through the process of training generative image model using gradient and then porting the model to ml js so you can interact with it in the browser for cristbal valenzuela min read series data augmentation data augmentation for bounding boxes rethinking image transforms for object detection how to adapt major image augmentation techniques for object detection purposes we also cover the implementation of horizontal flip augmentation ayoosh kathuria min read quilt reproducible machine learning with pytorch and quilt in this article we ll use quilt to transfer versioned training data to remote machine we ll start with the berkeley segmentation dataset package the dataset then train pytorch model for super resolution imaging aneesh karve min read tutorial build an ai to play dino run tutorial to build reinforcement learning model ravi munde min read tutorial vectorization and broadcasting with pytorch the performance gains derived from running your machine learning code on gpu can be huge but gpus are optimized for code that needs to perform the same operation thousands of times in amin manna min read gan building simple generative adversarial network gan using tensorflow generative adversarial networks or gans are one of the most active areas in deep learning research and development due to their incredible ability to generate synthetic results in this blog we will build out the basic intuition of gans through concrete example aadil hayat dillon min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part tutorial on building yolo detector from scratch detailing how to create the network architecture from configuration file load the weights and designing input output pipelines ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement your own yolo object detector from scratch in pytorch ayoosh kathuria min read gradient new gradient python sdk build out complex end to end machine learning pipelines with the new gradient python sdk dillon misha kutsovsky min read tutorial vectorization and broadcasting with pytorch the performance gains derived from running your machine learning code on gpu can be huge but gpus are optimized for code that needs to perform the same operation thousands of times in amin manna min read june series optimization intro to optimization in deep learning gradient descent image credits reilly media deep learning to large extent is really about solving massive nasty optimization problems neural network is merely very complicated function consisting of millions of parameters that represents mathematical solution to problem consider the task of image classification alexnet is mathematical function that takes an array representing rgb values of an image and produces the output as bunch of class scores by training neural networks we essentially mean we are minimising loss function the value of this loss function gives us measure how far from perfect is the performance of our network on given dataset the loss function let us for sake of simplicity let us assume our network has only two parameters in practice this number would be around billion but we ll still stick to the two parameter example throughout the post so as not drive ourselves nuts while trying to visualise things now the countour of very nice loss function may look like this contour of loss function why do say very nice loss function because loss function having contour like above is like santa it doesn exist however it still serves as decent pedagogical tool to get some of the most important ideas about gradient descent across the board so let get to it the and axes represent the values of the two weights the axis represents the value of the loss function for particular value of two weights our goal is to find the particular value of weight for which the loss is minimum such point is called minima for the loss function you have randomly initialized weights in the beginning so your neural network is probably behaving like drunk version of yourself classifying images of cats as humans such situation correspond to point on the contour where the network is performing badly and consequently the loss is high we need to find way to somehow navigate to the bottom of the valley to point where the loss function has minima so how do we do that gradient descent gradient descent when we initialize our weights we are at point in the loss landscape the first thing we do is to check out of all possible directions in the plane moving along which direction brings about the steepest decline in the value of the loss function this is the direction we have to move in this direction is given by the direction exactly opposite to the direction of the gradient the gradient the higher dimensional cousin of derivative gives us the direction with the steepest ascent to wrap your head around it consider the following figure at any point of our curve we can define plane that is tangential to the point in higher dimensions we can always define hyperplane but let stick to for now then we can have infinite directions on this plane out of them precisely one direction will give us the direction in which the function has the steepest ascent this direction is given by the gradient the direction opposite to it is the direction of steepest descent this is how the algorithm gets it name we perform descent along the direction of the gradient hence it called gradient descent now once we have the direction we want to move in we must decide the size of the step we must take the the size of this step is called the learning rate we must chose it carefully to ensure we can get down to the minima if we go too fast we might overshoot the minima and keep bouncing along the ridges of the valley without ever reaching the minima go too slow and the training might turn out to be too long to be feasible at all even if that not the case very slow learning rates make the algorithm more prone to get stuck in minima something we ll cover later in this post once we have our gradient and the learning rate we take step and recompute the gradient at whatever position we end up at and repeat the process while the direction of the gradient tells us which direction has the steepest ascent it magnitude tells us how steep the steepest ascent descent is so at the minima where the contour is almost flat you would expect the gradient to be almost zero in fact it precisely zero for the point of minima gradient descent in action using too large learning rate in practice we might never exactly reach the minima but we keep oscillating in flat region in close vicinity of the minima as we oscillate our this region the loss is almost the minimum we can achieve and doesn change much as we just keep bouncing around the actual minimum often we stop our iterations when the loss values haven improved in pre decided number say or iterations when such thing happens we say our training has converged or convergence has taken place common mistake let me digress for moment if you google for visualizations of gradient descent you ll probably see trajectory that starts from point and heads to minima just like the animation presented above however this gives you very inaccurate picture of what gradient descent really is the trajectory we take is entire confined to the plane the plane containing the weights as depicted in the above animation gradient descent doesn involve moving in direction at all this is because only the weights are the free parameters described by the and directions the actual trajectory that we take is defined in the plane as follows real gradient descent trajectory each point in the plane represents unique combination of weights and we want have sets of weights described by the minima basic equations the basic equation that describes the update rule of gradient descent is this update is performed during every iteration here is the weights vector which lies in the plane from this vector we subtract the gradient of the loss function with respect to the weights multiplied by alpha the learning rate the gradient is vector which gives us the direction in which loss function has the steepest ascent the direction of steepest descent is the direction exactly opposite to the gradient and that is why we are subtracting the gradient vector from the weights vector if imagining vectors is bit hard for you almost the same update rule is applied to every weight of the network simultaneously the only change is that since we are performing the update individually for each weight now the gradient in the above equation is replaced the the projection of the gradient vector along the direction represented by the particular weight this update is simultaneously done for all the weights before subtracting we multiply the gradient vector by the learning rate this represents the step that we talked about earlier realise that even if we keep the learning rate constant the size of step can change owing to changes in magnitude of the gradient ot the steepness of the loss contour as we approach minima the gradient approaches zero and we take smaller and smaller steps towards the minima in theory this is good since we want the algorithm to take smaller steps when it approaches minima having step size too large may cause it to overshoot minima and bounce between the ridges of the minima widely used technique in gradient descent is to have variable learning rate rather than fixed one initially we can afford large learning rate but later on we want to slow down as we approach minima an approach that implements this strategy is called simulated annealing or decaying learning rate in this the learning rate is decayed every fixed number of iterations challenges with gradient descent local minima okay so far the tale of gradient descent seems to be really happy one well let me spoil that for you remember when said our loss function is very nice and such loss functions don really exists they don first neural networks are complicated functions with lots of non linear transformations thrown in our hypothesis function the resultant loss function doesn look nice bowl with only one minima we can converge to in fact such nice santa like loss functions are called convex functions functions for which are always curving upwards and the loss functions for deep nets are hardly convex in fact they may look like this in the above image there exists local minima where the gradient is zero however we know that they are not the lowest loss we can achieve which is the point corresponding to the global minima now if you initialze your weights at point then you re gonna converge to the local minima and there no way gradient descent will get you out of there once you converge to the local minima gradient descent is driven by the gradient which will be zero at the base of any minima local minimum are called so since the value of the loss function is minimum at that point in local region whereas global minima is called so since the value of the loss function is minimum there globally across the entire domain the loss function only to make things worse the loss contours even may be more complicated given the fact that contours like the one we are considering never actually happen in practice in practice our neural network may have about give or take billion weights given us roughly billion dimensional function don even know the number of zeros in that figure in fact it even hard to visualize what such high dimensional function however given the sheer talent in the field of deep learning these days people have come up with ways to visualize the contours of loss functions in recent paper pioneers technique called filter normalization explaining which is beyond the scope of this post however it does give to us view of the underlying complexities of loss functions we deal with for example the following contour is constructed representation for loss contour of vgg deep network loss function on the cifar dataset complicated loss landscape image credits https www cs umd edu tomg projects landscapes as you can see the loss landscape is ridden with local minimum challenges with gradient descent saddle points the basic lesson we took away regarding the limitation of gradient descent was that once it arrived at region with gradient zero it was almost impossible for it to escape it regardless of the quality of the minima another sort of problem we face is that of saddle points which look like this saddle point you can also see saddle point in the earlier pic where two mountains meet saddle point gets it name from the saddle of horse with which it resembles while it minima in one direction it local maxima in another direction and if the contour is flatter towards the direction gd would keep oscillating to and fro in the direction and give us the illusion that we have converged to minima randomness to the rescue so how do we go about escaping local minima and saddle points while trying to converge to global minima the answer is randomness till now we were doing gradient descent with the loss function that had been created by summing loss over all possible examples of the training set if we get into local minima or saddle point we are stuck way to help gd escape these is to use what is called stochastic gradient descent in stochastic gradient descent instead of taking step by computing the gradient of the loss function creating by summing all the loss functions we take step by computing the gradient of the loss of only one randomly sampled without replacement example in contrast to stochastic gradient descent where each example is stochastically chosen our earlier approach processed all examples in one single batch and therefore is known as batch gradient descent the update rule is modified accordingly update rule for stochastic gradient descent this means at every step we are taking the gradient of loss function which is different from our actual loss function which is summation of loss of every example the gradient of this one example loss at particular may actually point in direction slighly different to the gradient of all example loss this also means that while the gradient of the all example loss may push us down local minima or get us stuck at saddle point the gradient of one example loss might point in different direction and might help us steer clear of these one could also consider point that is local minima for the all example loss if we re doing batch gradient descent we will get stuck here since the gradient will always point to the local minima however if we are using stochastic gradient descent this point may not lie around local minima in the loss contour of the one example loss allowing us to move away from it even if we get stuck in minima for the one example loss the loss landscape for the one example loss for the next randomly sampled data point might be different allowing us to keep moving when it does converge it converges to point that is minima for almost all the one example losses it also been emperically shown the saddle points are extremely unstable and slight nudge may be enough to escape one so does this mean in practice should be always perform this one example stochastic gradient descent batch size the answer is no though from theoretical standpoint stochastic gradient descent might give us the best results it not very viable option from computational stand point when we perform gradient descent with loss function that is created by summing all the individual losses the gradient of the individual losses can be calculated in parallel whereas it has to calculated sequentially step by step in case of stochastic gradient descent so what we do is balancing act instead of using the entire dataset or just single example to construct our loss function we use fixed number of examples say or to form what is called mini batch the word is used in contrast with processing all the examples at once which is generally called batch gradient descent the size of the mini batch is chosen as to ensure we get enough stochasticity to ward off local minima while leveraging enough computation power from parallel processing local minima revisited they are not as bad as you think before you antagonise local minima recent research has shown that local minima is not neccasarily bad in the loss landscape of neural network there are just way too many minimum and good local minima might perform just as well as global minima why do say good because you could still get stuck in bad local minima which are created as result of erratic training examples good local minima or often referred to in literature as optimal local minima can exist in considerable numbers given neural network high dimensional loss function it might also be noted that lot of neural networks perform classification if local minima corresponds to it producing scores between for the correct labels while the global minima has it producing scores between for the correct labels for same examples the output class prediction is going to be same for both desirable property of minima should be it that it should be on the flatter side why because flat minimum are easy to converge to given there less chance to overshoot the minima and be bouncing between the ridges of the minima more importantly we expect the loss surface of the test set to be slightly different from that of the training set on which we do our training for flat and wide minima the loss won change much due to this shift but this is not the case for narrow minima the point that we are trying to make is flatter minima generalise better and are thus desirable learning rate revisited recently there has been surge in research on learning rate scheduling to account for sub optimal minima in the loss landscape even with decaying learning rate one can get stuck in local minima traditionally either the training is done for fixed number of iterations or it can be stopped after say iterations after the loss doesn improve this has been called early stopping in literature having fast learning rate also helps us scoot over local minimum earlier in training people have also combined early stopping with learning rate decay where learning rate is decayed after every time the loss fails to improve after iterations eventually stopping after the rate is below some decided threshold in recent years cyclic learning rates have become popular in which the learning rate is slowly increased and then decreased and this is continued in cyclic fashion triangular and triangular methods for cycling learning rate proposed by leslie smith on the left plot min and max lr are kept the same on the right the difference is cut in half after each cycle image credits hafidz zulkifli something called stochastic gradient descent with warm restarts basically anneals the learning rate to lower bound and then restores the learning rate to it original value we also have different schedules as to how the learning rates decline from exponential decay to cosine decay cosine annealing combined with restarts very recent paper introduces technique called stochastic weight averaging the authors develop an approach where they first converge to minima cache the weights and then restore the learning rate to higher value this higher learning rate then propels the algorithm out of the minima to random point in the loss surface then the algorithm is made to converge again to another minima this is repeated for few times finally they average the predictions made by all the set of cached weights to produce the final prediction technique called stochastic weight averaging conclusion so this was the introductory post on gradient descent that has been the working horse for deep learning optimization since the seminal paper on backpropogation that showed you could train neural nets by computing gradients however there still one missing block about gradient descent that we haven talked about in this post and that is addressing the problem of pathological curvature extensions to vanilla stochastic gradient descent like momentum rmsprop and adam are used to overcome that vital problem however think whatever we have done is enough for one post and the rest of it will be covered in another post further reading visual loss landscapes for neural nets paper brilliant article on learning rate schedules by hafidz zulkifli stochastic weight averaging paper discourseembed discourseurl https community paperspace com https blog paperspace com intro to optimization in deep learning gradient descent function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more april series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part image credits karol majek check out his yolo real time detection video here this is part of the tutorial on implementing yolo detector from scratch in the last part explained how yolo works and in this part we are going to implement the layers used by yolo in pytorch in other words this is the part where we create the building blocks of our model the code for this tutorial is designed to run on python and pytorch it can be found in it entirety at this github repo this tutorial is broken into parts part understanding how yolo works part this one creating the layers of the network architecture part implementing the the forward pass of the network part objectness confidence thresholding and non maximum suppression part designing the input and the output pipelines prerequisites part of the tutorial knowledge of how yolo works basic working knowledge of pytorch including how to create custom architectures with nn module nn sequential and torch nn parameter classes assume you have had some experiene with pytorch before if you re just starting out recommend you to play around with the framework bit before returning to this post getting started first create directory where the code for detector will live then create file darknet py darknet is the name of the underlying architecture of yolo this file will contain the code that creates the yolo network we will supplement it with file called util py which will contain the code for various helper functions save both of these files in your detector folder you can use git to keep track of the changes configuration file the official code authored in uses configuration file to build the network the cfg file describes the layout of the network block by block if you re coming from caffe background it equivalent to protxt file used to describe the network we will use the official cfg file released by the author to build our network download it from here and place it in folder called cfg inside your detector directory if you re on linux cd into your network directory and type mkdir cfg cd cfg wget https raw com pjreddie darknet master cfg yolov cfg if you open the configuration file you will see something like this convolutional batch_normalize filters size stride pad activation leaky convolutional batch_normalize filters size stride pad activation leaky convolutional batch_normalize filters size stride pad activation leaky shortcut from activation linear we see blocks above out of them describe convolutional layers followed by shortcut layer shortcut layer is skip connection like the one used in resnet there are types of layers that are used in yolo convolutional convolutional batch_normalize filters size stride pad activation leaky shortcut shortcut from activation linear shortcut layer is skip connection akin to the one used in resnet the from parameter is which means the output of the shortcut layer is obtained by adding feature maps from the previous and the rd layer backwards from the shortcut layer upsample upsample stride upsamples the feature map in the previous layer by factor of stride using bilinear upsampling route route layers route layers the route layer deserves bit of explanation it has an attribute layers which can have either one or two values when layers attribute has only one value it outputs the feature maps of the layer indexed by the value in our example it is so the layer will output feature map from the th layer backwards from the route layer when layers has two values it returns the concatenated feature maps of the layers indexed by it values in our example it is and the layer will output feature maps from the previous layer and the st layer concatenated along the depth dimension yolo yolo mask anchors classes num jitter ignore_thresh truth_thresh random yolo layer corresponds to the detection layer described in part the anchors describes anchors but only the anchors which are indexed by attributes of the mask tag are used here the value of mask is which means the first second and third anchors are used this make sense since each cell of the detection layer predicts boxes in total we have detection layers at scales making up for total of anchors net net testing batch subdivisions training batch subdivisions width height channels momentum decay angle saturation exposure hue there another type of block called net in the cfg but wouldn call it layer as it only describes information about the network input and training parameters it isn used in the forward pass of yolo however it does provide us with information like the network input size which we use to adjust anchors in the forward pass parsing the configuration file before we begin add the necessary imports at the top of the darknet py file from import division import torch import torch nn as nn import torch nn functional as from torch autograd import variable import numpy as np we define function called parse_cfg which takes the path of the configuration file as the input def parse_cfg cfgfile takes configuration file returns list of blocks each blocks describes block in the neural network to be built block is represented as dictionary in the list the idea here is to parse the cfg and store every block as dict the attributes of the blocks and their values are stored as key value pairs in the dictionary as we parse through the cfg we keep appending these dicts denoted by the variable block in our code to list blocks our function will return this block we begin by saving the content of the cfg file in list of strings the following code performs some preprocessing on this list file open cfgfile lines file read split store the lines in list lines for in lines if len get read of the empty lines lines for in lines if get rid of comments lines rstrip lstrip for in lines get rid of fringe whitespaces then we loop over the resultant list to get blocks block blocks for line in lines if line this marks the start of new block if len block if block is not empty implies it is storing values of previous block blocks append block add it the blocks list block re init the block block type line rstrip else key value line split block key rstrip value lstrip blocks append block return blocks creating the building blocks now we are going to use the list returned by the above parse_cfg to construct pytorch modules for the blocks present in the config file we have types of layers in the list mentioned above pytorch provides pre built layers for types convolutional and upsample we will have to write our own modules for the rest of the layers by extending the nn module class the create_modules function takes list blocks returned by the parse_cfg function def create_modules blocks net_info blocks captures the information about the input and pre processing module_list nn modulelist prev_filters output_filters before we iterate over list of blocks we define variable net_info to store information about the network nn modulelist our function will return nn modulelist this class is almost like normal list containing nn module objects however when we add nn modulelist as member of nn module object when we add modules to our network all the parameters of nn module objects modules inside the nn modulelist are added as parameters of the nn module object our network which we are adding the nn modulelist as member of as well when we define new convolutional layer we must define the dimension of it kernel while the height and width of kernel is provided by the cfg file the depth of the kernel is precisely the number of filters or depth of the feature map present in the previous layer this means we need to keep track of number of filters in the layer on which the convolutional layer is being applied we use the variable prev_filter to do this we initialise this to as the image has filters corresponding to the rgb channels the route layer brings possibly concatenated feature maps from previous layers if there convolutional layer right in front of route layer then the kernel is applied on the feature maps of previous layers precisely the ones the route layer brings therefore we need to keep track of the number of filters in not only the previous layer but each one of the preceding layers as we iterate we append the number of output filters of each block to the list output_filters now the idea is to iterate over the list of blocks and create pytorch module for each block as we go for index in enumerate blocks module nn sequential check the type of block create new module for the block append to module_list nn sequential class is used to sequentially execute number of nn module objects if you look at the cfg you will realize block may contain more than one layer for example block of type convolutional has batch norm layer as well as leaky relu activation layer in addition to convolutional layer we string together these layers using the nn sequential and it the add_module function for example this is how we create the convolutional and the upsample layers if type convolutional get the info about the layer activation activation try batch_normalize int batch_normalize bias false except batch_normalize bias true filters int filters padding int pad kernel_size int size stride int stride if padding pad kernel_size else pad add the convolutional layer conv nn conv prev_filters filters kernel_size stride pad bias bias module add_module conv_ format index conv add the batch norm layer if batch_normalize bn nn batchnorm filters module add_module batch_norm_ format index bn check the activation it is either linear or leaky relu for yolo if activation leaky activn nn leakyrelu inplace true module add_module leaky_ format index activn if it an upsampling layer we use bilinear dupsampling elif type upsample stride int stride upsample nn upsample scale_factor mode bilinear module add_module upsample_ format index upsample route layer shortcut layers next we write the code for creating the route and the shortcut layers if it is route layer elif type route layers layers split start of route start int layers end if there exists one try end int layers except end positive anotation if start start start index if end end end index route emptylayer module add_module route_ format index route if end filters output_filters index start output_filters index end else filters output_filters index start shortcut corresponds to skip connection elif type shortcut shortcut emptylayer module add_module shortcut_ format index shortcut the code for creating the route layer deserves fair bit of explanation at first we extract the the value of the layers attribute cast it into an integer and store it in list then we have new layer called emptylayer which as the name suggests is just an empty layer route emptylayer it is defined as class emptylayer nn module def self super emptylayer self wait an empty layer now an empty layer might seem weird given it does nothing the route layer just like any other layer performs an operation bringing forward previous layer concatenation in pytorch when we define new layer we subclass nn module and write the operation the layer performs in the forward function of the nn module object for designing layer for the route block we will have to build nn module object that is initialized with values of the attribute layers as it member then we can write the code to concatenate bring forward the feature maps in the forward function finally we then execute this layer in th forward function of our network but given the code of concatenation is fairly short and simple calling torch cat on feature maps designing layer as above will lead to unnecessary abstraction that just increases boiler plate code instead what we can do is put dummy layer in place of proposed route layer and then perform the concatenation directly in the forward function of the nn module object representing darknet if the last line doesn make lot of sense to you suggest you to read how nn module class is used in pytorch link at the bottom the convolutional layer just in front of route layer applies it kernel to possibly concatenated feature maps from previous layers the following code updates the filters variable to hold the number of filters outputted by route layer if end if we are concatenating maps filters output_filters index start output_filters index end else filters output_filters index start the shortcut layer also makes use of an empty layer for it also performs very simple operation addition there is no need to update update the filters variable as it merely adds feature maps of previous layer to those of layer just behind yolo layer finally we write the code for creating the the yolo layer yolo is the detection layer elif type yolo mask mask split mask int for in mask anchors anchors split anchors int for in anchors anchors anchors anchors for in range len anchors anchors anchors for in mask detection detectionlayer anchors module add_module detection_ format index detection we define new layer detectionlayer that holds the anchors used to detect bounding boxes the detection layer is defined as class detectionlayer nn module def self anchors super detectionlayer self self anchors anchors at the end of the loop we do some bookkeeping module_list append module prev_filters filters output_filters append filters that concludes the body of the loop at the end of the function create_modules we return tuple containing the net_info and module_list return net_info module_list testing the code you can test your code by typing the following lines at the end of darknet py and running the file blocks parse_cfg cfg yolov cfg print create_modules blocks you will see long list exactly containing items the elements of which will look like sequential conv_ conv kernel_size stride bias false batch_norm_ batchnorm eps momentum affine true leaky_ leakyrelu inplace sequential conv_ conv kernel_size stride padding bias false batch_norm_ batchnorm eps momentum affine true leaky_ leakyrelu inplace sequential shortcut_ emptylayer that it for this part in this next part we will assemble the building blocks that we ve created to produce output from an image further reading pytorch tutorial nn module nn parameter classes nn modulelist and nn sequential ayoosh kathuria is currently an intern at the defense research and development organization india where he is working on improving object detection in grainy videos when he not working he either sleeping or playing pink floyd on his guitar you can connect with him on linkedin or look at more of what he does at github ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more july earn gpu credit to write about ml ai data science for paperspace tldr get paid to write articles about machine learning data science and more at paperspace we are working to build out new community resource to help people learn more about ml and related topics we want to provide valuable platform and combine that with the tools and resources needed to develop and run complex machine learning applications in the cloud if you have been following this blog we have some amazing posts on everything from style transfer to adversarial autoencoders with pytorch as we continue to grow this repository of information we are eager to help the ml ai data science community coalesce around best practices new methodologies techniques used by professionals and practitioners to solve real problems in particular we are looking for articles on such topics as framework comparisons tooling setup beginner getting started guides data handling toolset overviews profiling benchmarking writeups technical deep dives tools techniques the amount of gpu credit for free use of our gpus will correspond with the complexity and length of each article apply today dillon ceo co founder paperspace read more gan building simple generative adversarial network gan using tensorflow generative adversarial networks or gans are one of the most active areas in deep learning research and development due to their incredible ability to generate synthetic results in this blog we will build out the basic intuition of gans through concrete example aadil hayat dillon min read april series dimension reduction sne this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle sne isomap autoencoders more mathematical notebook with code is available the github repo sne is new award winning technique for dimension reduction and data visualization sne not only captures the local structure of the higher dimension but also preserves the global structures of the data like clusters it has stunning ability to produce well defined segregated clusters sne is based on stochastic neighbor embedding sne sne was developed to address some of the problems in sne so let have basic understanding of sne sne stochastic neighbor embedding uses probabilistic approach to embed high dimension dataset into lower dimension by preserving the neighborhood structure of the dataset gaussian probability distribution centered on each point is defined over all the potential neighbors of this point sne aims to minimize the difference in probability distribution in the higher dimension and lower dimension for each object and it neighbor we compute pi which reflects the probability that is neighbor of pi exp ij kiexp ij where ij is the dissimilarity between element and given as input or calculated from the dataset provided the dissimilarity between xi and xj can be calculated using the following formula ij xixj where generally calculated through binary search by equating the entropy of the distribution centered at xi to perplexity which is chosen by hand this method generates probability matrix which is asymmetric now random solution is chosen as the starting point for the low dimensional embedding probability distribution is defined on it in the same way as done above but with constant for all points sne tries to minimize the difference between these two distributions we can calculate the difference between two distributions using kullback liebler divergence for two discrete distirbution and kl divergence is given by dkl ipi pi qi sne defines cost function based of the difference between pij and qij which is given by ij pijlog pij qij while embedding the dataset in lower dimension two kinds of error can occur first neighbors are mapped as faraway points pij is large and qij is small and points which are far away mapped as neighbors pij is small while qij is large look closely at the cost function the cost of the first kind of error mapping large pij with small qij is smaller than the cost while mapping small pij as large qij sne heavily penalizes if the neighbors are mapped faraway from each other some of the shortcomings of sne approach are asymmetric probability matrix crowding problem as pointed out earlier the probability matrix is asymmetric suppose point xi is far away from other points it pij will be very small for all so it will have little effect on the cost function and embedding it correctly in the lower dimension will be hard any dimensional euclidean space can have an object with or less equidistant vertices not more than that now when the intrinsic dimension of dataset is high say and we are reducing its dimensions from to or our solution will be affected by crowding problem the amount of space available to map close points in or dimensions will always be greater than the space available in or dimensions in order to map close points properly moderately distant points will be pushed too far this will eat the gaps in original clusters and it will look like single giant cluster we need to brush up few more topics before we move to sne student distribution student distribution is continuous symmetric probability distribution function with heavy tails it has only one parameter degree of freedom as the degree of freedom increases it approaches the normal distribution function when degree of freedom it takes the form of cauchy distribution function and its probability density function is given by entropy entrophy is measure of the average information contained in data for variable with pdf it is given by xi log xi perpexility in information theory perplexity measures how good probability distribution predicts sample low perplexity indicates that distribution function is good at predicting sample it is given by perpx where is the entropy of the distribution sne sne differs from sne in two ways first it uses student distribution to measure the similarity between points yi and yj in the lower dimension secondly for the higher dimension it uses symmetric probability distribution such that pji pij steps of sne algorithm compute pairwise similarity pij for every and make pij symmetric choose random solution while not done compute pairwise similairites for yi compute the gradient update the solution if max_iter break else computing probability distribution for computing pairwise similarities we need to know the variance for the gaussian centered at xi one might think why not set single value of for every xi the density of data is likely to vary we need smaller for places with higher densities and bigger for places where points are far away the entropy of the gaussian distribution centered at xi increases as increases to get the we need to perform binary search such that perplexity of the gaussian distribution centered at xi is equal to the perplexity specified by the user now if you are thinking how perplexity fits into all this you can think of perplexity as measure of the number of neighbors impact of parameters on embedding for sne to be meaningful we have to choose right value of perplexity perplexity balances the local and global aspects of the dataset very high value will lead to the merging of clusters into single big cluster and low will produce many close small clusters which will be meaningless images below show the effect of perplexity on sne on iris dataset when number of neighbors sne produces many small clusters this will create problems when number of classes is high as the number of neighbors increases the clusters from same classes merge at and we have well defined clusters for few classes also the clusters become denser as the increases plot of subset of mnist dataset after sne embedding sne produces well defined and separate cluster for each of the digits drawbacks of sne problems with sne arise when intrinsic dimensions are higher more than dimensions sne has the tendency to get stuck in local optima like other gradient descent based algorithms the basic sne algorithm is slow due to nearest neighbor search queries conclusion we talked about another dimension reduction and visualization method sne through this post in the beginning we discussed important topics related to sne afterwards basic sne was implemented using pyspark there are few extensions of basic sne which improve the time complexity of the algorithm people who wish delve deeper into this topic barnes hut sne would be good starting point in next post we will learn about isomap ashwini kumar pal read more posts by this author read more announcement introducing the next iteration of gradient run on prem in your cloud or hybrid update this launch was featured in techcrunch over the last few years we ve fielded countless requests to run gradient our mlops saas platform on existing infrastructure ranging from local bare metal servers to dillon min read gradient new gradient python sdk build out complex end to end machine learning pipelines with the new gradient python sdk dillon misha kutsovsky min read announcement multinode distributed training new github app and more introducing gradientci powerful new way to train and deploy machine learning models from github add superpowers to your ml workflow dillon daniel parker jared scheib min read gradient gradient update gradient has been updated in response to ton of feedback from the community here roundup of some of the things we ve added recently new system custom metrics now whenever you dillon min read ci cd ci cd for machine learning ai the ecosystem for developing modern web applications is incredibly rich there are countless tools for delivering modern web app to production monitoring it performance and deploying in real time these tools are so dillon min read gradient introducing gradientci our new friendly ci cd bot for machine learning and ai pipelines update this post is out of date we recommend viewing the docs page which includes more info and step by step guide for getting started with gradientci we re excited to introduce gradientci our new dillon cristbal valenzuela min read gradient gradient update gradient has been updated in response to ton of feedback from the community here roundup of some of the things we ve added recently product release notes can be found here and dillon min read gan building simple generative adversarial network gan using tensorflow generative adversarial networks or gans are one of the most active areas in deep learning research and development due to their incredible ability to generate synthetic results in this blog we will build out the basic intuition of gans through concrete example aadil hayat dillon min read machine learning hands on with the googletpuv googles tensor procesing unit tpu has been making splash in the ml ai community for lot of good reasons currently training deep learning models takes an enormous amount of computing dillon min read machine learning what every ml ai developer should know aboutonnx the open neural network exchange format onnyx is new standard for exchanging deep learning models it promises to make deep learning models portable thus preventing vendor lock in lets look at dillon min read machine learning tesla available today paperspace is the first cloud provider to offer nvidia volta the worlds most powerful gpu we got first glimpse at the new volta line of gpu at gtc this year dillon min read data science jupyter notebooks the easy way with gpu support create paperspace gpu machine you can choose any of our gpu types gpu for this tutorial we are just going to pick the default ubuntu base template dillon min read earn gpu credit to write about ml ai data science for paperspace tldr get paid to write articles about machine learning data science and more at paperspace we are working to build out new community resource to help people learn more about ml and dillon min read enterprise paperspace public launch paperspace for teams we are excited to finally announce the general availability of paperspace starting today anyone can sign up for cloud computer by going to www paperspace com and creating an account when we dillon min read features new video tutorial using snapshots snapshots are one of the many benefits of using virtual machines the ability take snapshot of running machine and instantly rollback any time is invaluable check out our quick guide on dillon min read features new feature advanced settings panel starting today all paperspace users can access an advanced menu and have even greater control over their streaming performance starting today there are two available settings full color and multi monitor and we intend to dillon min read vdi netflix of computers interview with technical ly bk but we can do better than that and last week talked to the cofounder of an exciting brooklyn cloud computing company thats trying to reconceptualize the way we use computers the dillon min read press release press release public cloud expansion with coresite http www coresite com about news events press releases paperspace expands public cloud with coresite paperspace expands public cloud with coresite denver cojune coresite realty corporation nyse cor premier provider of secure reliable high performance data center dillon min read video new video tutorials creating vms and using templates dillon min read features new feature machine templates starting today paperspace for teams accounts can create templates from their machines with this feature team owner can configure machine with custom software and settings and then spawn as many machines dillon min read features new feature factor auth we are excited to announce that two factor is now possible on all paperspace accounts as part of our ongoing efforts to make your paperspace experience as secure as possible we have been listening dillon min read hello yc we are excited to annouce that we are joining ther winter batch at ycombinator we have lot of work to do but know that we will be surrounded by some of dillon min read april series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part image credits karol majek check out his yolo real time detection video here object detection is domain that has benefited immensely from the recent developments in deep learning recent years have seen people develop many algorithms for object detection some of which include yolo ssd mask rcnn and retinanet object detection is domain that has benefited immensely from the recent developments in deep learning recent years have seen people develop many algorithms for object detection some of which include yolo ssd mask rcnn and retinanet for the past few months ve been working on improving object detection at research lab one of the biggest takeaways from this experience has been realizing that the best way to go about learning object detection is to implement the algorithms by yourself from scratch this is exactly what we ll do in this tutorial we will use pytorch to implement an object detector based on yolo one of the faster object detection algorithms out there the code for this tutorial is designed to run on python and pytorch it can be found in it entirety at this github repo this tutorial is broken into parts part this one understanding how yolo works part creating the layers of the network architecture part implementing the the forward pass of the network part objectness score thresholding and non maximum suppression part designing the input and the output pipelines prerequisites you should understand how convolutional neural networks work this also includes knowledge of residual blocks skip connections and upsampling what is object detection bounding box regression iou and non maximum suppression basic pytorch usage you should be able to create simple neural networks with ease ve provided the link at the end of the post in case you fall short on any front what is yolo yolo stands for you only look once it an object detector that uses features learned by deep convolutional neural network to detect an object before we get out hands dirty with code we must understand how yolo works fully convolutional neural network yolo makes use of only convolutional layers making it fully convolutional network fcn it has convolutional layers with skip connections and upsampling layers no form of pooling is used and convolutional layer with stride is used to downsample the feature maps this helps in preventing loss of low level features often attributed to pooling being fcn yolo is invariant to the size of the input image however in practice we might want to stick to constant input size due to various problems that only show their heads when we are implementing the algorithm big one amongst these problems is that if we want to process our images in batches images in batches can be processed in parallel by the gpu leading to speed boosts we need to have all images of fixed height and width this is needed to concatenate multiple images into large batch concatenating many pytorch tensors into one the network downsamples the image by factor called the stride of the network for example if the stride of the network is then an input image of size will yield an output of size generally stride of any layer in the network is equal to the factor by which the output of the layer is smaller than the input image to the network interpreting the output typically as is the case for all object detectors the features learned by the convolutional layers are passed onto classifier regressor which makes the detection prediction coordinates of the bounding boxes the class label etc in yolo the prediction is done by using convolutional layer which uses convolutions now the first thing to notice is our output is feature map since we have used convolutions the size of the prediction map is exactly the size of the feature map before it in yolo and it descendants the way you interpret this prediction map is that each cell can predict fixed number of bounding boxes though the technically correct term to describe unit in the feature map would be neuron calling it cell makes it more intuitive in our context depth wise we have entries in the feature map represents the number of bounding boxes each cell can predict according to the paper each of these bounding boxes may specialize in detecting certain kind of object each of the bounding boxes have attributes which describe the center coordinates the dimensions the objectness score and class confidences for each bounding box yolo predicts bounding boxes for every cell you expect each cell of the feature map to predict an object through one of it bounding boxes if the center of the object falls in the receptive field of that cell receptive field is the region of the input image visible to the cell refer to the link on convolutional neural networks for further clarification this has to do with how yolo is trained where only one bounding box is responsible for detecting any given object first we must ascertain which of the cells this bounding box belongs to to do that we divide the input image into grid of dimensions equal to that of the final feature map let us consider an example below where the input image is and stride of the network is as pointed earlier the dimensions of the feature map will be we then divide the input image into cells then the cell on the input image containing the center of the ground truth box of an object is chosen to be the one responsible for predicting the object in the image it is the cell which marked red which contains the center of the ground truth box marked yellow now the red cell is the th cell in the th row on the grid we now assign the th cell in the th row on the feature map corresponding cell on the feature map as the one responsible for detecting the dog now this cell can predict three bounding boxes which one will be assigned to the dog ground truth label in order to understand that we must wrap out head around the concept of anchors note that the cell we re talking about here is cell on the prediction feature map we divide the input image into grid just to determine which cell of the prediction feature map is responsible for prediction anchor boxes it might make sense to predict the width and the height of the bounding box but in practice that leads to unstable gradients during training instead most of the modern object detectors predict log space transforms or simply offsets to pre defined default bounding boxes called anchors then these transforms are applied to the anchor boxes to obtain the prediction yolo has three anchors which result in prediction of three bounding boxes per cell coming back to our earlier question the bounding box responsible for detecting the dog will be the one whose anchor has the highest iou with the ground truth box making predictions the following formulae describe how the network output is transformed to obtain bounding box predictions bx by bw bh are the center co ordinates width and height of our prediction tx ty tw th is what the network outputs cx and cy are the top left co ordinates of the grid pw and ph are anchors dimensions for the box center coordinates notice we are running our center coordinates prediction through sigmoid function this forces the value of the output to be between and why should this be the case bear with me normally yolo doesn predict the absolute coordinates of the bounding box center it predicts offsets which are relative to the top left corner of the grid cell which is predicting the object normalised by the dimensions of the cell from the feature map which is for example consider the case of our dog image if the prediction for center is then this means that the center lies at on the feature map since the top left co ordinates of the red cell are but wait what happens if the predicted co ordinates are greater than one say this means center lies at notice the center now lies in cell just right to our red cell or the th cell in the th row this breaks theory behind yolo because if we postulate that the red box is responsible for predicting the dog the center of the dog must lie in the red cell and not in the one beside it therefore to remedy this problem the output is passed through sigmoid function which squashes the output in range from to effectively keeping the center in the grid which is predicting dimensions of the bounding box the dimensions of the bounding box are predicted by applying log space transform to the output and then multiplying with an anchor how the detector output is transformed to give the final prediction image credits http christopher github io the resultant predictions bw and bh are normalised by the height and width of the image training labels are chosen this way so if the predictions bx and by for the box containing the dog are then the actual width and height on feature map is objectness score object score represents the probability that an object is contained inside bounding box it should be nearly for the red and the neighboring grids whereas almost for say the grid at the corners the objectness score is also passed through sigmoid as it is to be interpreted as probability class confidences class confidences represent the probabilities of the detected object belonging to particular class dog cat banana car etc before yolo used to softmax the class scores however that design choice has been dropped in and authors have opted for using sigmoid instead the reason is that softmaxing class scores assume that the classes are mutually exclusive in simple words if an object belongs to one class then it guaranteed it cannot belong to another class this is true for coco database on which we will base our detector however this assumptions may not hold when we have classes like women and person this is the reason that authors have steered clear of using softmax activation prediction across different scales yolo makes prediction across different scales the detection layer is used make detection at feature maps of three different sizes having strides respectively this means with an input of we make detections on scales and the network downsamples the input image until the first detection layer where detection is made using feature maps of layer with stride further layers are upsampled by factor of and concatenated with feature maps of previous layers having identical feature map sizes another detection is now made at layer with stride the same upsampling procedure is repeated and final detection is made at the layer of stride at each scale each cell predicts bounding boxes using anchors making the total number of anchors used the anchors are different for different scales the authors report that this helps yolo get better at detecting small objects frequent complaint with the earlier versions of yolo upsampling can help the network learn fine grained features which are instrumental for detecting small objects output processing for an image of size yolo predicts bounding boxes however in case of our image there only one object dog how do we reduce the detections from to thresholding by object confidence first we filter boxes based on their objectness score generally boxes having scores below threshold are ignored non maximum suppression nms intends to cure the problem of multiple detections of the same image for example all the bounding boxes of the red grid cell may detect box or the adjacent cells may detect the same object if you don know about nms ve provided link to website explaining the same our implementation yolo can only detect objects belonging to the classes present in the dataset used to train the network we will be using the official weight file for our detector these weights have been obtained by training the network on coco dataset and therefore we can detect object categories that it for the first part this post explains enough about the yolo algorithm to enable you to implement the detector however if you want to dig deep into how yolo works how it trained and how it performs compared to other detectors you can read the original papers the links of which ve provided below that it for this part in the next part we implement various layers required to put together the detector further reading yolo you only look once unified real time object detection yolo yolo better faster stronger yolo an incremental improvement convolutional neural networks bounding box regression appendix iou non maximum suppresion pytorch official tutorial ayoosh kathuria is currently an intern at the defense research and development organization india where he is working on improving object detection in grainy videos when he not working he either sleeping or playing pink floyd on his guitar you can connect with him on linkedin or look at more of what he does at github span preheader display none important discourseembed discourseurl https community paperspace com https blog paperspace com how to implement yolo object detector in pytorch function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more july series optimization intro to optimization in deep learning busting the myth about batch normalization mathjax hub config tex jax inlinemath processescapes true recognize these people if not these people call themselves the myth busters heck they ve even got show of their own on discovery channel where they try to live up to their name trying to bust myths like whether you can cut jail bar by repeatedly eroding it with dental floss warning do not try this during your sentence inspired by them we at paperspace are going do something similar the myth we are going to tackle is whether batch normalization indeed solves the problem of internal covariate shift though batch normalization been around for few years and has become staple in deep architectures it remains one of the most misunderstood concepts in deep learning does batch norm really solve internal covariate shift if not then what does it do is your entire deep learning education lie let find out just before we begin would like to remind you that this post is part of the series on optimization in deep learning where we have already discussed how stochastic gradient descent is used to combat the problem of local minima and saddle points in deep learning how adaptive methods like momentum and adam augment vanilla gradient descent to tackle pathological curvature in optimization surfaces how different activation functions are used address the vanishing gradients problem one of the lessons that we took from the last post was that for neural networks to learn efficiently the distribution that is fed to the layers of network should be somewhat zero centered constant through time and data the second condition means that the distribution of the data being fed to the layers should not vary too much across the mini batches fed to the network as well it should stay somewhat constant as the training goes on contrary scenario would be the distribution changing rapidly from epoch to epoch internal covariate shift let get right to the business end of things the paper batch normalization accelerating deep network training by reducing internal covariate shift rests on premise of addressing an issue called internal covariate shift so what the hey is this internal covariate shift or ics as we call it from now on it when the input distribution to the layers of your neural network end up fluctuating the internal part refers to the fact that this fluctuation is happening in the intermediate layers of the neural network which can be thought of the internal part of the network the covariate part refers to the fact that the distributions are parameterized by weights that vary with each other shift well means the distribution is changing so let try to capture how this thing happens again imagine one of the simplest neural networks possible linearly stacked neurons such that you could also extend the analogy by replacing neurons with layers let us suppose we are optimizing loss function for the network given above the update rule of weights omega_d of the neuron is frac partial partial omega_d frac partial partial z_d frac partial z_d partial omega_d here z_d omega_d z_c is the activation of neuron simplifying we get frac partial partial omega_d frac partial partial z_d z_c so we see that the gradient of the weights of the layer depends on the output of the layer the same holds true for any layer in the neural network the gradient of the weights of neuron depends on it input or the output of the layer just behind it duh this gradient is then backpropagated and the weights updated this process is repeated now let us return to layer since we performed the gradient update for we now expect omega_d to score lower loss however that might not be the case why is that so let have closer look we perform the initial update at iteration let us denote the distribution of output of at iteration as p_c now the update for assumes the input distribution of as p_c during the backward pass however weights of omega_c is also updated this causes shift in distribution of output of in the next iteration suppose the distribution of z_c has shifted to p_c since the weights of the layer were updated in accordance with p_c and now the layer faces an input distribution p_c this disparity may lead to layer producing an output that doesn decrease the loss at all now we are in position to pose two questions how exactly does shift in distribution of the input make it harder for layer to learn can this be shift be drastic enough to cause the scenario described above we answer the first question first why is internal covariate shift even thing what neural networks do is that they generate mapping that maps the input to the output why in the world would it make difference if the distribution of were to change mean look here when is normally distributed here when is not normally distributed suppose the mapping we re trying is why would it matter if the distribution of has lot of density squashed up in one place or if it evenly spread out it turns out it does matter it matters because neural networks modern deep networks to be precise are insanely powerful curve fitters and as uncle ben told spiderman with great power comes great responsibility let us suppose we have layer which faces which has distribution given below also let us suppose the function learned by the layer up to this point in training is represented by the dashed line during iteration now suppose after the gradient updation the distribution of gets changed to something like this when the next minibatch is fed to the network during iteration notice how the loss for this mini batch is more as compared to the previous loss yikes why does this happen let rewind to our earlier figure you see the mapping we learned originally does good job of reducing the loss of the the previous mini batch same is true for many other functions which behave very differently in regions where is not dense different functions that can fit the same input had we chosen the function given by the red dashed line our loss for the next mini batch would have been low as well another function would have been the better fit but the glaring question right now is that how do we modify our algorithm so that we end up learning mapping corresponding the red dotted line instead the simple answer is that there no simple answer to this better to do at this point is that instead of trying to find cure for situations like these we rather focus our energies on preventing them in the first place the reason ics ends up screwing our learning is that our neural network will always perform better on the denser regions of the input distribution the loss for points in the denser region is reduced more as the data points in the denser region dominate the average loss which we are trying to minimize however if ics ends up changing the denser regions of the input distribution in subsequent batches during training the weights learned by the network during previous iterations are no longer optimal it will probably need very careful tuning of the hyperparameters to get reasonable learning this explains why ics can be such problem what we re talking is having good amount of variance in our mini batch variance makes sure that our mapping doesn over specialize in one region of the input distribution we also like to have the mean somewhere around zero the reason why you want to have zero centered input to layer has been discussed in great detail in the previous post here normalizing the inputs one way around this problem to normalize the inputs to the neural network so that the input distribution have zero mean and unit variance however this works only when when the network is not deep enough when the networks get deeper say or more layers the minor fluctuations in weights over more than odd layers can produce big changes in the distribution of the input being fed to deeper layers even if the input is normalized one not entirely correct but gets the point across analogy is that of changes in languages languages change as we travel distances however the languages within shorter distances have lot of similarities say spanish and portuguese however both of them derive themselves from pre historic indo european language so does hindustani language spoken in india km away however the difference between spanish and hindustani is much larger than those between spanish and portuguese the reason is that minor variations across small distances have amplified lot same goes for deep networks enter batch normalization we now introduce the concept of batch normalization which in effect normalizes the output activations of layer and then does something more here precise description begin gather y_i bn_ gamma beta x_i tag mu_b frac sum_ x_i tag sigma frac sum_ mu_b tag hat x_i frac x_i mu_b sqrt sigma_ beta epsilon tag y_i gamma hat x_i beta tag end gather the above equations describe what batch norm layer does equations describe how mean and variance of each activation across mini batch is calculated followed by subtraction by mean to zero center the activations and dividing by the standard deviation this is to make the standard deviation of each activation across the mini batch unit notice that the mean and the variance being calculated here is the mean and the variance across the mini batch the equation is where the real magic happens gamma and beta are the hyperparameters of the so called batch normalization layer the output of equation has mean of beta and standard deviation of gamma in effect batch normalization layer helps our optimization algorithm to control the mean and the variance of the output of the layer debunking the myth of ics the paper that introduced the batch normalization to the world attributed it success to the fact that it gets rid of internal covariate shift however that is fallacious statement and batch norm doesn prevent ics at all internal covariate shift is precisely the input distribution changing as we train our network batch norm has hyperparameters gamma and beta for adjusting the mean and variance of the activations however it does mean that as these hyperparameters are trained they also change and batch norm is inherently causing changing in distribution of activations or internal covariate shift had it prevented internal covariate shift the hyperparameters gamma and beta make no sense so why does batch norm work batch norm doesn cure internal covariate shift that for sure if not then why does it work at all ian goodfellow creator of gans and one of the foremost researcher in field of ai has given possible explaination in one of his lectures he delivered the link to the lecture has been given at the end of the article at this point must remind you that unless we back it up by concrete evidence this is merely speculation regardless the fact that it might come from one of the heavyweights in modern deep learning goodfellow argues that the explaination lies at the two hyperparameters of the batch norm layer let us again consider out super simple toy network here when we make gradient update to the weights of we only compute frac partial partial that the sensitivity of the loss function with respect to however we do not take into account that changing the weights of is also going to change the output of further layers like again this really boils down to our inability to use second order or higher order optimization methods owing to the computational intractability of using these algorithms gradient descent along with it variants can only capture first order interactions we have talked about it in depth in the part of this series here deep neural networks have higher order interactions which means changing weights of one layer might also effect the statistics of other layers in addition to the loss function these cross layer interactions when unaccounted lead to internal covariate shift every time we update the weights of layer there is chance that it effects the statistics of layer further in the neural network in an unfavorable way convergence may require careful initializing hyperparameter tuning and longer training durations in such cases however when we add the batch normalized layer between the layers the statistics of layer are only effected by the two hyperparameters gamma and beta now our optimization algorithm has to adjust only two hyperparameters to control the statistics of any layer rather than the entire weights in the previous layer this greatly speeds up convergence and avoids the need for careful initialization and hyperparameter tuning therefore batch norm acts more like check pointing mechanism notice that the ability to arbitrarily set the mean and the standard deviation of layer also means that we can recover the original distribution if that was sufficient for proper training batch norm before activation or after the activation while the original paper talks about applying batch norm just before the activation function it has been found in practice that applying batch norm after the activation yields better results this seems to make sense as if we were to put activation after batch norm then the batch norm layer cannot fully control the statistics of the input going into the next layer since the output of the batch norm layer has to go through an activation this is not the case with scenario where batch norm is applied after an activation batch norm at inference using batch normalization during inference can be bit tricky this is because we might not always have batch during inference time for example consider running an object detector on video in real time single frame is processed at once and hence there is no batch this is crucial since we need to compute the mean hat and variance sigma of batch to produce the output of the batch norm layer in that case we keep moving average of the mean and variance during training and then plug these values for the mean and the variance during inference this is the approach taken by most deep learning libraries that ship batch norm layers out of the box the justification of using moving average rests on the law of large numbers the mean and variance of mini batch is very noisy estimate of the true mean and the variance while the batch estimates are called the batch statistics the true unknown to us values of mean and variance are called the population statistics the law of large number states that for large number of samples the batch statistics will tend to converge to population statistics and that is why we use moving average during training it also helps us even out the noise in the estimates produced owing to the mini batch nature of our optimization algorithm in case we have the option of using batches at test time we use the same equations as above with an exception of minor change in the equation where we calculate the standard deviation instead of the equation sigma frac sum_ mu_b tag we use sigma frac sum_ mu_b tag the reason why we use in the denominator instead of is that since we have already estimated the mean we only have independent entities in our minibatch now had that not been the case the mean could have been arbitrarily any number but we do have fixed mean which we are using to compute the variance these independent entities are called degrees of freedom and discussion on them is beyond the scope of this article batch norm as regularizer batch norm also acts regularizer the mean and the variance estimated for each batch is noisier version of the true mean and this injects randomness in our optima search this helps in regularization conclusion while batch norm has been established as standard element of deep architectures now it only recently that research has been directed towards understanding how it really works recent paper that has been getting lot of attention is literally titled how does batch normalization help optimization no it is not about internal covariate shift which demonstrates how batch norm actually ends up increasing internal covariate shift as compared to network that doesn use batch norm they key insight from the paper is that batch norm actually makes the loss surface smoother which is why it works so well last year we also were introduced to selus or scaled exponential linear unit activation functions which implicitly normalize the activations going through them something that is done explicitly through batch norm the original paper for selu contains about pages of math showing how exactly that happens and the math inclined are encouraged to read that optimization is exciting field in deep learning while lot of applications of deep learning have been harnessed and put to use it only now that we have started to scratch the enticing field of deep learning theory to conclude we like to say myth busted further reading batch norm paper how does batch normalization help optimization no it is not about internal covariate shift scaled exponential linear units ian goodfellow lecture on batch normalization reddit discussion on whether to put batch norm before or after relu discourseembed discourseurl https community paperspace com https blog paperspace com busting the myths about batch normalization function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more may gan building simple generative adversarial network gan using tensorflow generative adversarial networks or gans are one of the most active areas in deep learning research and development due to their incredible ability to generate synthetic results in this blog we will build out the basic intuition of gans through concrete example this post is broken down in following way basic idea and intuition behind workings of generative adversarial networks implementing gan based model that generates data from simple distribution visualizing and analyzing different aspects of the gan to better understand what happening behind the scenes the code for this blog can be found here generative adversarial networks the basic idea behind gans is actually very simple at its core gan includes two agents with competing objectives that work through opposing goals this relatively simple setup results in both of the agent coming up with increasingly complex ways to deceive each other this kind of situation can be modeled in game theory as minimax game let take theoretical example of the process of money counterfeiting in this process we can imagine two types agents criminal and cop let us look into their competing objectives criminal objective the main objective of the criminal is to come up with complex ways of counterfeiting money such that the cop cannot distinguish between counterfeited money and real money cop objective the main objective of the cop is to come up with complex ways so as to distinguish between counterfeited money and real money as this process progresses the cop develops more and more sophisticated technology to detect money counterfeiting and criminal develops more and more sophisticated technology to counterfeit money this is the basis of what is called an adversarial process generative adversarial networks take advantage of adversarial processes to train two neural networks who compete with each other until desirable equilibrium is reached in this case we have generator network which takes input random noise and tries to generate data very close to the dataset we have the other network is called the discriminator network which takes input generated data and tries to discriminate between generated data and real data this network at its core implements binary classification and outputs the probability that the input data actually comes from the real dataset as opposed to the synthetic or fake data in the formal sense the objective function of this whole process can be written as the usual desirable equilibrium point for the above defined gans is that the generator should model the real data and discriminator should output the probability of as the generated data is same as the real data that is it is not sure if the new data coming from the generator is real or fake with equal probability you might be wondering why such complex learning process is even required what are the advantages of learning such model well the intuition behind this and all the generative approaches follow famous quote from richard feynman what cannot create do not understand this is relevant because if we are able to generate real data distribution from model then it means that we know everything that this to know about that model lot of time these real distributions include millions of images and we can generate them using model that has thousands of parameters then these parameters capture the essence of the given images gans have many other real life short term applications also which we will discuss in later section implementing gans in this section we will generate very simple data distribution and try to learn generator function that generates data from this distribution using gans model described above this section is broadly divided into parts firstly we will write basic function to generate quadratic distribution the real data distribution secondly we write code for generator and discriminator networks then we will use the data and the networks to write the code for training these two networks in an adversarial way the objective of this implementation is to learn new function that can generate data from the same distribution as the training data the expectation from the training is that our generator network should start producing data which follows the quadratic distribution this is explained and demonstrated more in the next section although we are starting with very simple data distribution this approach can be easily extended to generate data from the much more complex dataset few example gans have successfully generated images of handwritten digits faces of celebrities animals etc generating training data we implement our true dataset by generating random samples using numpy library and then generating the second coordinate using some kind of function for the purpose of this demo we have kept the function as quadratic function for simplicity you can play with this code to generate dataset with more dimensions and or more complex relation between its features such as higher degree polynomial sine cosine etc import numpy as np def get_y return def sample_data scale data scale np random random_sample for in range yi get_y data append yi return np array data the generated data is very simple and can be plotted as seen here generator and discriminator networks implementation we will now implement the generator and discriminator networks using tensorflow layers we implement the generator network using the following function def generator hsize reuse false with tf variable_scope gan generator reuse reuse tf layers dense hsize activation tf nn leaky_relu tf layers dense hsize activation tf nn leaky_relu out tf layers dense return out this function takes in the placeholder for random samples an array hsize for the number of units in the hidden layers and reuse variable which is used for reusing the same layers using these inputs it creates fully connected neural network of hidden layers with given number of nodes the output of this function is dimensional vector which corresponds to the dimensions of the real dataset that we are trying to learn the above function can be easily modified to include more hidden layers different types of layers different activation and different output mappings we implement the discriminator network using the following function def discriminator hsize reuse false with tf variable_scope gan discriminator reuse reuse tf layers dense hsize activation tf nn leaky_relu tf layers dense hsize activation tf nn leaky_relu tf layers dense out tf layers dense return out this function takes input placeholder for the samples from the vector space of real dataset the samples can be both real samples and samples generated from the generator network similar to the generator network above it also takes input hsize and reuse we use hidden layers for the discriminator out of which first layers size we take input we fix the size of the third hidden layer to so that we can visualize the transformed feature space in plane as explained in the later section the output of this function is logit prediction for the given and the output of the last layer which is the feature transformation learned by discriminator for the logit function is the inverse of the sigmoid function which is used to represent the logarithm of the odds ratio of the probability of variable being to that of it being adversarial training for the purpose of training we define the following placeholders and for real samples and random noise samples respectively tf placeholder tf float none tf placeholder tf float none we also need to create the graph for generating samples from generator network and feeding real and generated samples to the discriminator network this is done by using the functions and placeholders defined above g_sample generator r_logits r_rep discriminator f_logits g_rep discriminator g_sample reuse true using the logits for generated data and real data we define the loss functions for the generator and discriminator networks as follows disc_loss tf reduce_mean tf nn logits r_logits labels tf ones_like r_logits tf nn logits f_logits labels tf zeros_like f_logits gen_loss tf reduce_mean tf nn logits f_logits labels tf ones_like f_logits these losses are sigmoid cross entropy based losses using the equations we defined above this is commonly used loss function for so called discrete classification it takes as input the logit which is given by our discriminator network and true labels for each sample it then calculates the error for each sample we are using the optimized version of this as implemented by tensorflow which is more stable then directly taking calculating cross entropy for more details you can check out the relevant tensorflow api here next we define the optimizers for the two networks using the loss functions defined above and scope of the layers defined in the generator and discriminator functions we use rmsprop optimizer for both the networks with the learning rate as using the scope we fetch the weights variables for the given network only gen_vars tf get_collection tf graphkeys scope gan generator disc_vars tf get_collection tf graphkeys scope gan discriminator gen_step tf train learning_rate minimize gen_loss var_list gen_vars train step disc_step tf train learning_rate minimize disc_loss var_list disc_vars train step we then train both the networks in an alternating way for the required number of steps for in range x_batch sample_data batch_size z_batch sample_z batch_size dloss sess run disc_step disc_loss feed_dict x_batch z_batch gloss sess run gen_step gen_loss feed_dict z_batch print iterations discriminator loss generator loss dloss gloss the above code can be modified to include more complex training procedures such as running multiple steps of the discriminator and or generator update fetching the features of the real and generated samples and plotting the generated samples please refer to the code repository for such modifications analyzing gans visualizing the training losses to better understand what is happening in this process we can plot the training losses after every iterations from the plot below we can see how changes in loss decrease gradually and that loss becomes almost constant towards the end of training this negligible change in the loss of both discriminator and generator indicates equilibrium visualizing samples during training we can also plot the real and generated samples after every iterations of training these plots visualize how the generator network starts with random initial mapping between the input and dataset vector space and then it gradually progresses to resemble the real dataset samples as you can see the fake sample starts looking more and more like the real data distribution visualizing the generator update in this section we visualize the effect of updating the generator network weights within the adversarial trainingprocess we do this by plotting the activations of the last hidden layer of discriminator network we chose the last hidden layer to be of size so that it would be easy to plot without requiring dimensionality reduction the transformation of the input sample to different vector space we are interested in visualizing the feature transformation function learned by the discriminator network this function is what our network learns so that the real and fake data are separable we plot the feature transform of the real and generated samples as learned by the discriminator network last layer before and after we update the weights of the generator network we also plot the centroids of the points that we obtain after the feature transformation of the input samples finally we calculate the centroids of the points separately for both real and fake data before and after the generator update from the plots we can infer following things as expected there is no change in the transformed features of the real data samples from the plots we can see they totally coincide from the centroids we can see that centroid of the features of generated data samples almost always moves towards the centroid of the features of real data samples we can also see that as the iterations increase the transformed features of real samples get more and more mixed with transformed features of generated samples this is also expected because at the end of training the discriminator network should not be able to distinguish between real and generated samples hence at the end of training transformed features for both the samples should coincide discussion and future work we have implemented proof of concept gan model for generating data from very simple data distribution as an exercise for the curious reader we recommend modifying the above code to do the following visualize the before and after of the discriminator update change the activation functions of the layers and see the difference in training and generated samples add more layers and different types of layers and see the effect on the training time and the stability of the training modify the code for generating data to include data from different curves modify the above code to work with more complex data such as mnist cifar etc in future work we will discuss limitations of the gans and the modifications that are required to solve them discourseembed discourseurl https community paperspace com https blog paperspace com implementing gans in tensorflow function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild this post was collaboration between aadil hayat dillon aadil hayat read more posts by this author dillon ceo co founder paperspace more posts by dillon  announcement the new paperspace community we re always amazed by what our users are building with paperspace and felt it was important to provide space where people can share ideas ask questions learn new tools and techniques and george min read fake bananas detecting fake news at hackmit on paperspace fake bananas check your facts before you slip on em check out our github repo here this year at hackmit our team fake bananas leveraged paperspace server infrastructure to build george min read facial recognition using deep learning convolutional neural networks cnn and feature extraction convolutional neural networks allow us to extract wide range of features from images turns out we can use this idea of feature extraction for face george min read tutorial gpu acceleration in agisoft photoscan how to enable gpu acceleration in photoscan with paperspace powerful gpu and photoscan gpu accelerated workflow processing of large image datasets can happen in hours not days this walkthrough will cover the power george min read getting started how to get started with agisoft photoscan what is photoscan agisoft photoscan is photogrammetry solution used extensively within the building industry for model generation from existing sites building interiors and exteriors with paperspace powerful gpu and photoscan gpu george min read data science how to run tableau on chromebook what is tableau desktop tableau desktop is business analytics solution that can visualize data and deliver insights from nearly any data source it built for collaboration and can handle large amounts of george min read daas distributing your product to your customer via paperspace paperspace is powerful distribution vehicle to demonstrate your product capabilities in way that is simple and managable your prospective clients will be able to test drive your software with any sample george min read events join us at siggraph visit our booth come visit paperspace at the garage as part of siggraph siggraph we would love to say hi our booth is located at sg free exhibition passes to make it george min read features getting started with cpu instances linux cpu instances allow you to scale compute power as you need it across variety of use cases we re excited to announce their availability in our latest release here we re going to walk george min read machine learning paperspace insight data science at paperspace we re dedicated to making machine learning in the cloud more accessible to professionals and academics the idea of click ml in box is our response to the surge of requests for more george min read give to your friends receive introducing referral codes we re very excited to announce new feature that allows you to share your passion for paperspace to others referral codes share to anyone anyone you refer to george min read machine learning announcing the official paperspace meetup machine learning at work hello there friend are you software developer trying to get broad overview of the products and services available business analyst product manager marketing manager or consultant who has heard that george min read april series dimension reduction autoencoders this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle sne isomap autoencoders this post assumes you have working knowledge of neural networks notebook with the code is available at github repo an autoencoder can be defined as neural network whose primary purpose is to learn the underlying manifold or the feature space in the dataset an autoencoder tries to reconstruct the inputs at the outputs unlike other non linear dimension reduction methods the autoencoders do not strive to preserve to single property like distance mds topology lle an autoencoder generally consists of two parts an encoder which transforms the input to hidden code and decoder which reconstructs the input from hidden code simple example of an autoencoder would be something like the neural network shown in the diagram below one might wonder what is the use of autoencoders if the output is same as input how does feature learning or dimension reduction happen if the end result is same as input the assumption behind autoencoders is that the transformation input hidden input will help us learn important properties of the dataset the properties which we aim to learn in turn depend upon the restrictions put on the network types of autoencoders let discuss few popular types of autoencoders regularized autoencoders these types of autoencoders use various regularization terms in their loss functions to achieve desired properties the size of the hidden code can be greater than input size sparse autoencoders sparse autoencoder adds penalty on the sparsity of the hidden layer regularization forces the hidden layer to activate only some of the hidden units per data sample by activation we mean that if the value of jth hidden unit is close to it is activated else deactivated the output from deactivated node to the next layer is zero this restriction forces the network to condense and store only important features of the data the loss function of the sparse autoencoders can be represented as regularization term the middle layer represents the hidden layer the green and red nodes represent the deactivated and activated nodes respectively denoising autoencoders in denoising autoencoders random noise is deliberately added to the input and network is forced to reconstruct the unadulterated input the decoder function learns to resist small changes in the input this pretraining result in robust neural network which is immune to noise in input up to certain extent the standard normal function is used as the noising function to produce the corrupted input contractive autoencoders instead of adding noise to input contractive autoencoders add penalty on the large value of derivative of the feature extraction function small value of feature extraction function derivative results in negligible change in features when changes in the input are insignificant in contractive encoders feature extraction function is robust while in denoising encoders decoder function is robust variational autoencoders the variational autoencoders are based on nonlinear latent variable models in latent variable model we assume that observable are generated from hidden variables these hidden variables contain important properties about the data these autoencoders consist of two neural networks first for learning the latent variable distribution and second for generating the observables from random sample obtained from latent variables distribution apart from minimizing the reconstruction loss these autoencoders also minimize the difference between the assumed distribution of latent variables and distribution resulting from the encoder they are highly popular for generating images good choice for latent variables distribution is gaussian distribution as shown in the image above encoder outputs the parameters of the assumed gaussian next random sample is extracted from the gaussian distribution and decoder reconstructs the input from the random sample undercomplete autoencoders the size of hidden layer is smaller than the input layer in undercomplete autoencoders by reducing the hidden layer size we force the network to learn the important features of the dataset once the training phase is over decoder part is discarded and the encoder is used to transform data sample to feature subspace if the decoder transformation is linear and loss function is mse mean squared error the feature subspace is same as that of pca for network to learn something useful the size of the hidden code should not be close to or greater than input size network also network with high capacity deep and highly nonlinear may not be able to learn anything useful dimension reduction methods are based on the assumption that dimension of data is artificially inflated and its intrinsic dimension is much lower as we increase the number of layers in an autoencoder the size of the hidden layer will have to decrease if the size of the hidden layer becomes smaller than the intrinsic dimension of the data and it will result in loss of information the decoder could learn to map the hidden layer to specific inputs since the number of layers is large and it is highly nonlinear image of multiplayer encoder and decoder simple autoencoder is shown below loss function of the undercomplete autoencoders is given by since this post is on dimension reduction using autoencoders we will implement undercomplete autoencoders on pyspark there are few open source deep learning libraries for spark bigdl from intel by yahoo and spark deep learning from databricks we will be using intel bigdl step install bigdl if you have already installed spark run pip install user bigdl no deps else run pip install user bigdl in latter case pip will install pyspark along with bigdl step necessary imports matplotlib inline import numpy as np import datetime as dt import matplotlib pyplot as plt from matplotlib pyplot import imshow some imports from bigdl from bigdl nn layer import from bigdl nn criterion import from bigdl optim optimizer import from bigdl util common import from bigdl dataset transformer import from pyspark import sparkcontext sc sparkcontext getorcreate conf setmaster local set spark driver memory function to initialize the bigdl library init_engine step load and prepare the data bigdl provides nice function for downloading and reading mnist dataset from bigdl dataset import mnist mnist_path mnist images_train labels_train mnist read_data_sets mnist_path train mean and stddev of the pixel values mean np mean images_train std np std images_train parallelize center and scale the images_train rdd_images sc parallelize images_train map lambda features features mean std print total number of images rdd_images count step create the function for model parameters for training batch_size num_epochs network parameters size_hidden shape of the input data size_input function for creating an autoencoder def get_autoencoder hidden_size input_size initialize sequential type container module sequential create encoder layers module add linear input_size hidden_size module add relu create decoder layers module add linear hidden_size input_size module add sigmoid return module step set up the deep learning graph get_autoencoder size_hidden size_input transform dataset to rdd sample from rdd ndarray sample represents record in the dataset sample consists of two tensors features tensor and label tensor in our autoencoder features and label will be same train_data rdd_images map lambda sample from_ndarray reshape reshape create an optimizer optimizer optimizer model training_rdd train_data criterion msecriterion optim_method adam end_trigger maxepoch num_epochs batch_size batch_size write summary app_name dt datetime now strftime train_summary trainsummary log_dir tmp bigdl_summary app_name app_name optimizer train_summary print logs to saved to app_name step train the model run training process trained_uae optimizer optimize step model performance on test data let check our model performance on the test data images labels mnist read_data_sets mnist_path test rdd_test sc parallelize images map lambda features features mean std reshape map lambda features sample from_ndarray features features examples trained_uae predict rdd_test take plt subplots figsize for in range imshow np reshape images imshow np reshape examples as we can see from the image the reconstructions are very close to the original inputs conclusion through this post we discussed how autoencoders can be used for dimension reduction in the beginning we talked about different types of autoencoders and their purpose later on we implemented an undercomplete autoencoder using intel bigdl and pyspark for more tutorials on bigdl visit bigdl tutorials this post concludes our series of posts on dimension reduction ashwini kumar pal read more posts by this author read more series dimension reduction autoencoders this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series dimension reduction isomap this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series dimension reduction sne this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series dimension reduction lle this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series multi dimension scaling mds this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series diving deeper into dimension reduction with independent components analysis ica this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series understanding dimension reduction with principal component analysis pca this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read may tutorial build an ai to play dino run tutorial to build reinforcement learning model publication by deepmind titled playing atari with deep reinforcement learning introduced new deep learning model for reinforcement learning and demonstrated its ability to master difficult control policies for atari computer games using only raw pixels as input in this tutorial will implement this paper using keras we ll start with the basics of reinforcement learning and then dive into the code for hands on understanding ai playing the game started with this project in early march and got some good results however the cpu only system was the bottleneck for learning more features powerful gpu improved the performance tremendously there are many steps and concepts that we need to understand before we have running model steps build two way interface between browser javascript and model python capture and pre process images train model evaluate source code https github com paperspace dinoruntutorial git getting started to train and play the game as is clone the github repository after you have set up the environment using git clone https github com paperspace dinoruntutorial git and work on the jupyter notebook reinforcement learning dino run ipynb make sure you run init_cache first time to initialize the file system structure reinforcement learning child learning to walk this might be new word for many but each and every one of us has learned to walk using the concept of reinforcement learning rl and this is how our brain still works reward system is basis for any rl algorithm if we go back to the analogy of childs walk positive reward would be clap from parents or ability to reach candy and negative reward would be no candy the child then first learns to stand up before starting to walk in terms of artificial intelligence the main aim for an agent in our case the dino is to maximize certain numeric reward by performing particular sequence of actions in the environment the biggest challenge in rl is the absence of supervision labeled data to guide the agent it must explore and learn on its own the agent starts by randomly performing actions and observing the rewards each action brings and learns to predict the best possible action when faced with similar state of the environment vanilla reinforcement learning framework learning we use learning technique of rl where we try to approximate special function which drives the action selection policy for any sequence of environment states learning is model less implementation of reinforcement learning where table of values is maintained against each state action taken and the resulting reward sample table should give us the idea how the data is structured in our case the states are game screenshots and actions do nothing and jump sample table we take advantage of the deep neural networks to solve this problem through regression and choose an action with highest predicted value for detailed understanding of learning please refer this amazing blog post by tambet matiisen you can also refer my previous post to get around all the hyper parameters specific to learning setup let setup our environment to start the training process select the vm we need complete desktop environment where we can capture and utilize the screenshots for training chose paperspace ml in box mliab ubuntu image the advantage of mliab is that it comes pre installed with anaconda and many other ml libraries machine learning in box configure and install keras to use gpu we need to install keras and tensorflow gpu verion paperspace vms have these pre installed but if not install them pip install keras pip install tensorflow also make sure the gpu is recognized by the setup execute the python code below and you should see available gpu devices from keras import backend as installing dependencies selenium pip install selenium opencv pip install opencv python download chromedrive from http chromedriver chromium org game framework you can launch the game by pointing your browser to chrome dino or just by pulling the network plug an alternate approach is to extract the game from the open source repository of chromium if we intend to modify the game code our model is written in python and game is built in javascript we need some interfacing tools for them to communicate with each other selenium popular browser automation tool is used to send actions to the browser and get different game parameters like current score now that we have an interface to send actions to the game we need mechanism to capture the game screen the selenium and opencv gave best performance for screen capture and pre processing of the images respectively achieving descent frame rate of fps we require just frames per time frame enough to learn the speed as feature game module we implement the interfacing between python and javascript using this module the snippet below should give you gist of what happening in the module class game def self self webdriver chrome executable_path self self get game_url def restart self self execute_script runner instance_ restart def press_up self self body send_keys keys arrow_up def get_score self score_array self execute_script return runner instance_ distancemeter digits score join score_array return int score agent module we wrap all the interfacing using agent module we control the dino using this module as well as get status of the agent in the environment class dinoagent def self game takes game as input for taking actions self game self jump to start the game we need to jump once def is_crashed self return self get_crashed def jump self self press_up game state module to send actions to the module and get resultant state that the environment transitions into as result of that action we use the game state module it simplifies the process by receiving performing actions decide the reward and return the experience tuple class game_sate def self agent game self agent self game def get_state self actions score self get_score reward survival reward is_over false game over if actions else do nothing self jump image grab_screen self if self is_crashed self restart reward is_over true return image reward is_over return the experience tuple image pipeline image capture there are multiple ways we can capture the game screen like using pil and mss python library to take screenshot of entire screen and crop region of interest however the biggest disadvantage was the sensitivity to the screen resolution and window location luckily the game uses an html canvas we can easily get base formatted image using javascript we run this script using selenium javascript code to get the image data from canvas var canvas document runner canvas var img_data canvas todataurl return img_data image extracted from canvas def grab_screen none image_b execute_script getbase script screen np array image open bytesio base decode image_b image process_img screen processing image as required return image image processing the raw image captured has resolution of around with rgb channels we intend to use consecutive screenshot as single input to the model that makes our single input of dimensions this is computationally expensive and not all the features are useful for playing the game so we use the opencv library to resize crop and process the image the final processed input is of just pixels and single channeled grey scale def process_img image image cv cvtcolor image cv color_bgr gray image image return image image processing model architecture so we got the input and way to utilize the output of the model to play the game so lets look at the model architecture we use series of three convolution layers before flattening them to dense layers and output layer the cpu only model did not include pooling layers because had removed many features and adding pooling layers would ve led to significant loss of already sparse features but with power of gpu we can accommodate more features without any drop in frame rate max pooling layers significantly improves the processing of dense feature set model architecture our output layers consists of two neurons each representing the maximum predicted reward for each action we then choose the action with maximum reward value def buildmodel print now we build the model model sequential model add conv padding same strides input_shape img_cols img_rows img_channels model add maxpooling pool_size model add activation relu model add conv strides padding same model add maxpooling pool_size model add activation relu model add conv strides padding same model add maxpooling pool_size model add activation relu model add flatten model add dense model add activation relu model add dense actions adam adam lr learning_rate model compile loss mse optimizer adam print we finish building the model return model training these are the things happening in the training phase start with no action and get initial state s_t observe game play for observation number of steps predict and perform an action store experience in replay memory choose batch randomly from replay memory and train model on it restart if game over the code for this is little lengthy but fairly simple to understand def trainnetwork model game_state store the previous observations in replay memory deque experience replay memory get the first state by doing nothing do_nothing np zeros actions do_nothing do nothing jump x_t r_ terminal game_state get_state do_nothing get next step after performing the action s_t np stack x_t x_t x_t x_t axis reshape stack images to create placeholder input reshaped observe observation epsilon initial_epsilon while true endless running loss q_sa action_index r_t reward at a_t np zeros actions action at model predict s_t input stack of images get the prediction max_q np argmax chosing index with maximum value action_index max_q a_t action_index do nothing jump run the selected action and observed next state and reward x_t r_t terminal game_state get_state a_t x_t x_t reshape x_t shape x_t shape s_t np append x_t s_t axis append the new image to input stack and remove the first one append s_t action_index r_t s_t terminal store the transition only train if done observing sample minibatch to train on trainbatch random sample batch if observe else s_t s_t notice that we are sampling random experience replays from replay memory and using batched approach of training the reason for this is the unbalanced action distribution in the game structure as well as to avoid over fitting def trainbatch minibatch for in range len minibatch loss inputs np zeros batch s_t shape s_t shape s_t shape targets np zeros inputs shape actions state_t minibatch stack of images action_t minibatch this is action index reward_t minibatch reward at state_t due to action_t state_t minibatch next state terminal minibatch wheather the agent died or survided due the action inputs state_t targets model predict state_t predicted values q_sa model predict state_t predict values for next step if terminal targets action_t reward_t if terminated only equals reward else targets action_t reward_t gamma np max q_sa loss model train_on_batch inputs targets results we should be able to get good results by using this architecture the gpu has significantly improved the results which can be validated with the improvement in the average scores the plot below shows the average scores from the start of the training the average score per games stays well above at the end of training session average scores per games the highest score recorded was which is way beyond the previous model of and way beyond what most humans can do the plot shows the progress of highest scores for the training period games scale max scores per games the speed of the dino is proportional to the score making it harder to detect and decide an action at higher speed the entire game was hence trained on constant speed the code snippets in this blog are just for reference please refer the github repo for functional code with additional settings feel free to play around the code and contribute about me with some experience in software industry am exploring the field of ml and ai and their applications currently am pursuing my master from northeastern university boston would love to connect discuss and contribute to similar projects please feel free to connect on linkedin discourseembed discourseurl https community paperspace com https blog paperspace com dino run function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild ravi munde read more posts by this author read more april series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part image credits karol majek check out his yolo real time detection video here this is part of the tutorial on implementing yolo detector from scratch in the last part we implemented function to transform the output of the network into detection predictions with working detector at hand all that left is to create input and output pipelines the code for this tutorial is designed to run on python and pytorch it can be found in it entirety at this github repo this tutorial is broken into parts part understanding how yolo works part creating the layers of the network architecture part implementing the the forward pass of the network part confidence thresholding and non maximum suppression part this one designing the input and the output pipelines prerequisites part of the tutorial basic working knowledge of pytorch including how to create custom architectures with nn module nn sequential and torch nn parameter classes basic knowledge of opencv edit if you ve visited this post earlier than the way we resized an arbitarily sized image to darknet input size was by simply rescaling the dimensions however in the original implementation an image is resized keeping the aspect ratio intact and padding the left out portions for example if we were to resize image to the resized image would look like this this difference in preparing the input caused the earlier implementation to have marginally inferior performance to the original however the post has been updated to incorporate the resizing metho followed in the original implementation in this part we will build the input and the output pipelines of our detector this involves the reading images off the disk making prediction using the prediction to draw bounding boxes on images and then saving them to the disk we will also cover how to have the detector work in real time on camera feed or video we will introduce some command line flags to allow some experimentation with various hyperparamters of the network so let begin note you will need to install opencv for this part create file detector py in tour detector file add neccasary imports at top of it from import division import time import torch import torch nn as nn from torch autograd import variable import numpy as np import cv from util import import argparse import os import os path as osp from darknet import darknet import pickle as pkl import pandas as pd import random creating command line arguments since detector py is the file that we will execute to run our detector it nice to have command line arguments we can pass to it ve used python argparse module to do that def arg_parse parse arguements to the detect module parser argparse argumentparser description yolo detection module parser add_argument images dest images help image directory containing images to perform detection upon default imgs type str parser add_argument det dest det help image directory to store detections to default det type str parser add_argument bs dest bs help batch size default parser add_argument confidence dest confidence help object confidence to filter predictions default parser add_argument nms_thresh dest nms_thresh help nms threshhold default parser add_argument cfg dest cfgfile help config file default cfg yolov cfg type str parser add_argument weights dest weightsfile help weightsfile default yolov weights type str parser add_argument reso dest reso help input resolution of the network increase to increase accuracy decrease to increase speed default type str return parser parse_args args arg_parse images args images batch_size int args bs confidence float args confidence nms_thesh float args nms_thresh start cuda torch cuda is_available amongst these important flags are images used to specify the input image or directory of images det directory to save detections to reso input image resolution can be used for speed accuracy tradeoff cfg alternative configuration file and weightfile loading the network download the file coco names from here file that contains the names of the objects in the coco dataset create folder data in your detector directory equivalently if you re on linux you can type mkdir data cd data wget https raw com ayooshkathuria yolo_v master data coco names then we load the class file in our program num_classes for coco classes load_classes data coco names load_classes is function defined in util py that returns dictionary which maps the index of every class to string of it name def load_classes namesfile fp open namesfile names fp read split return names initialize the network and load weights set up the neural network print loading network model darknet args cfgfile model load_weights args weightsfile print network successfully loaded model net_info height args reso inp_dim int model net_info height assert inp_dim assert inp_dim if there gpu availible put the model on gpu if cuda model cuda set the model in evaluation mode model eval read the input images read the image from the disk or the images from directory the paths of the image images are stored in list called imlist read_dir time time detection phase try imlist osp join osp realpath images img for img in os listdir images except imlist imlist append osp join osp realpath images except print no file or directory with the name format images exit read_dir is checkpoint used to measure time we will encounter several of these if the directory to save the detections defined by the det flag doesn exist create it if not os path exists args det os makedirs args det we will use opencv to load the images load_batch time time loaded_ims cv imread for in imlist load_batch is again checkpoint opencv loads an image as an numpy array with bgr as the order of the color channels pytorch image input format is batches channels height width with the channel order being rgb therefore we write the function prep_image in util py to transform the numpy array into pytorch input format before we can write this function we must write function letterbox_image that resizes our image keeping the aspect ratio consistent and padding the left out areas with the color def letterbox_image img inp_dim resize image with unchanged aspect ratio using padding img_w img_h img shape img shape inp_dim new_w int img_w min img_w img_h new_h int img_h min img_w img_h resized_image cv resize img new_w new_h interpolation cv inter_cubic canvas np full inp_dim inp_dim canvas new_h new_h new_h new_w new_w new_w resized_image return canvas now we write the function that takes opencv images and converts it to the input of our network def prep_image img inp_dim prepare image for inputting to the neural network returns variable img cv resize img inp_dim inp_dim img img transpose copy img torch from_numpy img float div unsqueeze return img in addition to the transformed image we also maintain list of original images and im_dim_list list containing the dimensions of the original images pytorch variables for images im_batches list map prep_image loaded_ims inp_dim for in range len imlist list containing dimensions of original images im_dim_list shape shape for in loaded_ims im_dim_list torch floattensor im_dim_list repeat if cuda im_dim_list im_dim_list cuda create the batches leftover if len im_dim_list batch_size leftover if batch_size num_batches len imlist batch_size leftover im_batches torch cat im_batches batch_size min batch_size len im_batches for in range num_batches the detection loop we iterate over the batches generate the prediction and concatenate the prediction tensors of shape the output of write_results function of all the images we have to perform detections upon for each batch we measure the time taken for detection as the time spent between taking the input and producing the output of the write_results function in the output returned by one of the attributes was the index of the image in batch we transform that particular attribute in such way that it now represents the index of the image in imlist the list containing addresses of all images after that we print time taken for each detection as well as the object detected in each image if the output of the write_results function for batch is an int meaning there is no detection we use continue to skip the rest loop write start_det_loop time time for batch in enumerate im_batches load the image start time time if cuda batch batch cuda prediction model variable batch volatile true cuda prediction write_results prediction confidence num_classes nms_conf nms_thesh end time time if type prediction int for im_num image in enumerate imlist batch_size min batch_size len imlist im_id batch_size im_num print predicted in seconds format image split end start batch_size print format objects detected print continue prediction batch_size transform the atribute from index in batch to index in imlist if not write if we have initialised output output prediction write else output torch cat output prediction for im_num image in enumerate imlist batch_size min batch_size len imlist im_id batch_size im_num objs classes int for in output if int im_id print predicted in seconds format image split end start batch_size print format objects detected join objs print if cuda torch cuda synchronize the line torch cuda synchronize makes sure that cuda kernel is synchronized with the cpu otherwise cuda kernel returns the control to cpu as soon as the gpu job is queued and well before the gpu job is completed asynchronous calling this might lead to misleading time if end time time gets printed before the gpu job is actually over now we have the detections of all images in our tensor output let us draw the bounding boxes on images drawing bounding boxes on images we use try catch block to check whether there has been single detection has been made or not if that not the case exit the program try output except nameerror print no detections were made exit before we draw the bounding boxes the predictions contained in our output tensor conform to the input size of the network and not the original sizes of the images so before we can draw the bounding boxes let us transform the corner attributes of each bounding box to the original dimensions of images before we draw the bounding boxes the predictions contained in our output tensor are predictions on the padded image and not the original image merely re scaling them to the dimensions of the input image won work here we first need to transform the co ordinates of the boxes to be measured with respect to boundaries of the area on the padded image that contains the original image im_dim_list torch index_select im_dim_list output long scaling_factor torch min inp_dim im_dim_list view output inp_dim scaling_factor im_dim_list view output inp_dim scaling_factor im_dim_list view now our co ordinates conform to dimensions of our image on the padded area however in the function letterbox_image we had resized both the dimensions of our image by scaling factor remember both dimensions were divided with common factor to maintain aspect ratio we now undo this rescaling to get the co ordinates of the bounding box on the original image output scaling_factor let us now clip any bounding boxes that may have boundaries outside the image to the edges of our image for in range output shape output torch clamp output im_dim_list output torch clamp output im_dim_list if there are too many bounding boxes in the image drawing them all in one color may not be such nice idea download this file to your detector folder this is pickled file that contains many colors to randomly choose from class_load time time colors pkl load open pallete rb now let us write function to draw the boxes draw time time def write results color tuple int tuple int img results int cls int label format classes cls cv rectangle img color t_size cv gettextsize label cv t_size t_size cv rectangle img color cv puttext img label t_size cv return img the function above draws rectangle with color of random choice from colors it also creates filled rectangle on the top left corner of the bounding box and writes the class of the object detected across the filled rectangle argument of the cv rectangle function is used for creating filled rectangle we define write function locally so that it can access the colors list we could have also included colors as an argument but that would have allowed us to use only one color per image which defeats the purpose of what we want to do once we ve defined this function let us now draw the bounding boxes on images list map lambda write loaded_ims output the above snippet modifies the images inside loaded_ims inplace each image is saved by prefixing the det_ in front of the image name we create list of addresses to which we will save the our detection images to det_names pd series imlist apply lambda det_ format args det split finally write the images with detections to the address in det_names list map cv imwrite det_names loaded_ims end time time printing time summary at the end of our detector we will print summary containing which part of the code took how long to execute this is useful when we have to compare how different hyperparameters effect the speed of the detector hyperparameters such as batch size objectness confidence and nms threshold passed with bs confidence nms_thresh flags respectively can be set while executing the script detection py on the command line print summary print print format task time taken in seconds print print format reading addresses load_batch read_dir print format loading batch start_det_loop load_batch print format detection str len imlist images output_recast start_det_loop print format output processing class_load output_recast print format drawing boxes end draw print format average time_per_img end load_batch len imlist print torch cuda empty_cache testing the object detector for example running on terminal python detect py images dog cycle car png det det produces the output the following code is run on cpu expect detection times to be much much faster on gpu it around sec image on tesla loading network network successfully loaded dog cycle car png predicted in seconds objects detected bicycle truck dog summary task time taken in seconds reading addresses loading batch detection images output processing drawing boxes average time_per_img an image with name det_dog cycle car png is saved in the det directory running the detector on video webcam in order to run the detector on the video or webcam the code remains almost the same except we don have to iterate over batches but frames of video the code for running the detector on the video can be found in the file video py in the github repository the code is very similar to that of detect py except for few changes first we open the video camera feed in opencv videofile video avi or path to the video file cap cv videocapture videofile cap cv videocapture for webcam assert cap isopened cannot capture source frames the we iterate over the frames in similar fashion to the way we iterated over images lot of code has been simplified over many places because we no longer have to deal with batches but only one image at time this is because only one frame can come at time this includes using tuple in place of tensor for im_dim_list and minute change in the write function every iteration we keep track of the number of frames captured in variable called frames we then divide this number by the time elapsed since the first frame to print the fps of the video instead for writing the detection images to disk using cv imwrite we use cv imshow to display the frame with bounding box drawn on it if the user presses the button it causes the code to break the loop and the video ends frames start time time while cap isopened ret frame cap read if ret img prep_image frame inp_dim cv imshow frame im_dim frame shape frame shape im_dim torch floattensor im_dim repeat if cuda im_dim im_dim cuda img img cuda output model variable img volatile true cuda output write_results output confidence num_classes nms_conf nms_thesh if type output int frames print fps of the video is format frames time time start cv imshow frame frame key cv waitkey if key xff ord break continue output torch clamp output float inp_dim im_dim im_dim repeat output size inp_dim output im_dim classes load_classes data coco names colors pkl load open pallete rb list map lambda write frame output cv imshow frame frame key cv waitkey if key xff ord break frames print time time start print fps of the video is format frames time time start else break conclusion in this series of tutorials we have implemented an object detector from scratch and cheers for reaching this far still think being able to churn out efficient code is one of the most underrated skills deep learning practitioner can have however revolutionary your idea you maybe it of no use unless you can test it for that you need to have strong coding skills ve also learned that the the best way to learn about any topic in deep learning is to implement code it forces you to glance over the minute yet fundamental subtleties of topic that you may miss out on when you re reading paper hope this tutorial series has served as an exercise in honing your skills as deep learning practitioner further reading pytorch tutorial opencv basics python argparse ayoosh kathuria is currently an intern at the defense research and development organization india where he is working on improving object detection in grainy videos when he not working he either sleeping or playing pink floyd on his guitar you can connect with him on linkedin or look at more of what he does at github ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more gradient new gradient python sdk build out complex end to end machine learning pipelines with the new gradient python sdk dillon misha kutsovsky min read announcement introducing gradient low cost instances the public cloud was built first and foremost to enable companies to deliver web applications at scale fast forward decade and today the cloud is used for much more than that one daniel kobran min read tutorial generating an interactive pix pix model with gradient and ml js this post will go through the process of training generative image model using gradient and then porting the model to ml js so you can interact with it in the browser for cristbal valenzuela min read ci cd ci cd for machine learning ai the ecosystem for developing modern web applications is incredibly rich there are countless tools for delivering modern web app to production monitoring it performance and deploying in real time these tools are so dillon min read gradient introducing gradientci our new friendly ci cd bot for machine learning and ai pipelines update this post is out of date we recommend viewing the docs page which includes more info and step by step guide for getting started with gradientci we re excited to introduce gradientci our new dillon cristbal valenzuela min read series data augmentation data augmentation for bounding boxes rethinking image transforms for object detection how to adapt major image augmentation techniques for object detection purposes we also cover the implementation of horizontal flip augmentation ayoosh kathuria min read series data augmentation data augmentation for bounding boxes scaling and translation we implement scale and translate augmentation techniques and what to do if portion of your bounding box is outside the image after the augmentation ayoosh kathuria min read computer vision data augmentation for bounding boxes rotation and shearing this is part of the series where we are looking at ways to adapt image augmentation techniques to object detection tasks in this part we will cover how to implement how to rotate and shear images as well as bounding boxes using opencv affine transformation features ayoosh kathuria min read series data augmentation data augmentation for bounding boxes building input pipelines for your detector previously we have covered variety of image augmentation techniques such as flipping rotation shearing scaling and translating this part is about how to bring it all together and bake it into the input pipeline for your deep network ayoosh kathuria min read series optimization intro to optimization in deep learning busting the myth about batch normalization batch normalisation does not reduce internal covariate shift this posts looks into why internal covariate shift is problem and how batch normalisation is used to address it ayoosh kathuria min read machine learning creating your own style transfer mirror with gradient and ml js in this post we will learn how to train style transfer network with paperspace gradient and use the model in ml js to create an interactive style transfer mirror this post is cristbal valenzuela min read series optimization intro to optimization in deep learning vanishing gradients and choosing the right activation function an look into how various activation functions like relu prelu rrelu and elu are used to address the vanishing gradient problem and how to chose one amongst them for your network ayoosh kathuria min read series optimization intro to optimization in deep learning gradient descent an in depth explanation of gradient descent and how to avoid the problems of local minima and saddle points ayoosh kathuria min read gradient what new in gradient we ve been hard at work developing gradient into robust and scalable deep learning platform here roundup of some of the things we ve added recently product release notes can be found here and daniel kobran min read tutorial build an ai to play dino run tutorial to build reinforcement learning model ravi munde min read tutorial vectorization and broadcasting with pytorch the performance gains derived from running your machine learning code on gpu can be huge but gpus are optimized for code that needs to perform the same operation thousands of times in amin manna min read gan building simple generative adversarial network gan using tensorflow generative adversarial networks or gans are one of the most active areas in deep learning research and development due to their incredible ability to generate synthetic results in this blog we will build out the basic intuition of gans through concrete example aadil hayat dillon min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part tutorial on building yolo detector from scratch detailing how to create the network architecture from configuration file load the weights and designing input output pipelines ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement your own yolo object detector from scratch in pytorch ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement yolo object detector from scratch in pytorch ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement yolo object detector from scratch using pytorch ayoosh kathuria min read series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part part of the tutorial series on how to implement yolo object detector from scratch using pytorch ayoosh kathuria min read series dimension reduction autoencoders this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series dimension reduction isomap this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read series dimension reduction sne this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle ashwini kumar pal min read may gradient what new in gradient we ve been hard at work developing gradient into robust and scalable deep learning platform here roundup of some of the things we ve added recently product release notes can be found here and api release note are located here new jobs page in addition to the summary view on the main jobs page we ve added standalone page with all sorts of new functionality summary view to drilldown into the new job details page click the arrow icon next to the job name the job details page includes everything about your job parameters environment logs metrics and code all in one place new jobs details page jupyterlab jupyterlab is the next generation web based user interface from jupyter this new version includes multiple tabbed documents an improved terminal customizable shortcuts etc here an overview we ve added the data science stack and the stack containers as base container options public jobs getting functioning environment set up can be bear with public jobs you can easily package your job and share it with others just click the button in the upper right to make job public so anyone can clone it in their own account you can convert the job to private at any point here public job example persistent storage accessible in notebooks jupyter is great environment for managing data which you can now use to manage your persistent storage in gradient the persistent storage will be automatically mounted to every notebook and job in your account just spin up notebook and you ll see the storage directory here you can easily upload data move files around etc job builder ui new to gradient or not fan of working in command line try the new graphical job builder step by step ui for constructing jobs the section at the top includes few sample projects you can run with just couple clicks more documentation can be found here job metrics it important to understand the performance of the model you are training metrics like accuracy loss and validation are often used for this purpose we added section of the jobs page to plot these metrics since training can take hours or days or even weeks it important to track metrics in real time just add few lines to your code and we ll parse the output and convert them into metrics graphs will begin plotting as soon as the model begins training and will be available after the job is complete for reference comparison initializing charts print chart loss axis iteration print chart accuracy axis iteration graph loss and accuracy print chart loss value value print chart accuracy value value here an example of what typical output will look like guide and sample code can be found here public job example discourseembed discourseurl https community paperspace com https blog paperspace com whats new in gradient june function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild daniel kobran coo co founder paperspace read more august gradient new gradient python sdk introducing the new gradient python sdk for machine learning model training building and deployment build out complex end to end machine learning pipelines with ease for many machine learning developers the ability to interact with their development process through simple programmatic api has been long standing request the sdk joins our command line utility our builder gui and the gradientci build automation tool as first class citizen for building and deploying machine learning models in gradient installing pip install pre gradient quick start import the sdkclient from the gradient package from gradient import sdk_client create api key api_key os getenv ps_api_key access all paperspace entities from single client client sdk_client sdkclient api_key this new library allows you to interact with gradient from within python script or application it supplements the gradient cli functionality with the added ability to automate actions and pipelines the following is an example using the sdk to perform multinode with multiple workers parameter server observe the state transitions of the experiment stream the logs during training after training completes we take the associated tensorflow model deploy it for inference using tfserving as rest endpoint backed by multi instance gpus load balancing instantiate the sdk clients client sdk_client sdkclient api_key or access each component from its own client sdk_client api_key models_client sdk_client modelsclient api_key jobs_client sdk_client jobsclient api_key projects_client sdk_client projectsclient api_key sdk_client api_key create project project_id client projects create new project the sdk returns the id of any create calls as python objects to enable easy scripting create multinode distributed experiment step setup the hyperparameters create dictionary of parameters for running distributed multinode experiment env epochs_eval train_epochs max_steps eval_secs step create dictionary with experiment parameters name multinode_mnist project_id project_id tensorflow tensorflow gpu py worker_command pip install requirements txt python mnist py experiment_env env worker_count tensorflow tensorflow gpu py pip install requirements txt python mnist py workspace_url https github com paperspace mnist sample git model_path storage models tutorial mnist model_type tensorflow step run the training experiment pass the dictionary into experiments client experiment_id client experiments run_multi_node step watch the state transitions as experiment launches from gradient import constants experimentstate print watching state of experiment state while state running new_state client experiments get experiment_id state new_state experimentstate get_state_str new_state if new_state state print state new_state state new_state watching state of experiment state created state provisioning state provisioned state network setting up state network setup state running step stream the logs during runtime log_streamer client experiments yield_logs experiment_id print streaming logs of experiment try while true print log_streamer send none except print done streaming logs streaming logs of experiment logrow line message tensorflow core common_runtime gpu gpu_device cc created tensorflow device job worker replica task device gpu with mb memory physical gpu device name tesla pci bus id compute capability timestamp logrow line message tensorflow core common_runtime gpu gpu_device cc created tensorflow device job master replica task device gpu with mb memory physical gpu device name tesla pci bus id compute capability timestamp logrow line message tensorflow core common_runtime gpu gpu_device cc created tensorflow device job ps replica task device gpu with mb memory physical gpu device name tesla pci bus id compute capability timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job master timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job master localhost timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job master timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job ps timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job ps timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job ps localhost timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job worker timestamp logrow line message tensorflow core rpc grpc_channel cc initialize for job worker timestamp logrow line message py saving checkpoints for into storage models tutorial mnist mnist model ckpt timestamp logrow line message session_manager py done running local_init_op timestamp logrow line message util py initialize strategy timestamp logrow line message util py initialize strategy timestamp logrow line message tensorflow stream_executor dso_loader cc successfully opened cuda library libcublas so locally timestamp logrow line message py cross_entropy learning_rate train_accuracy timestamp logrow line message py loss step timestamp logrow line message py cross_entropy learning_rate train_accuracy timestamp logrow line message py cross_entropy learning_rate train_accuracy sec timestamp now view deploy the resulting model model client models list experiment_id experiment_id deploy_param deployment_type tensorflow serving on image_url tensorflow serving latest gpu name sdk_tutorial machine_type instance_count model_id model id mnist client deployments create deploy_param client deployments start mnist deployment client deployments list model_id model id programatically get the resulting endpoint print deployment print endpoint deployment endpoint deployment id_ des dp vav name sdk_tutorial endpoint https services paperspace io model serving des dp vav predict api_type rest state running model_id moj uljjrsx project_id pr kr qf image_url tensorflow serving latest gpu deployment_type tensorflow serving on machine_type instance_count endpoint https services paperspace io model serving des dp vav predict performing inference image example png image def image prediction_url vector make_vector image json inputs vector response requests post prediction_url json json print http response response status_code print response text image deployment endpoint send post request to rest endpoint get classification http response outputs classes probabilities additional resources read the product docs read the autogenerated docs this post was collaboration between dillon misha kutsovsky dillon ceo co founder paperspace more posts by dillon misha kutsovsky read more posts by this author interview deepfake faceoff dr fakenstein ctrlshiftface deepfake technology is unlocking new era of media production as with all technologies both positive and harmful use cases exist as ethical technologists we aspire to push the limits of what is john min read announcement introducing the next iteration of gradient run on prem in your cloud or hybrid update this launch was featured in techcrunch over the last few years we ve fielded countless requests to run gradient our mlops saas platform on existing infrastructure ranging from local bare metal servers to dillon min read tutorial neural machine translation with tensorflow if you are fan of google translate or some other translation service do you ever wonder how these programs are able to make spot on translations from one language to another on par henry ansah fordjour min read series gradient descent with python part generic python implementation of gradient descent for nn optimization hello again in the series of tutorials for implementing generic gradient descent gd algorithm in python for optimizing parameters of artificial neural network ann in the backpropagation phase the gd implementation will ahmed fawzy gad min read tutorial unpaired image to image translation with cyclegan yann lecun director of ai research at facebook and professor at nyu described generative adversarial networks gans as the most interesting idea in machine learning in the last years since the invention henry ansah fordjour min read gradient new gradient python sdk build out complex end to end machine learning pipelines with the new gradient python sdk dillon misha kutsovsky min read series gradient descent with python part generic python implementation of gradient descent for nn optimization hello again in the series of tutorials for implementing generic gradient descent gd algorithm in python for optimizing parameters of artificial neural network ann in the backpropagation phase the gd implementation will ahmed fawzy gad min read tutorial tensorflow in action tensorflow is one of the most popular frameworks used for deep learning projects and is approaching major new release tensorflow luckily we don have to wait for the official release alvin koontz min read advanced technologies group move quickly think deeply how research is done paperspace atg the advanced technologies group is an focused team here at paperspace comprising ml engineers and researchers as group we re interested in exploring advanced topics in deep learning data engineering computer harsh sikka min read series gradient descent with python part generic python implementation of gradient descent for nn optimization through series of tutorials the gradient descent gd algorithm will be implemented from scratch in python for optimizing parameters of artificial neural network ann in the backpropagation phase the gd implementation will ahmed fawzy gad min read deep learning interesting deep learning applications for nlp read on to discover deep learning methods are being applied in the field of natural language processing achieving state of the art results for most language problems gaurav belani min read deep learning building state of the art bacterial classifier with paperspace gradient and fast ai one of the great promises of deep learning is its applicability in wide variety of complex tasks recent years have seen an explosion in the number of fields deep learning has seen harsh sikka min read train ml models on free cloud gpus when we started paperspace back in our mission was to make cloud gpu resources more accessible and less expensive for everyone since inception we have continued to offer wide variety of moses feaster min read pytorch pytorch part understanding hooks in this post we cover debugging and visualisation in pytorch we go over pytorch hooks and how to use them to debug our backpass visualise activations and modify gradients ayoosh kathuria min read tutorial pytorch part memory management and using multiple gpus this article covers pytorch advanced gpu management features including how to multiple gpu for your network whether be it data or model parallelism we conclude with best practises for debugging memory error ayoosh kathuria min read tutorial pytorch part going deep with pytorch in this tutorial we dig deep into pytorch functionality and cover advanced tasks such as using different learning rates learning rate policies and different weight initialisations etc ayoosh kathuria min read pytorch pytorch part building your first neural network in this part we will implement neural network to classify cifar images we cover implementing the neural network data loading pipeline and decaying learning rate schedule ayoosh kathuria min read deep learning pytorch part understanding graphs automatic differentiation and autograd in this article we dive into how pytorch autograd engine performs automatic differentiation ayoosh kathuria min read tutorial convert full imagenet pre trained model from mxnet to pytorch currently there are many available deep learning frameworks for researchers and engineers to implement their desired deep models each deep learning framework has its own advantages and disadvantages for example tensorflow has amir hossein karami min read tutorial detecting and localizing pneumonia from chest ray scans with pytorch over the years we have seen very powerful models being built to distinguish between objects these models keep getting better in terms of performance and latency day by day but have we ever henry ansah fordjour min read announcement multinode distributed training new github app and more introducing gradientci powerful new way to train and deploy machine learning models from github add superpowers to your ml workflow dillon daniel parker jared scheib min read gradient gradient update gradient has been updated in response to ton of feedback from the community here roundup of some of the things we ve added recently new system custom metrics now whenever you dillon min read security introducing single sign on sso single sign on sso has become staple in enterprise authorization and identity management we are pleased to announce that saml based sso is now generally available across all paperspace products the benefits of sso include daniel kobran min read deep learning going beyond torchvision models resnets densenets and inception networks are undoubtedly some of the most powerful models out there for performing image classification and object recognition these models have shown some promising results in the imagenet large henry ansah fordjour min read tutorial physics control tasks with deep reinforcement learning in this tutorial we will implement the paper continuous control with deep reinforcement learning published by google deepmind and presented as conference paper at icrl the networks will be implemented in antonio cappiello min read  october ci cd ci cd for machine learning ai the ecosystem for developing modern web applications is incredibly rich there are countless tools for delivering modern web app to production monitoring it performance and deploying in real time these tools are so essential that modern web application development would be almost impossible without them by contrast modern ml and ai doesn yet have that same ecosystem this makes sense for number of reasons best practices have still yet to emerge there isn lamp stack for ml yet tools are changing quickly and modern deep learning has really only existed for blink of an eye in the grand scheme of things devops aiops the questions around ml tooling and building production pipelines are one of the key problems we are trying to solve here at paperspace most of our current work is being built into gradient our toolstack for ml ai developers to quickly develop modern deep learning applications we believe that one of the largest barriers to pervasive and productive ai is an infrastructural and tooling problem assuming that hard requirement of these intelligent systems is scrutibility determinism and reproducibility while container orchestration tools like kubernetes mesos etc are an essential part of modern ml they are only one small part of true ci cd system for deep learning furthermore traditional ci cd and similar system for ml ai have different parameters constraints and goals we have spent lot of time thinking about these systems exploring the landscape and working with developers in academia startups and large enterprise to identify general problems that span across problem domains and can be addressed by modern machine learning platform generally these pipelines looks pretty similar they take data in build model and then deploy this model to the world the particulars however are incredibly interesting and worth diving deeper into gradient is our take on modern ci cd for machine learning and ai systems as platform it is being designed to take set of fundamental building blocks primitives which can be composed into larger and more complex systems reproducible pipeline must be composed of deterministic and immutable pieces these include git hashes docker hashes etc powerful hashing is one of the key design patterns at the core of gradient job runs and even machine hardware host accelerator etc are all assigned immutable tags which are designed to contribute to the larger project of deterministic and reproducible processes this post is not about gradient itself but rather collection of thoughts on how these types of systems fundamentally differ from the existing tools in the developers toolchest the future of data pipelines at paperspace we share the belief that we are in golden age of machine intelligence but also acknowledge that the relatively nascent field is still playing catch up in many ways to give just one example using docker or similar technology pushed modern web infrastructure forward in ways that were unimaginable in the early days of the web by contrast in machine learning is still relatively new with substantial amounts of production work being done on laptops bare metal servers and hand configured environments much of modern ml is still being done on powerful desktop computers the things that sit under your desk and warm your feet companies like lambda labs and boxx offer big rigs that include fast processors and big gpus we think this is weird but understandable anti pattern that exists today because there doesn really exist an affordable and powerful cloud computing option big companies with large deep learning and ai expertise have been investing heavily in software platforms that help bring ml up to speed with the rest of the development process making ai operational is an ambition for many companies and the ones that do it successfully will have long term competitive advantages to give just few examples of these end to end ml platforms uber has discussed publicly their version called michaelangelo facebook has fblearner google has tfx and airbnb has bighead recognizing the power of opening up these types of tools to more companies that might not have the same internal expertise as google fb and uber companies like databricks have introduced platforms like mlflow open source alternatives exist such as polyaxon and kubeflow but in most cases company is left to hack together disparate systems or worse attempting to repurpose older toolstacks for these modern dataflows traditional ci cd workflow continuous integration continuous deployment ci cd describes set of best practices for application development pipelines they are largely implemented by devops teams to enable software developers to quickly and reliably introduce updates to production applications some of the core benefits of modern ci cd pipeline include reliability reproducibility speed safety version control quick survey of ci cd tools for traditional web applications yields number of tools that you have likely used of heard of at their core these tools attempt to formalize well known workflow build test deploy for example we largely use node js and golang here at paperspace and we have invested heavily in building infrastructure that lets us quickly push new features to production ci cd are often lumped together but in fact they describe two separate but related concepts continuous integration ci is primarily concerned with testing code as it is pushed making sure that new application features are automatically tested using unit tests by contrast continuous deployment cd describes the actual release delivery of the tested code for example cd system could describe how different feature release branches are deployed or even how new features are selectively rolled out to new users test feature on of the customer base importantly however both of these concepts have been largely absent from the conversation around modern machine learning and deep learning pipelines ci cd for ml ai looking at an ideal ci cd system for machine learning we immediately see number of key differences at paperspace we believe these differences are substantial enough to warrant entirely new workflows development paradigms and toolstacks data arguably the most consequential difference between traditional web apps and ml pipeline is the fact that the primary input to the system is not just code rather there are two equally consequential inbound components code and data data orchestration cleaning versioning etc is an entire domain that has only in recent history become first class citizen for many companies the big data shift of the last years as well as the emergence of the data scientist as primary operator at company speaks to this dramatic shift unfortunately we are still at very early stage for true versioned reproducible data pipelines there are no shortage of powerful etl extract transform load tools such as kafka spark cassandra hadoop etc which are widely used in large scale production systems today modern ml introduces additional constraints and higher standard for better understanding this data and it isn hyperbolic to say we are in reproducibility crisis and modern ml is rightly criticized for being an inscrutable black box there are many big and unanswered questions around data governance provenance if self driving car is involved with an accident regulating body will rightly want to know what assumptions in the data and the model contributed to the error condition the data can embed bias in ways that deep learning models are particularly good at extracting and as this trend continues there will undoubtedly be increased scrutiny on how data is collected prepared and ultimately delivered as an input in to prediction engines tools such as quilt are leading the way for forward looking data versioning tool but they have not yet had widespread adoption some alternatives include dat and gitlfs but the space is still new and relatively unexplored also worth mentioning is the work being done by teams such as pachyderm we are big fans to think about data as first class primitive in datascience ml workflows accelerators it almost so obvious that it goes without mentioning but modern webapps are huge beneficiaries of the fact that almost everything runs on traditional architectures regular cpus there is some really interesting work around arm for certain applications but for the most part this homogeneity at the hardware level has allowed general portability that in retrospect was undoubtedly big part of the general cloud evolution modern ml ai and in particular deep learning owes much of its recent progress to the fact that it works extremely well on the gpu this is more of historical anomaly more than anything else but the last few years have witnessed the transition of the gpu from its more well known application in graphics processing to becoming general compute device it is unlikely that the same device will be used to power video games and deep learning applications and hardware vendors are racing to develop custom silicon that can accelerate deep learning training and inference companies like graphcore with their ipu intel with the nervana platform and google with the tpu tensor processing unit are all racing to develop custom chips that are purpose built for modern machine learning what does this mean for the modern ml ai engineer the hardware landscape is becoming more complex heterogeneous and rich it is very likely that modern ml pipeline would utilize cpu at the data ingest phase an nvidia gpu for training the model and custom architectures for deployment to the edge the neural engine that lives in your iphone training step the training step in ml pipeline is the area that ends up usually taking the most compute time it is another big differentiator between traditional datascience and modern deep learning you can do world class datascience on an inexpensive laptop computer just to get started with real deep learning requires investing in expensive gpus ideally multiple or sophisticated cloud tools the training task can take anywhere from couple hours to couple weeks depending on the complexity of the model the amount of data to be processed and its particular dimensions features etc and the type of accelerator being used distributed training involving multiple distinct compute nodes has made big progress very recently with tools like uber horovod tensorflow distributed and suite of libraries built in to pytorch to name just few which adds additional complexity to the task refitting online so now the holy grail of machine learning pipelines realtime online predictive engines that not only deploy forward but are actually continuously updated you might have heard of the term refitting the model which means that new data enters in and the model is updated in response to these new observations traditional web application development is largely unidirectional in the sense that it flows from code deployment usually there are static releases and modern software development oftentimes necessitates distinct development staging and production environments newer technologies such as jenkinsx support things like distinct deployments for each developer branch but this doesn change the fact that most deployment processes looks pretty static from the outside of course there is customer feedback bug fixes etc that inform the development life cycle but this is generally the responsibility of organizational process an agile development method in near future we predict that every company will employ some form of continuous real time deep learning engine that said the barriers to creating such system today are numerous even static ml pipelines are hard to put into practice by sophisticated teams with substantial resources the future however is bright in the sense that these types of self updating self modifying systems are getting more practical and we can begin to discuss their possibilities and constraints in addition to the fundamental machine learning algorithms and toolstacks that have been introduced in recent years and are constantly being pushed forward by an active academic community the infrastructural solutions to self updating ml pipelines are arguably core component of truly pervasive machine intelligence the idea of self updating deep learning engine opens up whole host of problems at basic level how do we detect quantify and ultimately correct so called model drift where the outputted model of classification or prediction engine begins to diverge from the input in an undesirable way perhaps even more pressing what are the boundaries of these systems and how do we begin to meaningfully constrain them the thread below is particularly illuminating in short facebook can simultaneously measure everything about us and control the information we consume when you have access to both perception and action youre looking at an ai problem you can start establishing an optimization loop for human behavior rl loop franois chollet fchollet march conclusion ultimately ci cd and associated best practices contribute to faster development team that commits to reproducible pipleining tool can build faster deploy faster and as team grow faster modern ml is quickly evolving space that brings in many different practitioners from traditional software developers to mathematicians academics and business executives and in this sense it is an exciting area to be working in even basic terminology is being defined and best practices are largely yet to emerge we are eager to hear your thoughts and observations from the field special thanks to aneesh karve quilt and john mannes basis set ventures for reviewing early drafts of this post dillon ceo co founder paperspace read more july machine learning creating your own style transfer mirror with gradient and ml js in this post we will learn how to train style transfer network with paperspace gradient and use the model in ml js to create an interactive style transfer mirror this post is the second on series of blog posts dedicated to train machine learning models in paperspace and then use them in ml js you can read the first post in this series on how to train lstm network to generate text here style transfer style transfer is the technique of recomposing images in the style of other images it first appeared in september when gatys et al published the paper neural algorithm of artistic style in this paper the researchers demonstrated how deep neural networks specifically convolutional neural networks can develop and extract representation of the style of an image and store this representation inside feauture maps the idea is to then use that learned style representation and apply it to another image more specifically the system uses neural representations to separate and recombine content and style of arbitrary images providing neural algorithm for the creation of artistic images our work offers path forward to an algorithmic understanding of how humans create and perceive artistic imagery basically you train deep neural network to extract representation of an image style you can then apply this style to content image and create new image cs that has the content of but the style of after gatys et al publication other similar methods and optimizations were published perceptual losses for real time style transfer and super resolution by johnson et al introduced new methods for optimizing the process three orders of magnitude faster and with high resolution images you can learn more about the technical details of what the network is doing when transfering styles here here and in this previous paperspace post pablo picasso painting on glass in restyled by works from his blue african and cubist periods respectively by gene kogan style transfer mirror in the browser in this tutorial we will train model to capture and learn the style of any image you want we will then use this model inside the browser with ml js to create an interactive mirror that will use the webcam and which applies real time style transfer over the captured image here is demo of the final result using chungungo pate factory in tunqun by the chilean artist bororo please allow and enable your webcam we are running this model entirley on the browser thanks to ml js if you haven read the previous post ml js is new javascript library that aims to make machine learning approachable for broad audience of artists creative coders and students the library provides access to machine learning algorithms and models in the browser building on top of tensorflow js with no other external dependencies so we will train model in python using gpu acceleration thanks to gradient export the model to javascript and run everything on the browser with the ml styletransfer method setting up you can find the code for this project in this repository this code is based on github com lengstrom fast style transfer which is combination of gatys neural algorithm of artistic style johnson perceptual losses for real time style transfer and super resolution and ulyanov instance normalization training this algorithm requires access to the coco dataset coco is large scale object detection segmentation and captioning dataset the version of the dataset we will be using is about gb in total fortunately paperspace has public datasets which you can access from your jobs so there no need to download it public datasets are automatically mounted to your jobs and notebooks under the read only datasets directory install the paperspace node api we will use the paperspace node api or the python api if you don have it installed you can easily install it with npm npm install paperspace node or with python pip install paperspace you can also install binaries from the github releases page if you prefer once you have created paperspace account you will be able to login in with your credentials from your command line paperspace login add your paperspace email and password when prompted if you don have an account with paperspace yet you can use this link to get for free link https www paperspace com vztqgmt training instructions clone the repository start by cloning or downloading the project repository git clone https github com paperspace git cd this will be the root of our project select style image put the image you want to train the style on inside the images folder run your code on gradient in the repository root you will find file called run sh this is script that contains the instructions we will use run to train our model open run sh and modify the style argument to point to your image python style py style images yourimage jpg checkpoint dir checkpoints vgg path styletransfer data imagenet vgg verydeep mat train path datasets coco model dir artifacts test images violetaparra jpg test dir tests content weight checkpoint iterations batch size style should point to the image you want to use model dir will be the folder where the ml js model will be saved test is an image that will be used to test the process during each epoch you can learn more about how to use all the parameters for training in the on the original repository for this code here and here now we can start the training process type paperspace jobs create container cvalenzuelab styletransfer machinetype command run sh project style transfer training this means we want to create new paperspace job using as base container docker image that comes pre installed with all the dependencies we will need we also want to use machinetype and we want to run the command run sh to start the training process this project will be called style transfer training when the training process starts you should see the following uploading styletransfer zip bps new jobid jstj ojrollcf cluster ps jobs job pending waiting for job to run job running storage region east coast ny awaiting logs ml js style transfer training note this traning will take couple of hours training is starting training this model takes between hours on machine you can choose better gpu if you wish to make the process faster you can also close the terminal if you wish the training process will still continue and will not be interrupted if you login into paperspace com under the gradient tab you can check the status of the model you can also check it by typing paperspace jobs logs tail jobid your_job_id download the model once it finishes you should see the following in the log converting model to ml js writing manifest to artifacts manifest json done checkpoint saved visit https ml js org docs styletransfer for more information this means the final model is ready in artifacts folder of your job if you go to paperspace com check your job under the gradient tab and click artifacts you will see folder called model this folder contains the architecture and all the learned weigths from our model they are ported into json friendly format that web browsers can use and that ml js uses to load it click the icon on the right to download the model or type paperspace jobs artifactsget jobid your_job_id this will download the folder with our trained model be sure to download the model inside ml js_example models now we are ready to try our model in ml js using the model in the root of our project you will find folder called ml js_example this folder contains very simple example of how to load style transfer model in ml and use the camera as input it uses js to make this process easier you can look at the original example and code here for now the line that you should change is this at the stop of ml js_example sketch js const style new ml styletransfer models your_new_model your_new_model should be the name of the model you just downloaded we are almost ready to test the model the only thing left is to start server to view our files if you are using python python if you are using python python http server visit http localhost and if everything went well you should see the demo note on training and images try with different images and and discover different results avoid geometry or images with lot of patterns because those images do not hold enough recongizable feature that network can learn this for example is using winter serigraphy by the chilean kinetic artist matilde prez you can notice that the results are not as good as the previous example because the input image is mostly composed of regular geometric patter repetition with few independent features more resources gene kogan style transfer experiments neural algorithm of artistic style artistic style transfer with deep neural networks ml js discourseembed discourseurl https community paperspace com https blog paperspace com creating your own style transfer mirror function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild cristbal valenzuela read more posts by this author read more april series yolo object detector in pytorch how to implement yolo object detector from scratch in pytorch part image credits karol majek check out his yolo real time detection video here this is part of the tutorial on implementing yolo detector from scratch in the last part we implemented the forward pass of our network in this part we threshold our detections by an object confidence followed by non maximum suppression the code for this tutorial is designed to run on python and pytorch it can be found in it entirety at this github repo this tutorial is broken into parts part understanding how yolo works part creating the layers of the network architecture part implementing the the forward pass of the network part this one confidence thresholding and non maximum suppression part designing the input and the output pipelines prerequisites part of the tutorial basic working knowledge of pytorch including how to create custom architectures with nn module nn sequential and torch nn parameter classes basic knowledge of numpy in case you re lacking on any front there are links below the post for you to follow in the previous parts we have built model which outputs several object detections given an input image to be precise our output is tensor of shape is the number of images in batch is the number of bounding boxes predicted per image and is the number of bounding box attributes however as described in part we must subject our output to objectness score thresholding and non maximal suppression to obtain what will call in the rest of this post as the true detections to do that we will create function called write_results in the file util py def write_results prediction confidence num_classes nms_conf the functions takes as as input the prediction confidence objectness score threshold num_classes in our case and nms_conf the nms iou threshold object confidence thresholding our prediction tensor contains information about bounding boxes for each of the bounding box having objectness score below threshold we set the values of it every attribute entire row representing the bounding box to zero conf_mask prediction confidence float unsqueeze prediction prediction conf_mask performing non maximum suppression note assume you understand what iou intersection over union is and what non maximum suppression is if that is not the case refer to links at the end of the post the bounding box attributes we have now are described by the center coordinates as well as the height and width of the bounding box however it easier to calculate iou of two boxes using coordinates of pair of diagnal corners of each box so we transform the center center height width attributes of our boxes to top left corner top left corner right bottom corner right bottom corner box_corner prediction new prediction shape box_corner prediction prediction box_corner prediction prediction box_corner prediction prediction box_corner prediction prediction prediction box_corner the number of true detections in every image may be different for example batch of size where images and have true detections respectively therefore confidence thresholding and nms has to be done for one image at once this means we cannot vectorise the operations involved and must loop over the first dimension of prediction containing indexes of images in batch batch_size prediction size write false for ind in range batch_size image_pred prediction ind image tensor confidence threshholding nms as describe previously write flag is used to indicate that we haven initialized output tensor we will use to collect true detections across the entire batch once inside the loop let clean things up bit notice each bounding box row has attributes out of which are the class scores at this point we re only concerned with the class score having the maximum value so we remove the class scores from each row and instead add the index of the class having the maximum values as well the class score of that class max_conf max_conf_score torch max image_pred num_classes max_conf max_conf float unsqueeze max_conf_score max_conf_score float unsqueeze seq image_pred max_conf max_conf_score image_pred torch cat seq remember we had set the bounding box rows having object confidence less than the threshold to zero let get rid of them non_zero_ind torch nonzero image_pred try image_pred_ image_pred non_zero_ind squeeze view except continue for pytorch compatibility since the above code with not raise exception for no detection as scalars are supported in pytorch if image_pred_ shape continue the try except block is there to handle situations where we get no detections in that case we use continue to skip the rest of the loop body for this image now let get the classes detected in an image get the various classes detected in the image img_classes unique image_pred_ index holds the class index since there can be multiple true detections of the same class we use function called unique to get classes present in any given image def unique tensor tensor_np tensor cpu numpy unique_np np unique tensor_np unique_tensor torch from_numpy unique_np tensor_res tensor new unique_tensor shape tensor_res copy_ unique_tensor return tensor_res then we perform nms classwise for cls in img_classes perform nms once we are inside the loop the first thing we do is extract the detections of particular class denoted by variable cls the following code is indented by three blocks in the original code file but ve not indented it here because the space is limited on this page get the detections with one particular class cls_mask image_pred_ image_pred_ cls float unsqueeze class_mask_ind torch nonzero cls_mask squeeze image_pred_ class_mask_ind view sort the detections such that the entry with the maximum objectness confidence is at the top conf_sort_index torch sort descending true conf_sort_index idx size number of detections now we perform nms for in range idx get the ious of all boxes that come after the one we are looking at in the loop try ious bbox_iou unsqueeze except valueerror break except indexerror break zero out all the detections that have iou treshhold iou_mask ious nms_conf float unsqueeze iou_mask remove the non zero entries non_zero_ind torch nonzero squeeze non_zero_ind view here we use function bbox_iou the first input is the bounding box row that is indexed by the the variable in the loop second input to bbox_iou is tensor of multiple rows of bounding boxes the output of the function bbox_iou is tensor containing ious of the bounding box represented by the first input with each of the bounding boxes present in the second input if we have two bounding boxes of the same class having an an iou larger than threshold then the one with lower class confidence is eliminated we ve already sorted out bounding boxes with the ones having higher confidences at top in the body of the loop the following lines gives the iou of box indexed by with all the bounding boxes having indices higher than ious bbox_iou unsqueeze every iteration if any of the bounding boxes having indices greater than have an iou with box indexed by larger than the threshold nms_thresh than that particular box is eliminated zero out all the detections that have iou treshhold iou_mask ious nms_conf float unsqueeze iou_mask remove the non zero entries non_zero_ind torch nonzero squeeze non_zero_ind also notice we have put the line of code to compute the ious in try catch block this is because the loop is designed to run idx iterations number of rows in however as we proceed with the loop number of bounding boxes may be removed from this means even if one value is removed from we cannot have idx iterations hence we might try to index value that is out of bounds indexerror or the slice may return an empty tensor assigning which triggers valueerror at that point we can ascertain that nms can remove no further bounding boxes and we break out of the loop calculating the iou here is the function bbox_iou def bbox_iou box box returns the iou of two bounding boxes get the coordinates of bounding boxes box box box box box box box box get the corrdinates of the intersection rectangle inter_rect_x torch max inter_rect_y torch max inter_rect_x torch min inter_rect_y torch min intersection area inter_area torch clamp inter_rect_x inter_rect_x min torch clamp inter_rect_y inter_rect_y min union area iou inter_area inter_area return iou writing the predictions the function write_results outputs tensor of shape here is the true detections in all of images each represented by row each detections has attributes namely index of the image in the batch to which the detection belongs to corner coordinates objectness score the score of class with maximum confidence and the index of that class just as before we do not initialize our output tensor unless we have detection to assign to it once it has been initialized we concatenate subsequent detections to it we use the write flag to indicate whether the tensor has been initialized or not at the end of loop that iterates over classes we add the resultant detections to the tensor output batch_ind new size fill_ ind repeat the batch_id for as many detections of the class cls in the image seq batch_ind if not write output torch cat seq write true else out torch cat seq output torch cat output out at the end of the function we check whether output has been initialized at all or not if it hasn been means there hasn been single detection in any images of the batch in that case we return try return output except return this is it for this post at the end of this post we finally have prediction in form tensor which lists each prediction as it row the only thing that left now is to create an input pipeline to read images from disk compute the prediction draw bounding boxes on the images and then display write these images this is what we will do in the next part further reading pytorch tutorial iou non maximum suppresion non maximum suppression ayoosh kathuria is currently an intern at the defense research and development organisation india where he is working on improving object detection in grainy videos when he not working he either sleeping or playing pink floyd on his guitar you can connect with him on linkedin or look at more of what he does at github ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more november tutorial generating an interactive pix pix model with gradient and ml js this post will go through the process of training generative image model using gradient and then porting the model to ml js so you can interact with it in the browser for this we will use pix pix or image to image translation with conditional adversarial nets and train it on pairs of satellite images and map tiles this is the third post on series of blog posts dedicated to train machine learning models in paperspace and then use them in ml js introducing pix pixpix pix or image to image translation is technique to train machine learning model to learn mapping between pairs of related images from input to output images this means the model will learn how to convert images of one type or with one set of characteristics into an new image with another set of characteristics you can use this approach to synthesize new pixels given similar input used when training the model for this pix pix uses special kind of generative algorithm called conditional adversarial network cgan where the generation process is conditioned on input image the original paper and code was publish by phillip isola et al on november and since then this technique has been widely used and explored by many people and researchers but besides its interesting technical novelty some of its creative results are fascinating input output and target images using the cmp facades dataset image by christopher hessethis post will be focused on running and training your own model good resource if you are interested in more detailed description of how pix pix works is the machine learning for artist ml pix pix post there you can find in depth explanations of how the model learns to generalize the technical details of the technique and the kind of creative applications people have been building for instance you can create real time interactive project like this one experimenting with image to image translation for characters in runwayml and hellopaperspace guess can call this the alternative late show with stephenathome pic twitter com sm rawdgub cris valenzuela c_valenzuelab august what we will be buildingfor this tutorial we will create an interactive satellite image generator we will train model on pairs of satellite and map tiles of any city you want and pix pix will learn how to convert tile maps into satellite looking images you can use the same approach to train model in any kind of related pairs of images you like take look the demo this example is based on gene kogan invisible cities project where he created different models for different cities and then made city map style transfer invisible cities project made during machine learning for artists workshop with gene kogan opendotlabwe will be actually using some of the scripts used in invisible cities to get images from mapbox we will then use pix pix tensorflow implementation made by christopher hesse and run it inside gradient hesse made single file implementation of the original paper and code written in torch to tensorflow he also wrote tensorflow js port that is able to run on the browser the implementation ml js uses is based on that code with some additional changes hesse also made great introduction to the way image to image translation works including detailed explanation of how the encoding decoding process works and what happens during training and validation phases you can find his blog post here setting upinstalling the paperspace node apiwe will use the paperspace node api or the python api if you don have it installed you can easily install it with npm npm install paperspace node or with python pip install paperspace you can also install binaries from the github releases page if you prefer once you have created paperspace account you will be able to login in with your credentials from your command line paperspace login add your paperspace email and password when prompted if you don have an account with paperspace yet you can use this link to get for free link https www paperspace com vztqgmt get the codestart by cloning or downloading the project repository git clone https github com paperspace training pix pix git cd training pix pixthis will be the root of our project get the datawe will need to generate the data for our project for this we will use mapbox to get the tiles of any city we want you will need to sign up if you don already have an account into mapbox following this link it free and there no need to use credit card when signing in once registered visit your account dashboard and select the access token tab there you will find the api code you we will need to get access to download the images this token should look something like this default public token pk eyj p_ jjxyyyyyyyyyyy we are now ready to download some map images we will use python from the root of the project type the following python scripts map_tiles get_tiles py key your_api_key width height zoom num_images output_dir images augment true lat_min lng_min lat_max lng_max style_map cvalenzuela cjksl ss ezlnr this means we want to download images of size with in the boundaries defined in lat_min lat_max lng_min and lng_max with zoom of in this particular case we are defining the boundaries of small part of santiago chile but feel free to change them to any other part of the world you like if you run that script you should see the following getting map image getting map image getting map image getting map image after this script finishes two new folders will be created inside the images folder one will contain satellite images and the other tile maps one image pair left is satellite and right is tile pix pix will learn to translate from to we will then need to create one single image that holds these pairs of images run the following script python scripts map_tiles copy_tiles py in_path images this will create new folder called combined containing images of size try opening the folder and explore the training set you will be using the final step before the training phase is to separate our data into training and validation sets to do so run the following python scripts split py dir images combined that will split our data into training and validation sets folders inside images combined you should now erase the map and sat folders so you don upload them to the training process trainingonce our pairs of images have been collected we need to train our model in order to do so we will need gpu accelerated computing this process is actually really easy with gradient from the root of our project run the following command paperspace jobs create container tensorflow tensorflow gpu py machinetype command run sh project pix pixtraining ignorefiles ml js_example here we are creating new gradient job using as base python with tensorflow and gpu support we are selecting machine type and we are running the command run sh the name of the project is pix pixtraining and we are ignoring the files in the the examples folderif you explore the file run sh you will see that we are calling the pix pix py file with some default parameters python pix pix py mode train output_dir artifacts max_epochs input_dir images combined train which_direction btoa save_freq display_freq our final model will be inside the artifacts folder once the job is sumbitted to the paperspace cluster you should see the following uploading pix pix zip bps new jobid js zo cloaysao cluster ps jobs job pending waiting for job to run training pix pix this script will train model and export it to ml js based on https github com affinelayer pix pix tensorflow starting progress epoch step image sec remaining discrim_loss gen_loss_gan gen_loss_l recording summary progress epoch step image sec remaining discrim_loss gen_loss_gan gen_loss_l saving model this process will take around hours to train you can monitor the progress via the gradient ui or by typing paperspace jobs logs tail jobid your_job_id downloading the modelonce the training process is finished the script will create model that ready to use in ml js by the end of the training process the log should say the following progress epoch step image sec remaining discrim_loss gen_loss_gan gen_loss_l saving model training finished exporting the model loading model from checkpoint exporting model export finished porting the model to ml js done your model is ready read how to use it here https ml js org docs pix pix all set you can now download the resulting model with the following command cd models paperspace jobs artifactsget jobid your_job_id this will download all the files in artifacts we actually just need the file called model pict copy that file to ml js_example model use the modelopen ml js_example script js and change the path to point to your new model pix pix ml pix pix model model pict modelloaded we are almost ready to test the model the only thing left is to start server to view our files if you are using python python you are using python python http servervisit http localhost and if everything went well you should see the demo this approach and code for training pix pix should work with any well structure pairs of images you want to use examples of pix pix models include edges cats edges shoes edges handbags edges to faces labes to facedes pose body etc more resourcesimage to image translation with conditional adversarial netsoriginal hesse pix pix blog post machine learning for artist ml pix pix post ml js cristbal valenzuela read more posts by this author read more april series dimension reduction isomap this tutorial is from part series on dimension reduction understanding dimension reduction with principal component analysis pca diving deeper into dimension reduction with independent components analysis ica multi dimension scaling mds lle sne isomap autoencoders jupyter notebook with math and code spark is available on github repo isomap stands for isometric mapping isomap is non linear dimensionality reduction method based on the spectral theory which tries to preserve the geodesic distances in the lower dimension isomap starts by creating neighborhood network after that it uses graph distance to the approximate geodesic distance between all pairs of points and then through eigenvalue decomposition of the geodesic distance matrix it finds the low dimensional embedding of the dataset in non linear manifolds the euclidean metric for distance holds good if and only if neighborhood structure can be approximated as linear if neighborhood contains holes then euclidean distances can be highly misleading in contrast to this if we measure the distance between two points by following the manifold we will have better approximation of how far or near two points are let understand this with an extremely simple example suppose our data lies on circular manifold in structure like in the image below why geodesic distances are better than the euclidean distances in nonlinear manifolds we will reduce the data to using the euclidean distances and approximate geodesic distances now if we look at the mapping based on the euclidean metric we see that for points which are far apart have been mapped poorly only the points which can be approximated to lie on linear manifold give satisfactory results on the other hand see the mapping with geodesic distances it nicely approximates the close points as neighbors and far away points as distant the geodesic distances between two points in the image are approximated by graph distance between the two points thus euclidean distances should not be used for approximating the distance between two points in non linear manifolds while geodesic distances can be used isomap uses the above principle to create similarity matrix for eigenvalue decomposition unlike other non linear dimensionality reduction like lle lpp which only use local information isomap uses the local information to create global similarity matrix the isomap algorithm uses euclidean metrics to prepare the neighborhood graph then it approximates the geodesic distance between two points by measuring shortest path between these points using graph distance thus it approximates both global as well as the local structure of the dataset in the low dimensional embedding let have basic understanding of few concepts which we need to implement the isomap algorithm pregel api pregel is distributed programming model developed by google for processing large scale graphs it is the inspiration behind the apache giraph project and graphx library of spark pregel is basically message passing interface based on the idea that vertex state should depend on its neighbors pregel computation takes as input graph and set of vertex states at every iteration which is called superstep it processes messages received at vertex and updates the vertex state after that it decides which of its neighbors should receive the message at next superstep and what should be the message thus messages are passed along edges and computation happens only at the vertices the graph is not passed across the network only messages computation stops at maximum iterations or when no messages are left to pass let understand it using simple example suppose we need to find the degree of each vertex for the graph given below image shown below represents single iteration of pregel model at initialization every vertex degree is we can send an empty message as an initial message to start the computation at the end of superstep each vertex sends message through each of its edges at next superstep each vertex sums the messages received and update its degree classical mds isomap is closely related to the original scaling algorithm proposed by the torgerson and gower in fact it is an extension of the classical scaling the classical algorithm gives closed form solution to the dimensionality reduction problem classical mds uses the euclidean distances as the similarity metric while isomap uses geodesic distances steps of classical mds are create matrix of squared dissimilarities from the given obtain the matrix by double centring the dissimilarity matrix compute the eigenvalue decomposition of matrix qq choose the eigenvectors having highest eigenvalues steps of isomap isomap differs from classical mds in initial few steps only instead of using euclidean metric for dissimilarity it uses graph distances steps of the isomap algorithm are neighbourhood graph create neighborhood graph and adjacency matrix from the dataset dissimilarity matrix after neighborhood search we will use spark graphx library for calculating the geodesic distances between the points while creating our neighborhood network we have to make sure that the resulting graph is single connected component if not then our similarity matrix will remain incomplete and results will be incoherent we need to iterate over the different values of neighborhood selection parameter to get the fully connected graph as of now spark does not have the shortest path function for the weighted graph we will have to implement it the code below presents shortest path algorithm using pregel like api of graphx the code is from the shortest path function for unweighted graphs of graphx lib functions addmaps and sendmessage have been modified to support weighted graphs def shortestpath verts rdd vertexid immap long double edges rdd edge double landmarks seq long seq graph immap long double double val graph verts edges type spmap map vertexid double def makemap vertexid double map def incrementmap spmap spmap spmap spmap double spmap spmap map case if spmap getorelse double maxvalue else def addmaps spmap spmap spmap spmap spmap spmap keyset spmap keyset map math min spmap getorelse double maxvalue spmap getorelse double maxvalue collection breakout var spgraph graph immap long double double null if landmarks isempty spgraph mapvertices vid attr makemap vid else spgraph mapvertices vid attr if landmarks contains vid makemap vid else makemap val initialmessage makemap def vertexprogram id vertexid attr spmap msg spmap spmap addmaps attr msg def sendmessage edge edgetriplet spmap double iterator vertexid spmap val newattr incrementmap edge srcattr edge dstattr edge attr if newattr isempty iterator edge dstid newattr else iterator empty val pregel spgraph initialmessage vertexprogram sendmessage addmaps return eigenvalue decomposition before eigenvalue decomposition we have to square the distance and double center the squared similarities matrix after eigenvalue decomposition select the first eigenvectors with highest eigenvalues the plot of subset of mnist dataset after isomap dimension reduction what we have implemented is the vanilla version isomap it requires lot of time and computing power it has two bottlenecks first calculation of dissimilarity matrix requires operations where is the number of the samples and the second calculation of pairwise graph distances if is huge which is true generally in case of big datasets it becomes impractical solution to this problem is landmark isomap landmark isomap is based on landmark mds landmark mds selects group of points termed as landmarks and implements classical mds on them based on the mapping obtained from classical mds remaining points are mapped in the low dimensional embedding using distance based triangulation steps for landmark classical scaling selects landmarks points xlandmarks apply classical mds on landmarks points and obtain low dimensional emebedding lk calculate where ui is mean of ith row of dissimilarity matrix of landmark points given vector xa calculate where ai is the squared distance between the point xa and the landmark point low dimensional embedding for the xa is given by ya au where is the penrose moore inverse of the lk selection of landmark points can be random or through specific method for obtaining dimensional embedding at least landmark points are needed for reasons related to the stability of the algorithm number of landmark points chosen should be more than strict minimum the accuracy of isometric mapping in landmark isomap does not suffer much due to approximation in the algorithm drawbacks of isomaps isomap performs poorly when manifold is not well sampled and contains holes as mentioned earlier neighborhood graph creation is tricky and slightly wrong parameters can produce bad results conclusion in this article we discussed another manifold learning algorithm isomap isometric mapping in the beginning of the post we talked about what is isometric mapping and how it is different from other dimension reduction algorithms then we had brief discussion on pregel api later on we implemented an isomap algorithm in scala using spark graphx library for people wishing to go deeper in distributed graph processing graphx is good starting point next post in this series will be on autoencoders ashwini kumar pal read more posts by this author read more september series data augmentation data augmentation for bounding boxes rethinking image transforms for object detection when it comes to getting good performances from deep learning tasks the more data the merrier however we may only have limited data with us data augmentation is one way to battle this shortage of data by artificially augmenting our dataset in fact the technique has proven to be so successful that it become staple of deep learning systems why does data augmentation work very straightforward way to understand why data augmentation works is by thinking of it as way to artificially expand our dataset as is the case with deep learning applications the more data the merrier another way to understand why data augmentation works so well is by thinking of it as added noise to our dataset this is especially true in case of online data augmentation or augmenting every data sample stochastically each time we feed it to the training loop left original image right augmented image each time the neural network sees the same image it bit different due to the stochastic data augmentation being applied to it this difference can be seen as noise being added to our data sample each time and this noise forces the neural network to learn generalised features instead of overfitting on the dataset github repoeverything from this article and the entire augmentation library can be found in the following github repo https github com paperspace documentation for this project can be found by opening the docs build html index html in your browser or at this link this series has parts part basic design and horizontal flipping part scaling and translation part rotation and shearing part baking augmentation into input pipelinesobject detection for bounding boxesnow lot of deep learning libraries like torchvision keras and specialised libraries on github provide data augmentation for classification training tasks however the support for data augmentation for object detection tasks is still missing for example an augmentation which horizontally flips the image for classification tasks will like look the one above however doing the same augmentation for an object detection tasks also requires you to update the bounding box for example this change of bounding boxes during horizontal flipit this sort of data augmentation or specifically the detection equivalent of the major data augmentation techniques requiring us to update the bounding boxes that we will cover in these article to be precise here is the exact list of augmentations we will be covering horizontal flip as shown above scaling and translating rotation shearing resizing for input to the neural network technical details we will be basing our little data augmentation library on numpy and opencv we will define our augmentations as classes instances of which can be called to perform augmentation we will define uniform way to define these classes so that you can also write your own data augmentations we will also define data augmentation that does nothing of it own but combines data augmentations so that they can be applied in sequence for each data augmentation we will define two variants of it stochastic one and deterministic one in the stochastic one the augmentation happens randomly whereas in deterministic the parameters of the augmentation like the angle to be rotated are held fixed example data augmentation horizontal flipthis article will outline the general approach to writing an augmentation we will also go over some utility functions that will help us visualise detections and some other stuff so let get started format for storing annotationfor every image we store the bounding box annotations in numpy array with rows and columns here represents the number of objects in the image while the five columns represent the top left coordinatethe top left coordinate the right bottom coordinate the right bottom coordinatethe class of the objectformat for storing bounding box annotationsi know lot of datasets and annotation tools store annotations in other formats so leave it you to turn whatever storage format your data annotations are stored in into the format described above and yes for demonstration purposes we are going to use the following image of lionel messi scoring beauty of goal against nigeria file organisationwe keep our code in files data_aug py and bbox_util py the first file is going to contain the code for augmentations while the second file will contain the code for helper functions both these files will live inside folder called data_auglet us assume that you have to use these data augmentations in your training loop ll let you figure out how you extract your images and make sure annotations are in proper format however for sake of keeping thing simple let us use only one image at time you can easily move this code inside the loop or your data fetching function to extend the functionality clone the github repo in the folder containing the file of your training code or the file where you need to make of the augmentation git clone https github com paperspace horizontal flipfirst we import all the necessary stuff and make sure the path is added even if we call the functions from outside the folder containing the files the following code goes in the file data_aug pyimport random import numpy as np import cv import matplotlib pyplot as plt import sys import os lib_path os path join os path realpath data_aug sys path append lib_path the data augmentation will be implementing is which flips an image horizontally with probability we first start by defining the class and it method the init method contains the parameters of the augmentation for this augmentation it is the probability with each image is flipped for another augmentation like rotation it may contain the angle by which the object is to be rotated class object randomly horizontally flips the image with the probability parameters float the probability with which the image is flipped returns numpy ndaaray flipped image in the numpy format of shape hxwxc numpy ndarray tranformed bounding box co ordinates of the format where is number of bounding boxes and represents of the box def self self the docstring of the function has been written in numpy docstring format this will be useful to generate documentation using sphinx the method of each function is used to define all the parameters of the augmentation however the actually logic of the augmentation is defined in the function the call function when invoked from class instance takes two arguments img and bboxes where img is the opencv numpy array containing the pixel values and bboxes is the numpy array containing the bounding box annotations the function also returns the same arguments and this helps us chain together bunch of augmentations to be applied in sequence def self img bboxes img_center np array img shape img_center np hstack img_center img_center if random random self img img bboxes img_center bboxes box_w abs bboxes bboxes bboxes box_w bboxes box_w return img bboxeslet us break by bit by bit what going on in here in horizontal flip we rotate the image about verticle line passing through its center the new coordinates of each corner can be then described as the mirror image of the corner in the vertical line passing through the center of the image for the mathematically inclined the vertical line passing through the center would be the perpendicular bisector of the line joining the original corner and the new transformed corner to have better understanding of what is going on consider the following image the pixels in the right half of the transformed image and the left half of the original image are mirror images of each other about the central line the above is accomplished by the following piece of code img_center np array img shape img_center np hstack img_center img_center if random random self img img bboxes img_center bboxes note that the line img img basically takes the array containing the image and reverses it elements in the st dimension or the dimensional which stores the coordinates of the pixel values however one must notice that the mirror image of the top left corner is the top right corner of the resultant box infact the resultant coordinates are the top right as well as bottom left coordinates of the bounding box however we need them in the top left and bottom right format the side effect of our codethe following piece of code takes care of the conversion box_w abs bboxes bboxes bboxes box_w bboxes box_w we end up by returning the image and the array containing the bounding boxes deterministic version of above code applies the transformation stochastically with the probability however if we want to build deterministic version we can simply pass the argument as or we could write another class where we do not have the parameter at all and implement the function like this def self img bboxes img_center np array img shape img_center np hstack img_center img_center img img bboxes img_center bboxes box_w abs bboxes bboxes bboxes box_w bboxes box_w return img bboxesseeing it in actionnow let suppose you have to use the horizontalflip augmentation with your images we will use it on one image but you can use it on any number you like first we create file test py we begin by importing all the good stuff from data_aug data_aug import import cv import pickle as pkl import numpy as np import matplotlib pyplot as pltthen we import the image and load the annotation img cv imread messi jpg opencv uses bgr channels bboxes pkl load open messi_ann pkl rb print bboxes visual inspection in order to see whether our augmentation really worked or not we define helper function draw_rect which takes in img and bboxes and returns numpy image array with the bounding boxes drawn on that image let us create file bbox_utils py and import the neccasary stuff import cv import numpy as npnow we define the function draw_rectdef draw_rect im cords color none draw the rectangle on the image parameters im numpy ndarray numpy image cords numpy ndarray numpy array containing bounding boxes of shape where is the number of bounding boxes and the bounding boxes are represented in the format returns numpy ndarray numpy image with bounding boxes drawn on it im im copy cords cords reshape if not color color for cord in cords pt pt cord cord cord cord pt int pt int pt pt int pt int pt im cv rectangle im copy pt pt color int max im shape return imonce this is done let us go back to our test py file and plot the original bounding boxes plt imshow draw_rect img bboxes this produces something like this let us see the effect of our transformation hor_flip img bboxes hor_flip img bboxes plt imshow draw_rect img bboxes you should get something like this takeaway lessonsthe bounding box annotation should be stored in numpy array of size where is the number of objects and each box is represented by row having attributes the coordinates of the top left corner the coordinates of the bottom right corner and the class of the object each data augmentation is defined as class where the method is used to define the parameters of the augmentation whereas the method describes the actual logic of the augmentation it takes two arguments the image img and the bounding box annotations bboxes and returns the transformed values this is it for this article in the next article we will be dealing with scale and translate augmentations not only they are more complex transformations given there are more parameters the scaling and translation factors but also bring some challenges that we didn have to deal with in the horizontalflip transformation an example is to decide whether to retain box if portion of it is outside the image after the augmentation discourseembed discourseurl https community paperspace com https blog paperspace com data augmentation for bounding boxes function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more july series optimization intro to optimization in deep learning vanishing gradients and choosing the right activation function mathjax hub config tex jax inlinemath processescapes true this is the third post in the optimization series where we are trying to give the reader comprehensive review of optimization in deep learning so far we have looked at how mini batch gradient descent is used to combat local minima and saddle points how adaptive methods like momentum rmsprop and adam augment vanilla gradient descent to address the problem of pathological curvature distributions damned distributions and statistics neural networks unlike the machine learning methods that came before it do not rest upon any probabilistic or statistical assumptions about the data they are fed however one of the most if not the most important element required to ensure that neural networks learn properly is that the data fed to the layers of neural network exhibit certain properties the data distribution should be zero centered the mean of the distribution should be around zero absence of this can cause vanishing gradients and jittery training it is preferred that the distribution be normal one absence of this can cause the network to overfit to domain of input space the distributions of the activations both across the batch as well as the across layer should remain somewhat constant as the training goes by absence of this is called internal covariate shift and this may slow down training in this article we will cover problems no and and how activation functions are used to address them we end with some practical advice to choose which activation function to chose for your deep network vanishing gradients the problem of vanishing gradients is well documented and gets much more pronounced as we go deeper and deeper with neural networks let us understand why they happen imagine the possibly simplest neural network bunch of neurons stacked linearly one can easily extend this analogy to deeper densely connected architectures in fact one can easily do that by replacing each neuron in the network by full layer each of the neurons use sigmoid non linearity as it activation function the graph for sigmoid function looks like this if you look at the slope of the sigmoid function you will realize it tends to zero on either of the fringes or better let us look at the plot of the gradient of the sigmoid function when we differentiate the output of sigmoid activation layer with respect to it weights we see that the gradient of the sigmoid function is factor in the expression this gradient has value ranging from to frac partial sigma omega tx partial omega frac partial sigma omega tx partial omega tx frac partial omega tx partial omega the second term is sigmoid derivative which has range of to going back to our example let us figure out the gradient rule for neuron applying chain rule we see that the gradient for neuron looks like frac partial partial frac partial partial frac partial partial frac partial partial frac partial partial realize that each of the term in the expression above can be further factorized to product of gradients one of which is gradient of the sigmoid function for instance frac partial partial frac partial partial sigma omega_d tc b_d frac partial sigma omega_d tc b_d partial omega_d tc b_d frac partial omega_d tc b_d partial now let us suppose instead of neurons in front of there are about neurons in front of this is totally plausible in practical scenario where networks may easily have layers then the gradient expression of has product of sigmoid gradients in it and as each such term has value between and the value of the gradient of might be driven to zero to see how this might happen let do simple experiment let us randomly sample numbers from to and then multiply them altogether import random from functools import reduce li random uniform for in range print reduce lambda li go try it yourself despite repeated attempts could never get value of order more than if this value is present in the gradient expression of neuron as factor then it gradient would be almost negligible this means in deeper architectures no learning happens for the deeper neurons or if it happens it does so at remarkably slower rate than the learning for the shallower higher layers such phenomenon is called the vanishing gradients problem wherein the gradients of the deeper neurons become zero or to say vanish the problem then is that the deeper layers of the network learn very slowly or in worst case the deeper layers don learn at all saturated neurons the problems of vanishing gradients can be worsened by saturated neurons suppose that pre activation omega tx that is fed to neuron with sigmoid activation is either very high or very low the gradient of sigmoid at very high or low values is almost any gradient update would hardly produce change in the weights omega and the bias and it would take lot of steps for the neuron to get modify weights so that the pre activation falls in an area where the gradient has substantial value relu to the rescue the first attempt at curbing the problem of vanishing gradients in general deep network setting lstms were introduced to combat this as well but they were restricted to recurrent models was the introduction of the relu activation function the gradient of relu is for gt and for lt it has multiple benefits the product of gradients of relu function doesn end up converging to as the value is either or if the value is the gradient is back propagated as it is if it is then no gradient is backpropagated from that point backwards one sided saturations we had two sided saturation in the sigmoid functions that is the activation function would saturate in both the positive and the negative direction in contrast relus provide one sided saturations though it is not exactly precise to call the zero part of relu saturation however it serves the same purpose in way that the value of the function doesn vary at all as opposed to very very small variation in proper saturation as the input to the function becomes more and more negative what benefit might one sided saturation bring you may ask we like to think neurons in deep network like switches which specialize in detecting certain features which are often termed as concepts while the neurons in the higher layers might end up specializing in detecting high level concepts like eyes tyres etc the neurons in lower layers end up specializing in low level concepts such as curves edges etc we want the neurons to fire when such concept in present in the input it gets and the magnitude of it is measure of the extent of the concept in the input for example if neuron detects an edge it magnitude might represent the sharpness of an edge activation maps created by neurons learn different concepts however it doesn make sense as to have an unbounded negative value for neuron while it intuitive to interpret the confidence in presence of concept it quite odd to to encode the absence of concept considering the example related to neuron detecting edges having an activation of as compared as to an activation of might mean more sharper edge but what sense does value of make when compared to wherein below value below zero represents no edge at all therefore it be convenient to have uniform value of zero for all the input that corresponds to the case of the concept being absent some other concept might be present or none at all relus with their one sided saturation accomplish exactly that information disentanglement and robustness to noise having one sided saturation makes neuron robust to noise why let us assume that we have neurons values of which are unbounded don saturate in either of the direction the inputs which contain the concept to varying degrees produce variance in the positive output of the neuron this is fine as we want the magnitude to be indicator of the strength of the signal however the variance in the signal bought about background noise or concepts the neuron doesn specialize in region containing arcs being fed to neurons that specialize in detecting lines produce variance in the the negative output of the neuron this type of variance can contribute extraneous useless information to other neurons which have dependencies with the particular neuron we are talking about this can also lead to correlated units for example neuron that detects lines might have negative correlation with neuron that detects arcs now let us consider the same scenario with neuron that saturates in the negative region for preactivation here the variance due to noise which showed up as negative magnitude earlier is squashed by the saturating element of the activation function this prevents noise from producing extraneous signals sparsity using relu activation function also has computational benefits relu based networks train quicker since no significant computation is spent in calculating the gradient of relu activation this is contrast to sigmoid where exponentials would need to be computed in order to calculate gradients since relu clamp the negative preactivations to zero they implicitly introduce sparsity in the network which can be exploited for computational benefits the dying relu problem relus come with their own set of shortcomings while sparsity is computational advantage too much of it can actually hamper learning normally the pre activation also contains bias term if this bias term becomes too negative such that omega tx lt then the gradient of the relu activation during backward pass is therefore the weights and the bias causing the negative preactivations cannot be updated if the weights and bias learned is such that the preactivation is negative for the entire domain of inputs the neuron never learns causing sigmoid like saturation this is known as the dying relu problem zero centered activations since relus only output non negative activations regardless of it input they will always produce positive activations this can be drawback let us understand how for relu based neural network the gradient for any set of weights omega_n belonging to layer l_n having an activation z_n relu omega_n tx_n b_n for the loss function frac partial partial omega_ frac partial partial relu omega_n tx_n b_n relu omega_n tx_n b_n x_n here relu omega_n tx_n b_n gt is indicator function which is when the condition passed as it arguement is true and otherwise since relu only outputs non negative value x_ since each element of x_n is either positive or zero the gradient update for each weight in omega_n has the same sign as frac partial partial relu omega_n tx_n b_n now how is that problem the problem is that since the sign of gradient update for all neurons is the same all the weights of the layer l_n can either increase or decrease during one update however the ideal gradient weight update might be one where some weights increase while the other weights decrease this is not possible with relu suppose some weights need to decrease in accordance to an ideal weight update however if the gradient update is positive these weights become too positive in the current iteration in the next iteration the gradient may be negative as well as large to remedy these increased weights which might end up overshooting the weights which need little negative change or positive change this can cause zig zag patter in search of minima which can slow down the training problem with leaky relus leaky relus and parameterized relus in order to combat the problem of dying relus the leaky relu was proposed leaky relu is same as normal relu except that instead of being for lt it has small negative slope for that region in practice the negative slope alpha is chosen to be value of the order the benefit with leaky relu is that the backward pass is able to alter weights which produce negative preactivation as the gradient of the activation function for inputs lt is alpha for example leaky relu is used in yolo object detection algorithm since the negative pre activations produce negative values instead of we do not have the problem regarding weights being updated only in one direction that was associated with relu the value of alpha is something people have experimented quite bit with there exists an approach which is called randomized leaky relu where the negative slope is randomly chosen from uniform distribution with mean and standard deviation left begin array ll when gt alpha when leq end array right alpha sim the original paper of randomized relu claims that it produces better and faster results than leaky relu and proposes through empirical means that if we were limited to only single choice of alpha as in leaky relu choice of frac would work better than the reason why randomized leaky relu works is due to the random choice of negative slope hence randomness of gradients for negative preactivations which introduces randomness in the optimization algorithm this randomness or noise helps us steer clear of local minima and saddle points if you need more perspective on this encourage you to checkout the first part of the series where we have talked in depth about the topic taking the benefit of different negative slope for each neuron people have taken the approach further by not randomly sampling the negative slope alpha but turning it into hyperparameter which is learned by the network during training such an activation is called parametrized relu revisting saturation while neuron saturation seems like very bad thing to have in neural network having one sided saturation like we had in relu isn necessarily that bad while the above discussed variants of relu contribute to zero centered activations they don have the benefits of one sided saturation as discussed above exponential linear units and bias shift following the discussion above it seems as if the perfect activation function has two desirable properties producing zero centered distribution which can make the training faster having one sided saturation which leads to better convergence while leaky relus and prelu solve the first condition they fall short on the second one on the other hand vanilla relu satisfies the second but not the first condition an activation function that satisfies both the conditions is an exponential linear unit elu left begin array ll when gt alpha when leq end array right the gradient of the function is for gt while it is alpha for lt the function saturates for negative values to value of alpha alpha is hyperparameter that is normally chosen to be since the function does have region of negative values we no longer have the problem of non zero centered activations causing erratic training how to chose activation function try your luck with relu activation despite the fact we have outlined problems with relu lot of people have achieved good results with relu in accordance with the principal of occam razor it better to try out simpler stuff first relus among all the other viable contenders have the cheapest computational budget as well are dead simple to implement if your project requires coding up from scratch if relu doesn output promising results my next choice is either leaky relu or elu ve found that activations which are capable of producing zero centered activations are much better than the ones which don elu might have been very easy choice but elu based networks are slow to train as well slow at inference time since we have to compute lot of exponentials to compute the activation for negative preactivations if compute resources are not an issue for you or if the network is not gigantic go for elu other wise you might want to stick to leaky relus both lrelu and elu add another hyperparameter to be tuned if you have lot of computational budget and lot of time you can contrast the performance of the above activations with those of prelu and randomized relus randomized relu can be useful if your function shows overfitting with parametric relu you add whole bunch of parameters to be learned to your optimisation problem therefore parameterized relu should be used only if you have lot of training data conclusion in this post we covered the need for constant and well behaved distribution of data being fed to layers of neural network for it learn properly while activation functions implicitly try to normalize these distributions technique called batch normalization does this explicitly and it wouldn be wrong to say that it has been one of the major breakthroughs in the field of deep learning in the recent years however that will be covered in the next part of the series till then you can try your hand at trying out different activations for your network have fun experimenting further reading exploding gradient problem in depth look into advantages of relus reddit discussion on whether relus are still used and if yes why elu paper discourseembed discourseurl https community paperspace com https blog paperspace com vanishing gradients activation function function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild ayoosh kathuria deep learning engineer at mathworks currently working on bringing gans to matlab previously research intern at drdo passionate about computer vision and unsupervised learning read more august announcement the new paperspace community we re always amazed by what our users are building with paperspace and felt it was important to provide space where people can share ideas ask questions learn new tools and techniques and ultimately empower each other we recently added community which we like to formally share with everyone the community is designed with several top level categories covering different use cases as well as paperspace specific categories for questions suggestions about the service itself there are ton of useful features like tagging starting poll bookmarking marking response as solution to question etc the thing that we have found most helpful are tutorials and content around getting your environment running new technologies etc here an example tutorial on running docker on the new nvidia volta gpu beyond asking question or solving particular problem you have this is the kind of post we we think will be most valuable to the community we hope you take look and explore some of the content most importantly we encourage everyone to ask questions and share things you ve learned that might be helpful to others take me to the community the paperspace team discourseembed discourseurl https community paperspace com https blog paperspace com the paperspace community function var document createelement script type text javascript async true src discourseembed discourseurl javascripts embed js document head document body appendchild george read more posts by this author read more